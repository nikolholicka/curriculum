{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Neural Networks with Regularization - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Recall from the last lab that you had a training accuracy close to 90% and a test set accuracy close to 76%.\n",
    "\n",
    "As with your previous machine learning work, you should be asking a couple of questions:\n",
    "- Is there high bias? yes/no\n",
    "- Is there high variance? yes/no \n",
    "\n",
    "In this lab, you'll use the a train-validate-test partition as well as a validation set to get better insights of how to tune neural networks using regularization techniques. You'll start by repeating the process from the last section: importing the data and performing preprocessing including one-hot encoding. From there, you'll define and compile the model like before. However, this time, when you are presented with the `history` dictionary of the model, you will have additional data entries for not only the train and test set but also the validation set.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Construct and run a basic model in Keras\n",
    "* Construct a validation set and explain potential benefits\n",
    "* Apply L1 and L2 regularization\n",
    "* Apply dropout regularization\n",
    "* Observe and comment on the effect of using more data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the libraries\n",
    "\n",
    "As usual, start by importing some of the packages and modules that you intend to use. The first thing you'll be doing is importing the data and taking a random sample, so that should clue you in to what tools to import. If you need more tools down the line, you can always import additional packages later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "As with the previous lab, the data is stored in a file **Bank_complaints.csv**. Load and preview the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Bank_complaints.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>In XX/XX/XXXX I filled out the Fedlaon applica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>I am being contacted by a debt collector for p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>I cosigned XXXX student loans at SallieMae for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>Navient has sytematically and illegally failed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>My wife became eligible for XXXX Loan Forgiven...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Product                       Consumer complaint narrative\n",
       "0  Student loan  In XX/XX/XXXX I filled out the Fedlaon applica...\n",
       "1  Student loan  I am being contacted by a debt collector for p...\n",
       "2  Student loan  I cosigned XXXX student loans at SallieMae for...\n",
       "3  Student loan  Navient has sytematically and illegally failed...\n",
       "4  Student loan  My wife became eligible for XXXX Loan Forgiven..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Overview\n",
    "\n",
    "Before you begin to practice some of your new tools regarding regularization and optimization, let's practice munging some data as you did in the previous section with bank complaints. Recall some techniques:\n",
    "\n",
    "* Train - test split\n",
    "* Sampling in order to reduce training time (investigate model accuracy vs data size later on)\n",
    "* One-hot encoding your complaint text\n",
    "* Transforming your category labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: Generate a Random Sample\n",
    "\n",
    "Since you have quite a bit of data and training networks takes a substantial amount of time and resources, downsample in order to test your initial pipeline. Going forward, these can be interesting areas of investigation: how does your models performance change as you increase (or decrease) the size of your dataset?  \n",
    "\n",
    "Generate the random sample using seed 123 for consistency of results. Make your new sample have 10,000 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(10000,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)\n",
    "\n",
    "df.head()\n",
    "y=df.Product\n",
    "X=df['Consumer complaint narrative']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test Split\n",
    "\n",
    "Below, perform an appropriate train test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Yyour code here\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the model using a validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Validation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lecture, you saw that in deep learning, you generally set aside a validation set, which is then used during hyperparameter tuning. Afterwards, when you have decided upon a final model, the test can then be used to define the final model perforance. \n",
    "\n",
    "In this example, take the first 1000 cases out of the training set to create a validation set. You should do this for both `train` and `label_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just run this block of code \n",
    "\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(X_train, y_train, test_size=1000, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: One-hot Encoding of the Complaints\n",
    "\n",
    "As before, you need to do some preprocessing and data manipulationg before building the neural network. \n",
    "\n",
    "Keep the 2,000 most common words and use one-hot encoding to reformat the complaints into a matrix of vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; use one-hot encoding to reformat the complaints into a matrix of vectors.\n",
    "#Only keep the 2000 most common words.\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(num_words=2000) #Initialize a tokenizer.\n",
    "\n",
    "tokenizer.fit_on_texts(X_train_final) #Fit it to the complaints\n",
    "\n",
    "X_train_tokenized= tokenizer.texts_to_matrix(X_train_final, mode='binary')\n",
    "X_val = tokenizer.texts_to_matrix(X_val, mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: Encoding the Products\n",
    "\n",
    "Similarly, now transform the descriptive product labels to integers labels. After transforming them to integer labels, retransform them into a matrix of binary flags, one for each of the various product labels.  \n",
    "  \n",
    "> **Note**: This is similar to your previous work with dummy variables. Each of the various product categories will be its own column, and each observation will be a row. In turn, each of these observation rows will have a 1 in the column associated with it's label, and all other entries for the row will be zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarizer = LabelBinarizer()\n",
    "binarizer.fit(y_train_final)\n",
    "\n",
    "y_train_bin = to_categorical(binarizer.transform(y_train_final))[:,:,1]\n",
    "y_val = to_categorical(binarizer.transform(y_val))[:,:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rebuild a fully connected (Dense) layer network with relu activations in Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that you used 2 hidden with 50 units in the first layer and 25 in the second, both with a `relu` activation function. Because you are dealing with a multiclass problem (classifying the complaints into 7 classes), use a softmax classifyer in order to output 7 class probabilities per case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; build a neural network using Keras as described above.\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Dense(50, activation='relu', input_shape=(2000,)))\n",
    "model.add(keras.layers.Dense(25, activation='relu'))\n",
    "model.add(keras.layers.Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the Model\n",
    "In the compiler, you'll be passing the optimizer, loss function, and metrics. Train the model for 120 epochs in mini-batches of 256 samples. This time, include the argument `validation_data` and assign it `(val, label_val)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='SGD',loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "Ok, now for the resource intensive part: time to train your model! Note that this is where you also introduce the validation data to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 1000 samples\n",
      "Epoch 1/120\n",
      "7000/7000 [==============================] - 1s 98us/step - loss: 1.9498 - accuracy: 0.1334 - val_loss: 1.9513 - val_accuracy: 0.1210\n",
      "Epoch 2/120\n",
      "7000/7000 [==============================] - 0s 68us/step - loss: 1.9279 - accuracy: 0.1554 - val_loss: 1.9314 - val_accuracy: 0.1440\n",
      "Epoch 3/120\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 1.9098 - accuracy: 0.1811 - val_loss: 1.9133 - val_accuracy: 0.1820\n",
      "Epoch 4/120\n",
      "7000/7000 [==============================] - 1s 77us/step - loss: 1.8916 - accuracy: 0.2096 - val_loss: 1.8941 - val_accuracy: 0.2170\n",
      "Epoch 5/120\n",
      "7000/7000 [==============================] - 1s 75us/step - loss: 1.8715 - accuracy: 0.2451 - val_loss: 1.8730 - val_accuracy: 0.2520\n",
      "Epoch 6/120\n",
      "7000/7000 [==============================] - 1s 77us/step - loss: 1.8486 - accuracy: 0.2787 - val_loss: 1.8489 - val_accuracy: 0.2850\n",
      "Epoch 7/120\n",
      "7000/7000 [==============================] - 1s 101us/step - loss: 1.8222 - accuracy: 0.3129 - val_loss: 1.8204 - val_accuracy: 0.3150\n",
      "Epoch 8/120\n",
      "7000/7000 [==============================] - 1s 83us/step - loss: 1.7917 - accuracy: 0.3414 - val_loss: 1.7877 - val_accuracy: 0.3530\n",
      "Epoch 9/120\n",
      "7000/7000 [==============================] - 1s 95us/step - loss: 1.7561 - accuracy: 0.3674 - val_loss: 1.7502 - val_accuracy: 0.3720\n",
      "Epoch 10/120\n",
      "7000/7000 [==============================] - 1s 91us/step - loss: 1.7152 - accuracy: 0.3951 - val_loss: 1.7070 - val_accuracy: 0.3950\n",
      "Epoch 11/120\n",
      "7000/7000 [==============================] - 1s 101us/step - loss: 1.6685 - accuracy: 0.4261 - val_loss: 1.6583 - val_accuracy: 0.4240\n",
      "Epoch 12/120\n",
      "7000/7000 [==============================] - 1s 73us/step - loss: 1.6171 - accuracy: 0.4506 - val_loss: 1.6058 - val_accuracy: 0.4490\n",
      "Epoch 13/120\n",
      "7000/7000 [==============================] - 1s 74us/step - loss: 1.5620 - accuracy: 0.4724 - val_loss: 1.5506 - val_accuracy: 0.4710\n",
      "Epoch 14/120\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 1.5058 - accuracy: 0.4987 - val_loss: 1.4971 - val_accuracy: 0.4960\n",
      "Epoch 15/120\n",
      "7000/7000 [==============================] - 0s 71us/step - loss: 1.4504 - accuracy: 0.5299 - val_loss: 1.4431 - val_accuracy: 0.5070\n",
      "Epoch 16/120\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 1.3962 - accuracy: 0.5443 - val_loss: 1.3941 - val_accuracy: 0.5350\n",
      "Epoch 17/120\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 1.3447 - accuracy: 0.5703 - val_loss: 1.3433 - val_accuracy: 0.5570\n",
      "Epoch 18/120\n",
      "7000/7000 [==============================] - 0s 71us/step - loss: 1.2957 - accuracy: 0.5901 - val_loss: 1.2996 - val_accuracy: 0.5850\n",
      "Epoch 19/120\n",
      "7000/7000 [==============================] - 1s 71us/step - loss: 1.2488 - accuracy: 0.6066 - val_loss: 1.2556 - val_accuracy: 0.6130\n",
      "Epoch 20/120\n",
      "7000/7000 [==============================] - 0s 71us/step - loss: 1.2050 - accuracy: 0.6281 - val_loss: 1.2144 - val_accuracy: 0.6220\n",
      "Epoch 21/120\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 1.1636 - accuracy: 0.6400 - val_loss: 1.1761 - val_accuracy: 0.6360\n",
      "Epoch 22/120\n",
      "7000/7000 [==============================] - 1s 71us/step - loss: 1.1250 - accuracy: 0.6540 - val_loss: 1.1417 - val_accuracy: 0.6500\n",
      "Epoch 23/120\n",
      "7000/7000 [==============================] - 1s 71us/step - loss: 1.0885 - accuracy: 0.6684 - val_loss: 1.1080 - val_accuracy: 0.6610\n",
      "Epoch 24/120\n",
      "7000/7000 [==============================] - 1s 73us/step - loss: 1.0544 - accuracy: 0.6810 - val_loss: 1.0780 - val_accuracy: 0.6670\n",
      "Epoch 25/120\n",
      "7000/7000 [==============================] - 1s 73us/step - loss: 1.0221 - accuracy: 0.6907 - val_loss: 1.0495 - val_accuracy: 0.6700\n",
      "Epoch 26/120\n",
      "7000/7000 [==============================] - 1s 86us/step - loss: 0.9937 - accuracy: 0.6957 - val_loss: 1.0222 - val_accuracy: 0.6890\n",
      "Epoch 27/120\n",
      "7000/7000 [==============================] - 1s 73us/step - loss: 0.9654 - accuracy: 0.7073 - val_loss: 0.9978 - val_accuracy: 0.6890\n",
      "Epoch 28/120\n",
      "7000/7000 [==============================] - 1s 85us/step - loss: 0.9398 - accuracy: 0.7121 - val_loss: 0.9761 - val_accuracy: 0.6860\n",
      "Epoch 29/120\n",
      "7000/7000 [==============================] - 1s 71us/step - loss: 0.9157 - accuracy: 0.7181 - val_loss: 0.9542 - val_accuracy: 0.6950\n",
      "Epoch 30/120\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 0.8928 - accuracy: 0.7211 - val_loss: 0.9351 - val_accuracy: 0.6990\n",
      "Epoch 31/120\n",
      "7000/7000 [==============================] - 1s 73us/step - loss: 0.8717 - accuracy: 0.7259 - val_loss: 0.9202 - val_accuracy: 0.7040\n",
      "Epoch 32/120\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 0.8516 - accuracy: 0.7301 - val_loss: 0.9039 - val_accuracy: 0.6980\n",
      "Epoch 33/120\n",
      "7000/7000 [==============================] - 0s 66us/step - loss: 0.8337 - accuracy: 0.7321 - val_loss: 0.8850 - val_accuracy: 0.7110\n",
      "Epoch 34/120\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 0.8161 - accuracy: 0.7389 - val_loss: 0.8689 - val_accuracy: 0.7080\n",
      "Epoch 35/120\n",
      "7000/7000 [==============================] - 1s 73us/step - loss: 0.7999 - accuracy: 0.7410 - val_loss: 0.8563 - val_accuracy: 0.7090\n",
      "Epoch 36/120\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 0.7848 - accuracy: 0.7434 - val_loss: 0.8422 - val_accuracy: 0.7190\n",
      "Epoch 37/120\n",
      "7000/7000 [==============================] - 0s 71us/step - loss: 0.7699 - accuracy: 0.7489 - val_loss: 0.8348 - val_accuracy: 0.7200\n",
      "Epoch 38/120\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 0.7564 - accuracy: 0.7521 - val_loss: 0.8216 - val_accuracy: 0.7230\n",
      "Epoch 39/120\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 0.7430 - accuracy: 0.7556 - val_loss: 0.8132 - val_accuracy: 0.7210\n",
      "Epoch 40/120\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 0.7309 - accuracy: 0.7583 - val_loss: 0.8064 - val_accuracy: 0.7240\n",
      "Epoch 41/120\n",
      "7000/7000 [==============================] - 1s 137us/step - loss: 0.7193 - accuracy: 0.7617 - val_loss: 0.7934 - val_accuracy: 0.7280\n",
      "Epoch 42/120\n",
      "7000/7000 [==============================] - 1s 95us/step - loss: 0.7082 - accuracy: 0.7649 - val_loss: 0.7893 - val_accuracy: 0.7340\n",
      "Epoch 43/120\n",
      "7000/7000 [==============================] - 1s 98us/step - loss: 0.6978 - accuracy: 0.7664 - val_loss: 0.7785 - val_accuracy: 0.7310\n",
      "Epoch 44/120\n",
      "7000/7000 [==============================] - 1s 81us/step - loss: 0.6876 - accuracy: 0.7723 - val_loss: 0.7691 - val_accuracy: 0.7280\n",
      "Epoch 45/120\n",
      "7000/7000 [==============================] - 1s 82us/step - loss: 0.6781 - accuracy: 0.7727 - val_loss: 0.7659 - val_accuracy: 0.7370\n",
      "Epoch 46/120\n",
      "7000/7000 [==============================] - 1s 73us/step - loss: 0.6686 - accuracy: 0.7777 - val_loss: 0.7625 - val_accuracy: 0.7350\n",
      "Epoch 47/120\n",
      "7000/7000 [==============================] - 1s 74us/step - loss: 0.6599 - accuracy: 0.7799 - val_loss: 0.7530 - val_accuracy: 0.7400\n",
      "Epoch 48/120\n",
      "7000/7000 [==============================] - 1s 82us/step - loss: 0.6511 - accuracy: 0.7810 - val_loss: 0.7476 - val_accuracy: 0.7370\n",
      "Epoch 49/120\n",
      "7000/7000 [==============================] - 0s 66us/step - loss: 0.6435 - accuracy: 0.7843 - val_loss: 0.7425 - val_accuracy: 0.7380\n",
      "Epoch 50/120\n",
      "7000/7000 [==============================] - 1s 80us/step - loss: 0.6358 - accuracy: 0.7876 - val_loss: 0.7355 - val_accuracy: 0.7360\n",
      "Epoch 51/120\n",
      "7000/7000 [==============================] - 1s 75us/step - loss: 0.6277 - accuracy: 0.7916 - val_loss: 0.7308 - val_accuracy: 0.7420\n",
      "Epoch 52/120\n",
      "7000/7000 [==============================] - 1s 87us/step - loss: 0.6204 - accuracy: 0.7946 - val_loss: 0.7287 - val_accuracy: 0.7490\n",
      "Epoch 53/120\n",
      "7000/7000 [==============================] - 1s 82us/step - loss: 0.6140 - accuracy: 0.7944 - val_loss: 0.7264 - val_accuracy: 0.7400\n",
      "Epoch 54/120\n",
      "7000/7000 [==============================] - 1s 74us/step - loss: 0.6069 - accuracy: 0.7986 - val_loss: 0.7208 - val_accuracy: 0.7460\n",
      "Epoch 55/120\n",
      "7000/7000 [==============================] - 1s 78us/step - loss: 0.6008 - accuracy: 0.7999 - val_loss: 0.7151 - val_accuracy: 0.7510\n",
      "Epoch 56/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 0s 66us/step - loss: 0.5937 - accuracy: 0.8020 - val_loss: 0.7121 - val_accuracy: 0.7530\n",
      "Epoch 57/120\n",
      "7000/7000 [==============================] - 0s 64us/step - loss: 0.5876 - accuracy: 0.8051 - val_loss: 0.7087 - val_accuracy: 0.7510\n",
      "Epoch 58/120\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 0.5817 - accuracy: 0.8063 - val_loss: 0.7100 - val_accuracy: 0.7540\n",
      "Epoch 59/120\n",
      "7000/7000 [==============================] - 0s 68us/step - loss: 0.5760 - accuracy: 0.8083 - val_loss: 0.7038 - val_accuracy: 0.7560\n",
      "Epoch 60/120\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 0.5697 - accuracy: 0.8114 - val_loss: 0.7050 - val_accuracy: 0.7450\n",
      "Epoch 61/120\n",
      "7000/7000 [==============================] - 0s 68us/step - loss: 0.5646 - accuracy: 0.8109 - val_loss: 0.6982 - val_accuracy: 0.7570\n",
      "Epoch 62/120\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.5592 - accuracy: 0.8140 - val_loss: 0.6930 - val_accuracy: 0.7570\n",
      "Epoch 63/120\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.5535 - accuracy: 0.8160 - val_loss: 0.6904 - val_accuracy: 0.7570\n",
      "Epoch 64/120\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 0.5486 - accuracy: 0.8146 - val_loss: 0.6933 - val_accuracy: 0.7580\n",
      "Epoch 65/120\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.5439 - accuracy: 0.8180 - val_loss: 0.6879 - val_accuracy: 0.7540\n",
      "Epoch 66/120\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 0.5391 - accuracy: 0.8204 - val_loss: 0.6870 - val_accuracy: 0.7530\n",
      "Epoch 67/120\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.5337 - accuracy: 0.8203 - val_loss: 0.6810 - val_accuracy: 0.7610\n",
      "Epoch 68/120\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.5291 - accuracy: 0.8236 - val_loss: 0.6808 - val_accuracy: 0.7630\n",
      "Epoch 69/120\n",
      "7000/7000 [==============================] - 0s 65us/step - loss: 0.5248 - accuracy: 0.8233 - val_loss: 0.6787 - val_accuracy: 0.7640\n",
      "Epoch 70/120\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 0.5196 - accuracy: 0.8266 - val_loss: 0.6815 - val_accuracy: 0.7610\n",
      "Epoch 71/120\n",
      "7000/7000 [==============================] - 0s 65us/step - loss: 0.5157 - accuracy: 0.8260 - val_loss: 0.6800 - val_accuracy: 0.7620\n",
      "Epoch 72/120\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.5107 - accuracy: 0.8281 - val_loss: 0.6752 - val_accuracy: 0.7700\n",
      "Epoch 73/120\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 0.5066 - accuracy: 0.8296 - val_loss: 0.6698 - val_accuracy: 0.7590\n",
      "Epoch 74/120\n",
      "7000/7000 [==============================] - 0s 65us/step - loss: 0.5024 - accuracy: 0.8319 - val_loss: 0.6693 - val_accuracy: 0.7580\n",
      "Epoch 75/120\n",
      "7000/7000 [==============================] - 0s 65us/step - loss: 0.4986 - accuracy: 0.8316 - val_loss: 0.6662 - val_accuracy: 0.7650\n",
      "Epoch 76/120\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 0.4938 - accuracy: 0.8341 - val_loss: 0.6693 - val_accuracy: 0.7620\n",
      "Epoch 77/120\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 0.4902 - accuracy: 0.8340 - val_loss: 0.6647 - val_accuracy: 0.7660\n",
      "Epoch 78/120\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 0.4860 - accuracy: 0.8356 - val_loss: 0.6632 - val_accuracy: 0.7650\n",
      "Epoch 79/120\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 0.4822 - accuracy: 0.8400 - val_loss: 0.6646 - val_accuracy: 0.7620\n",
      "Epoch 80/120\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 0.4782 - accuracy: 0.8394 - val_loss: 0.6635 - val_accuracy: 0.7680\n",
      "Epoch 81/120\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.4744 - accuracy: 0.8414 - val_loss: 0.6612 - val_accuracy: 0.7650\n",
      "Epoch 82/120\n",
      "7000/7000 [==============================] - 0s 66us/step - loss: 0.4705 - accuracy: 0.8447 - val_loss: 0.6577 - val_accuracy: 0.7670\n",
      "Epoch 83/120\n",
      "7000/7000 [==============================] - 0s 66us/step - loss: 0.4672 - accuracy: 0.8433 - val_loss: 0.6576 - val_accuracy: 0.7710\n",
      "Epoch 84/120\n",
      "7000/7000 [==============================] - 0s 65us/step - loss: 0.4632 - accuracy: 0.8440 - val_loss: 0.6558 - val_accuracy: 0.7750\n",
      "Epoch 85/120\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 0.4597 - accuracy: 0.8463 - val_loss: 0.6563 - val_accuracy: 0.7680\n",
      "Epoch 86/120\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 0.4558 - accuracy: 0.8470 - val_loss: 0.6572 - val_accuracy: 0.7690\n",
      "Epoch 87/120\n",
      "7000/7000 [==============================] - 1s 77us/step - loss: 0.4527 - accuracy: 0.8470 - val_loss: 0.6554 - val_accuracy: 0.7690\n",
      "Epoch 88/120\n",
      "7000/7000 [==============================] - 0s 66us/step - loss: 0.4491 - accuracy: 0.8484 - val_loss: 0.6531 - val_accuracy: 0.7700\n",
      "Epoch 89/120\n",
      "7000/7000 [==============================] - 0s 67us/step - loss: 0.4458 - accuracy: 0.8531 - val_loss: 0.6568 - val_accuracy: 0.7730\n",
      "Epoch 90/120\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 0.4419 - accuracy: 0.8537 - val_loss: 0.6528 - val_accuracy: 0.7680\n",
      "Epoch 91/120\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 0.4389 - accuracy: 0.8533 - val_loss: 0.6520 - val_accuracy: 0.7690\n",
      "Epoch 92/120\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 0.4352 - accuracy: 0.8549 - val_loss: 0.6545 - val_accuracy: 0.7700\n",
      "Epoch 93/120\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 0.4321 - accuracy: 0.8584 - val_loss: 0.6509 - val_accuracy: 0.7680\n",
      "Epoch 94/120\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.4291 - accuracy: 0.8560 - val_loss: 0.6481 - val_accuracy: 0.7670\n",
      "Epoch 95/120\n",
      "7000/7000 [==============================] - 1s 90us/step - loss: 0.4255 - accuracy: 0.8587 - val_loss: 0.6473 - val_accuracy: 0.7680\n",
      "Epoch 96/120\n",
      "7000/7000 [==============================] - 1s 119us/step - loss: 0.4223 - accuracy: 0.8586 - val_loss: 0.6498 - val_accuracy: 0.7740\n",
      "Epoch 97/120\n",
      "7000/7000 [==============================] - 1s 118us/step - loss: 0.4193 - accuracy: 0.8609 - val_loss: 0.6456 - val_accuracy: 0.7630\n",
      "Epoch 98/120\n",
      "7000/7000 [==============================] - 1s 118us/step - loss: 0.4161 - accuracy: 0.8601 - val_loss: 0.6490 - val_accuracy: 0.7670\n",
      "Epoch 99/120\n",
      "7000/7000 [==============================] - 1s 119us/step - loss: 0.4132 - accuracy: 0.8626 - val_loss: 0.6490 - val_accuracy: 0.7660\n",
      "Epoch 100/120\n",
      "7000/7000 [==============================] - 1s 123us/step - loss: 0.4098 - accuracy: 0.8654 - val_loss: 0.6503 - val_accuracy: 0.7670\n",
      "Epoch 101/120\n",
      "7000/7000 [==============================] - 1s 118us/step - loss: 0.4070 - accuracy: 0.8649 - val_loss: 0.6473 - val_accuracy: 0.7680\n",
      "Epoch 102/120\n",
      "7000/7000 [==============================] - 1s 114us/step - loss: 0.4040 - accuracy: 0.8689 - val_loss: 0.6442 - val_accuracy: 0.7670\n",
      "Epoch 103/120\n",
      "7000/7000 [==============================] - 1s 121us/step - loss: 0.4008 - accuracy: 0.8673 - val_loss: 0.6466 - val_accuracy: 0.7630\n",
      "Epoch 104/120\n",
      "7000/7000 [==============================] - 1s 118us/step - loss: 0.3979 - accuracy: 0.8684 - val_loss: 0.6501 - val_accuracy: 0.7660\n",
      "Epoch 105/120\n",
      "7000/7000 [==============================] - 1s 121us/step - loss: 0.3950 - accuracy: 0.8703 - val_loss: 0.6464 - val_accuracy: 0.7720\n",
      "Epoch 106/120\n",
      "7000/7000 [==============================] - 1s 118us/step - loss: 0.3920 - accuracy: 0.8689 - val_loss: 0.6466 - val_accuracy: 0.7670\n",
      "Epoch 107/120\n",
      "7000/7000 [==============================] - 1s 119us/step - loss: 0.3893 - accuracy: 0.8719 - val_loss: 0.6451 - val_accuracy: 0.7720\n",
      "Epoch 108/120\n",
      "7000/7000 [==============================] - 1s 119us/step - loss: 0.3861 - accuracy: 0.8733 - val_loss: 0.6476 - val_accuracy: 0.7630\n",
      "Epoch 109/120\n",
      "7000/7000 [==============================] - 1s 115us/step - loss: 0.3831 - accuracy: 0.8746 - val_loss: 0.6575 - val_accuracy: 0.7630\n",
      "Epoch 110/120\n",
      "7000/7000 [==============================] - 1s 121us/step - loss: 0.3810 - accuracy: 0.8753 - val_loss: 0.6437 - val_accuracy: 0.7610\n",
      "Epoch 111/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 1s 111us/step - loss: 0.3777 - accuracy: 0.8767 - val_loss: 0.6481 - val_accuracy: 0.7630\n",
      "Epoch 112/120\n",
      "7000/7000 [==============================] - 1s 111us/step - loss: 0.3753 - accuracy: 0.8784 - val_loss: 0.6453 - val_accuracy: 0.7670\n",
      "Epoch 113/120\n",
      "7000/7000 [==============================] - 1s 115us/step - loss: 0.3726 - accuracy: 0.8797 - val_loss: 0.6455 - val_accuracy: 0.7660\n",
      "Epoch 114/120\n",
      "7000/7000 [==============================] - 1s 108us/step - loss: 0.3695 - accuracy: 0.8807 - val_loss: 0.6486 - val_accuracy: 0.7660\n",
      "Epoch 115/120\n",
      "7000/7000 [==============================] - 1s 113us/step - loss: 0.3677 - accuracy: 0.8803 - val_loss: 0.6465 - val_accuracy: 0.7650\n",
      "Epoch 116/120\n",
      "7000/7000 [==============================] - 1s 111us/step - loss: 0.3645 - accuracy: 0.8799 - val_loss: 0.6518 - val_accuracy: 0.7640\n",
      "Epoch 117/120\n",
      "7000/7000 [==============================] - 1s 116us/step - loss: 0.3621 - accuracy: 0.8809 - val_loss: 0.6442 - val_accuracy: 0.7660\n",
      "Epoch 118/120\n",
      "7000/7000 [==============================] - 1s 111us/step - loss: 0.3592 - accuracy: 0.8841 - val_loss: 0.6492 - val_accuracy: 0.7670\n",
      "Epoch 119/120\n",
      "7000/7000 [==============================] - 1s 112us/step - loss: 0.3566 - accuracy: 0.8841 - val_loss: 0.6452 - val_accuracy: 0.7630\n",
      "Epoch 120/120\n",
      "7000/7000 [==============================] - 1s 111us/step - loss: 0.3537 - accuracy: 0.8860 - val_loss: 0.6475 - val_accuracy: 0.7670\n"
     ]
    }
   ],
   "source": [
    "#Code provided; note the extra validation parameter passed.\n",
    "model_val = model.fit(X_train_tokenized,\n",
    "                    y_train_bin,\n",
    "                    epochs=120,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Performance Results: the `history` dictionary\n",
    "\n",
    "The dictionary `history` contains four entries this time: one per metric that was being monitored during training and during validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_val_dict = model_val.history\n",
    "model_val_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 1s 117us/step\n",
      "Training Loss: 0.351 Training Accuracy: 0.889\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(X_train_tokenized, y_train_bin)\n",
    "print(f'Training Loss: {results_train[0]:.3} Training Accuracy: {results_train[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess then evaluate our models performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 124us/step\n",
      "Testing Loss: 0.669 Testing Accuracy: 0.761\n"
     ]
    }
   ],
   "source": [
    "X_test_tok = tokenizer.texts_to_matrix(X_test, mode='binary')\n",
    "y_test_cat = to_categorical(binarizer.transform(y_test))[:, :, 1]\n",
    "\n",
    "results_test = model.evaluate(X_test_tok, y_test_cat)\n",
    "print(f'Testing Loss: {results_test[0]:.3} Testing Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'accuracy']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first element of the list returned by `model.evaluate` is the loss, and the second is the accuracy score. \n",
    "\n",
    "Note that the result you obtained here isn't exactly the same as before. This is because the training set is slightly different! You removed 1000 instances for validation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss function versus the number of epochs. Be sure to include the training and the validation loss in the same plot. Then, create a second plot comparing training and validation accuracy to the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss vs number of epochs with train and val set\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "loss_values = model_val_dict['loss']\n",
    "val_loss_values = model_val_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "ax.plot(epochs, loss_values, label='Training loss')\n",
    "ax.plot(epochs, val_loss_values, label='Validation loss')\n",
    "\n",
    "ax.set_title('Training & validation loss')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend();\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "acc_values = model_val_dict['accuracy'] \n",
    "val_acc_values = model_val_dict['val_accuracy']\n",
    "\n",
    "ax.plot(epochs, acc_values, label='Training acc')\n",
    "ax.plot(epochs, val_acc_values, label='Validation acc')\n",
    "ax.set_title('Training & validation accuracy')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice an interesting pattern here: although the training accuracy keeps increasing when going through more epochs, and the training loss keeps decreasing, the validation accuracy and loss seem to be reaching a limit around the 60th epoch. This means that you're probably **overfitting** the model to the training data when you train for many epochs past this dropoff point of around 40 epochs. Luckily, you learned how to tackle overfitting in the previous lecture! Since it seems clear that you are training too long, include early stopping at the 60th epoch first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping\n",
    "\n",
    "Below, observe how to update the model to include an earlier cutoff point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 1000 samples\n",
      "Epoch 1/60\n",
      "7000/7000 [==============================] - 1s 85us/step - loss: 1.9420 - accuracy: 0.1634 - val_loss: 1.9385 - val_accuracy: 0.1610\n",
      "Epoch 2/60\n",
      "7000/7000 [==============================] - 1s 77us/step - loss: 1.9266 - accuracy: 0.1800 - val_loss: 1.9263 - val_accuracy: 0.1800\n",
      "Epoch 3/60\n",
      "7000/7000 [==============================] - 0s 66us/step - loss: 1.9148 - accuracy: 0.1971 - val_loss: 1.9158 - val_accuracy: 0.1980\n",
      "Epoch 4/60\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 1.9033 - accuracy: 0.2157 - val_loss: 1.9057 - val_accuracy: 0.2030\n",
      "Epoch 5/60\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 1.8913 - accuracy: 0.2319 - val_loss: 1.8947 - val_accuracy: 0.2240\n",
      "Epoch 6/60\n",
      "7000/7000 [==============================] - 1s 96us/step - loss: 1.8785 - accuracy: 0.2500 - val_loss: 1.8826 - val_accuracy: 0.2330\n",
      "Epoch 7/60\n",
      "7000/7000 [==============================] - 1s 91us/step - loss: 1.8642 - accuracy: 0.2701 - val_loss: 1.8686 - val_accuracy: 0.2510\n",
      "Epoch 8/60\n",
      "7000/7000 [==============================] - 1s 76us/step - loss: 1.8475 - accuracy: 0.2887 - val_loss: 1.8520 - val_accuracy: 0.2630\n",
      "Epoch 9/60\n",
      "7000/7000 [==============================] - 1s 75us/step - loss: 1.8279 - accuracy: 0.3119 - val_loss: 1.8305 - val_accuracy: 0.2930\n",
      "Epoch 10/60\n",
      "7000/7000 [==============================] - 1s 77us/step - loss: 1.8033 - accuracy: 0.3501 - val_loss: 1.8001 - val_accuracy: 0.3440\n",
      "Epoch 11/60\n",
      "7000/7000 [==============================] - 1s 74us/step - loss: 1.7703 - accuracy: 0.3971 - val_loss: 1.7618 - val_accuracy: 0.3970\n",
      "Epoch 12/60\n",
      "7000/7000 [==============================] - 1s 74us/step - loss: 1.7312 - accuracy: 0.4377 - val_loss: 1.7177 - val_accuracy: 0.4410\n",
      "Epoch 13/60\n",
      "7000/7000 [==============================] - 1s 75us/step - loss: 1.6872 - accuracy: 0.4707 - val_loss: 1.6681 - val_accuracy: 0.4920\n",
      "Epoch 14/60\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 1.6386 - accuracy: 0.4991 - val_loss: 1.6162 - val_accuracy: 0.5160\n",
      "Epoch 15/60\n",
      "7000/7000 [==============================] - 1s 74us/step - loss: 1.5868 - accuracy: 0.5247 - val_loss: 1.5633 - val_accuracy: 0.5430\n",
      "Epoch 16/60\n",
      "7000/7000 [==============================] - 1s 81us/step - loss: 1.5327 - accuracy: 0.5426 - val_loss: 1.5114 - val_accuracy: 0.5600\n",
      "Epoch 17/60\n",
      "7000/7000 [==============================] - 0s 65us/step - loss: 1.4777 - accuracy: 0.5604 - val_loss: 1.4531 - val_accuracy: 0.5820\n",
      "Epoch 18/60\n",
      "7000/7000 [==============================] - 0s 66us/step - loss: 1.4220 - accuracy: 0.5784 - val_loss: 1.3986 - val_accuracy: 0.6030\n",
      "Epoch 19/60\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 1.3670 - accuracy: 0.5951 - val_loss: 1.3419 - val_accuracy: 0.6070\n",
      "Epoch 20/60\n",
      "7000/7000 [==============================] - 1s 73us/step - loss: 1.3141 - accuracy: 0.6060 - val_loss: 1.2933 - val_accuracy: 0.6210\n",
      "Epoch 21/60\n",
      "7000/7000 [==============================] - 1s 78us/step - loss: 1.2630 - accuracy: 0.6196 - val_loss: 1.2470 - val_accuracy: 0.6290\n",
      "Epoch 22/60\n",
      "7000/7000 [==============================] - 1s 73us/step - loss: 1.2149 - accuracy: 0.6317 - val_loss: 1.1985 - val_accuracy: 0.6420\n",
      "Epoch 23/60\n",
      "7000/7000 [==============================] - 1s 77us/step - loss: 1.1699 - accuracy: 0.6447 - val_loss: 1.1596 - val_accuracy: 0.6470\n",
      "Epoch 24/60\n",
      "7000/7000 [==============================] - 1s 77us/step - loss: 1.1276 - accuracy: 0.6587 - val_loss: 1.1218 - val_accuracy: 0.6550\n",
      "Epoch 25/60\n",
      "7000/7000 [==============================] - 1s 97us/step - loss: 1.0882 - accuracy: 0.6691 - val_loss: 1.0868 - val_accuracy: 0.6610\n",
      "Epoch 26/60\n",
      "7000/7000 [==============================] - 1s 75us/step - loss: 1.0520 - accuracy: 0.6776 - val_loss: 1.0575 - val_accuracy: 0.6620\n",
      "Epoch 27/60\n",
      "7000/7000 [==============================] - 1s 75us/step - loss: 1.0181 - accuracy: 0.6849 - val_loss: 1.0237 - val_accuracy: 0.6660\n",
      "Epoch 28/60\n",
      "7000/7000 [==============================] - 1s 77us/step - loss: 0.9867 - accuracy: 0.6927 - val_loss: 0.9982 - val_accuracy: 0.6770\n",
      "Epoch 29/60\n",
      "7000/7000 [==============================] - 1s 77us/step - loss: 0.9578 - accuracy: 0.7004 - val_loss: 0.9715 - val_accuracy: 0.6850\n",
      "Epoch 30/60\n",
      "7000/7000 [==============================] - 1s 73us/step - loss: 0.9309 - accuracy: 0.7070 - val_loss: 0.9487 - val_accuracy: 0.6950\n",
      "Epoch 31/60\n",
      "7000/7000 [==============================] - 1s 75us/step - loss: 0.9062 - accuracy: 0.7129 - val_loss: 0.9281 - val_accuracy: 0.7040\n",
      "Epoch 32/60\n",
      "7000/7000 [==============================] - 1s 75us/step - loss: 0.8831 - accuracy: 0.7196 - val_loss: 0.9106 - val_accuracy: 0.7010\n",
      "Epoch 33/60\n",
      "7000/7000 [==============================] - 0s 71us/step - loss: 0.8616 - accuracy: 0.7260 - val_loss: 0.8881 - val_accuracy: 0.7080\n",
      "Epoch 34/60\n",
      "7000/7000 [==============================] - 1s 74us/step - loss: 0.8414 - accuracy: 0.7297 - val_loss: 0.8729 - val_accuracy: 0.7150\n",
      "Epoch 35/60\n",
      "7000/7000 [==============================] - 1s 71us/step - loss: 0.8229 - accuracy: 0.7349 - val_loss: 0.8593 - val_accuracy: 0.7200\n",
      "Epoch 36/60\n",
      "7000/7000 [==============================] - 1s 75us/step - loss: 0.8051 - accuracy: 0.7396 - val_loss: 0.8480 - val_accuracy: 0.7240\n",
      "Epoch 37/60\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 0.7890 - accuracy: 0.7447 - val_loss: 0.8310 - val_accuracy: 0.7270\n",
      "Epoch 38/60\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 0.7733 - accuracy: 0.7467 - val_loss: 0.8206 - val_accuracy: 0.7300\n",
      "Epoch 39/60\n",
      "7000/7000 [==============================] - 0s 71us/step - loss: 0.7592 - accuracy: 0.7510 - val_loss: 0.8095 - val_accuracy: 0.7300\n",
      "Epoch 40/60\n",
      "7000/7000 [==============================] - 0s 71us/step - loss: 0.7451 - accuracy: 0.7541 - val_loss: 0.7989 - val_accuracy: 0.7360\n",
      "Epoch 41/60\n",
      "7000/7000 [==============================] - 0s 66us/step - loss: 0.7323 - accuracy: 0.7579 - val_loss: 0.7967 - val_accuracy: 0.7270\n",
      "Epoch 42/60\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 0.7205 - accuracy: 0.7623 - val_loss: 0.7871 - val_accuracy: 0.7330\n",
      "Epoch 43/60\n",
      "7000/7000 [==============================] - 0s 71us/step - loss: 0.7086 - accuracy: 0.7634 - val_loss: 0.7760 - val_accuracy: 0.7360\n",
      "Epoch 44/60\n",
      "7000/7000 [==============================] - 1s 102us/step - loss: 0.6977 - accuracy: 0.7684 - val_loss: 0.7681 - val_accuracy: 0.7360\n",
      "Epoch 45/60\n",
      "7000/7000 [==============================] - 1s 75us/step - loss: 0.6871 - accuracy: 0.7707 - val_loss: 0.7599 - val_accuracy: 0.7410\n",
      "Epoch 46/60\n",
      "7000/7000 [==============================] - 1s 107us/step - loss: 0.6765 - accuracy: 0.7729 - val_loss: 0.7556 - val_accuracy: 0.7420\n",
      "Epoch 47/60\n",
      "7000/7000 [==============================] - 1s 82us/step - loss: 0.6671 - accuracy: 0.7757 - val_loss: 0.7454 - val_accuracy: 0.7400\n",
      "Epoch 48/60\n",
      "7000/7000 [==============================] - 0s 66us/step - loss: 0.6582 - accuracy: 0.7777 - val_loss: 0.7467 - val_accuracy: 0.7430\n",
      "Epoch 49/60\n",
      "7000/7000 [==============================] - 1s 95us/step - loss: 0.6492 - accuracy: 0.7814 - val_loss: 0.7413 - val_accuracy: 0.7400\n",
      "Epoch 50/60\n",
      "7000/7000 [==============================] - 1s 85us/step - loss: 0.6406 - accuracy: 0.7844 - val_loss: 0.7314 - val_accuracy: 0.7480\n",
      "Epoch 51/60\n",
      "7000/7000 [==============================] - 1s 85us/step - loss: 0.6326 - accuracy: 0.7863 - val_loss: 0.7245 - val_accuracy: 0.7480\n",
      "Epoch 52/60\n",
      "7000/7000 [==============================] - 1s 81us/step - loss: 0.6251 - accuracy: 0.7894 - val_loss: 0.7252 - val_accuracy: 0.7500\n",
      "Epoch 53/60\n",
      "7000/7000 [==============================] - 1s 80us/step - loss: 0.6174 - accuracy: 0.7926 - val_loss: 0.7195 - val_accuracy: 0.7470\n",
      "Epoch 54/60\n",
      "7000/7000 [==============================] - 1s 81us/step - loss: 0.6102 - accuracy: 0.7954 - val_loss: 0.7127 - val_accuracy: 0.7510\n",
      "Epoch 55/60\n",
      "7000/7000 [==============================] - 1s 75us/step - loss: 0.6024 - accuracy: 0.7977 - val_loss: 0.7116 - val_accuracy: 0.7570\n",
      "Epoch 56/60\n",
      "7000/7000 [==============================] - 1s 86us/step - loss: 0.5958 - accuracy: 0.8003 - val_loss: 0.7062 - val_accuracy: 0.7510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/60\n",
      "7000/7000 [==============================] - 0s 67us/step - loss: 0.5892 - accuracy: 0.8036 - val_loss: 0.7041 - val_accuracy: 0.7550\n",
      "Epoch 58/60\n",
      "7000/7000 [==============================] - 1s 79us/step - loss: 0.5825 - accuracy: 0.8036 - val_loss: 0.7045 - val_accuracy: 0.7480\n",
      "Epoch 59/60\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 0.5768 - accuracy: 0.8061 - val_loss: 0.6967 - val_accuracy: 0.7520\n",
      "Epoch 60/60\n",
      "7000/7000 [==============================] - 1s 75us/step - loss: 0.5701 - accuracy: 0.8079 - val_loss: 0.6941 - val_accuracy: 0.7530\n"
     ]
    }
   ],
   "source": [
    "random.seed(123)\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(50, activation='relu', input_shape=(2000,))) #2 hidden layers\n",
    "model.add(keras.layers.Dense(25, activation='relu'))\n",
    "model.add(keras.layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "final_model = model.fit(X_train_tokenized,\n",
    "                    y_train_bin,\n",
    "                    epochs=60,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can use the test set to make label predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 1s 117us/step\n",
      "Training Loss: 0.564 Training Accuracy: 0.811\n",
      "2000/2000 [==============================] - 0s 126us/step\n",
      "Testing Loss: 0.708 Testing Accuracy: 0.742\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(X_train_tokenized, y_train_bin)\n",
    "print(f'Training Loss: {results_train[0]:.3} Training Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "results_test = model.evaluate(X_test_tok, y_test_cat)\n",
    "print(f'Testing Loss: {results_test[0]:.3} Testing Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've significantly reduced the variance, so this is already pretty good! your test set accuracy is slightly worse, but this model will definitely be more robust than the 120 epochs model you originally fit.\n",
    "\n",
    "Now, take a look at how regularization techniques can further improve your model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, take a look at L2 regularization. Keras makes L2 regularization easy. Simply add the `kernel_regularizer=keras.regularizers.l2(lambda_coeff)` parameter to any model layer. The `lambda_coeff` parameter determines the strength of the regularization you wish to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 1000 samples\n",
      "Epoch 1/120\n",
      "7000/7000 [==============================] - 1s 160us/step - loss: 2.5959 - accuracy: 0.1563 - val_loss: 2.5749 - val_accuracy: 0.1700\n",
      "Epoch 2/120\n",
      "7000/7000 [==============================] - 1s 123us/step - loss: 2.5671 - accuracy: 0.1826 - val_loss: 2.5533 - val_accuracy: 0.2000\n",
      "Epoch 3/120\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 2.5449 - accuracy: 0.2039 - val_loss: 2.5341 - val_accuracy: 0.2150\n",
      "Epoch 4/120\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 2.5242 - accuracy: 0.2246 - val_loss: 2.5150 - val_accuracy: 0.2460\n",
      "Epoch 5/120\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 2.5028 - accuracy: 0.2514 - val_loss: 2.4941 - val_accuracy: 0.2650\n",
      "Epoch 6/120\n",
      "7000/7000 [==============================] - 1s 96us/step - loss: 2.4798 - accuracy: 0.2753 - val_loss: 2.4692 - val_accuracy: 0.2940\n",
      "Epoch 7/120\n",
      "7000/7000 [==============================] - 1s 71us/step - loss: 2.4538 - accuracy: 0.2906 - val_loss: 2.4416 - val_accuracy: 0.3120\n",
      "Epoch 8/120\n",
      "7000/7000 [==============================] - 0s 71us/step - loss: 2.4246 - accuracy: 0.3127 - val_loss: 2.4102 - val_accuracy: 0.3220\n",
      "Epoch 9/120\n",
      "7000/7000 [==============================] - 1s 74us/step - loss: 2.3920 - accuracy: 0.3330 - val_loss: 2.3752 - val_accuracy: 0.3520\n",
      "Epoch 10/120\n",
      "7000/7000 [==============================] - 1s 71us/step - loss: 2.3563 - accuracy: 0.3550 - val_loss: 2.3366 - val_accuracy: 0.3660\n",
      "Epoch 11/120\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 2.3176 - accuracy: 0.3736 - val_loss: 2.2949 - val_accuracy: 0.3920\n",
      "Epoch 12/120\n",
      "7000/7000 [==============================] - 0s 71us/step - loss: 2.2759 - accuracy: 0.3956 - val_loss: 2.2495 - val_accuracy: 0.4100\n",
      "Epoch 13/120\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 2.2309 - accuracy: 0.4184 - val_loss: 2.2023 - val_accuracy: 0.4410\n",
      "Epoch 14/120\n",
      "7000/7000 [==============================] - 1s 73us/step - loss: 2.1847 - accuracy: 0.4399 - val_loss: 2.1563 - val_accuracy: 0.4690\n",
      "Epoch 15/120\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 2.1377 - accuracy: 0.4711 - val_loss: 2.1110 - val_accuracy: 0.4960\n",
      "Epoch 16/120\n",
      "7000/7000 [==============================] - 1s 72us/step - loss: 2.0910 - accuracy: 0.4996 - val_loss: 2.0652 - val_accuracy: 0.5160\n",
      "Epoch 17/120\n",
      "7000/7000 [==============================] - 1s 72us/step - loss: 2.0446 - accuracy: 0.5216 - val_loss: 2.0192 - val_accuracy: 0.5180\n",
      "Epoch 18/120\n",
      "7000/7000 [==============================] - 1s 73us/step - loss: 1.9989 - accuracy: 0.5441 - val_loss: 1.9768 - val_accuracy: 0.5630\n",
      "Epoch 19/120\n",
      "7000/7000 [==============================] - 0s 67us/step - loss: 1.9540 - accuracy: 0.5709 - val_loss: 1.9351 - val_accuracy: 0.5770\n",
      "Epoch 20/120\n",
      "7000/7000 [==============================] - 1s 74us/step - loss: 1.9101 - accuracy: 0.5879 - val_loss: 1.8943 - val_accuracy: 0.5900\n",
      "Epoch 21/120\n",
      "7000/7000 [==============================] - 1s 77us/step - loss: 1.8676 - accuracy: 0.6077 - val_loss: 1.8530 - val_accuracy: 0.6060\n",
      "Epoch 22/120\n",
      "7000/7000 [==============================] - 1s 73us/step - loss: 1.8262 - accuracy: 0.6253 - val_loss: 1.8149 - val_accuracy: 0.6240\n",
      "Epoch 23/120\n",
      "7000/7000 [==============================] - 1s 75us/step - loss: 1.7866 - accuracy: 0.6406 - val_loss: 1.7769 - val_accuracy: 0.6270\n",
      "Epoch 24/120\n",
      "7000/7000 [==============================] - 1s 109us/step - loss: 1.7487 - accuracy: 0.6456 - val_loss: 1.7428 - val_accuracy: 0.6420\n",
      "Epoch 25/120\n",
      "7000/7000 [==============================] - 1s 95us/step - loss: 1.7128 - accuracy: 0.6580 - val_loss: 1.7103 - val_accuracy: 0.6530\n",
      "Epoch 26/120\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 1.6780 - accuracy: 0.6684 - val_loss: 1.6796 - val_accuracy: 0.6580\n",
      "Epoch 27/120\n",
      "7000/7000 [==============================] - 1s 80us/step - loss: 1.6455 - accuracy: 0.6773 - val_loss: 1.6486 - val_accuracy: 0.6640\n",
      "Epoch 28/120\n",
      "7000/7000 [==============================] - 1s 75us/step - loss: 1.6150 - accuracy: 0.6840 - val_loss: 1.6243 - val_accuracy: 0.6730\n",
      "Epoch 29/120\n",
      "7000/7000 [==============================] - 1s 74us/step - loss: 1.5865 - accuracy: 0.6951 - val_loss: 1.5965 - val_accuracy: 0.6730\n",
      "Epoch 30/120\n",
      "7000/7000 [==============================] - 1s 76us/step - loss: 1.5597 - accuracy: 0.7001 - val_loss: 1.5719 - val_accuracy: 0.6850\n",
      "Epoch 31/120\n",
      "7000/7000 [==============================] - 1s 73us/step - loss: 1.5345 - accuracy: 0.7064 - val_loss: 1.5512 - val_accuracy: 0.6940\n",
      "Epoch 32/120\n",
      "7000/7000 [==============================] - 1s 73us/step - loss: 1.5110 - accuracy: 0.7117 - val_loss: 1.5286 - val_accuracy: 0.6940\n",
      "Epoch 33/120\n",
      "7000/7000 [==============================] - 1s 76us/step - loss: 1.4886 - accuracy: 0.7144 - val_loss: 1.5071 - val_accuracy: 0.7050\n",
      "Epoch 34/120\n",
      "7000/7000 [==============================] - 1s 75us/step - loss: 1.4680 - accuracy: 0.7191 - val_loss: 1.4925 - val_accuracy: 0.7040\n",
      "Epoch 35/120\n",
      "7000/7000 [==============================] - 1s 104us/step - loss: 1.4484 - accuracy: 0.7221 - val_loss: 1.4762 - val_accuracy: 0.7020\n",
      "Epoch 36/120\n",
      "7000/7000 [==============================] - 1s 147us/step - loss: 1.4301 - accuracy: 0.7249 - val_loss: 1.4602 - val_accuracy: 0.7120\n",
      "Epoch 37/120\n",
      "7000/7000 [==============================] - 1s 114us/step - loss: 1.4126 - accuracy: 0.7276 - val_loss: 1.4436 - val_accuracy: 0.7170\n",
      "Epoch 38/120\n",
      "7000/7000 [==============================] - 1s 108us/step - loss: 1.3963 - accuracy: 0.7341 - val_loss: 1.4303 - val_accuracy: 0.7220\n",
      "Epoch 39/120\n",
      "7000/7000 [==============================] - 1s 105us/step - loss: 1.3809 - accuracy: 0.7363 - val_loss: 1.4163 - val_accuracy: 0.7260\n",
      "Epoch 40/120\n",
      "7000/7000 [==============================] - 1s 118us/step - loss: 1.3659 - accuracy: 0.7404 - val_loss: 1.4025 - val_accuracy: 0.7260\n",
      "Epoch 41/120\n",
      "7000/7000 [==============================] - 1s 87us/step - loss: 1.3522 - accuracy: 0.7451 - val_loss: 1.3913 - val_accuracy: 0.7250\n",
      "Epoch 42/120\n",
      "7000/7000 [==============================] - 1s 85us/step - loss: 1.3388 - accuracy: 0.7474 - val_loss: 1.3809 - val_accuracy: 0.7300\n",
      "Epoch 43/120\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 1.3261 - accuracy: 0.7509 - val_loss: 1.3721 - val_accuracy: 0.7340\n",
      "Epoch 44/120\n",
      "7000/7000 [==============================] - 0s 67us/step - loss: 1.3139 - accuracy: 0.7536 - val_loss: 1.3635 - val_accuracy: 0.7380\n",
      "Epoch 45/120\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 1.3018 - accuracy: 0.7563 - val_loss: 1.3525 - val_accuracy: 0.7450\n",
      "Epoch 46/120\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 1.2911 - accuracy: 0.7599 - val_loss: 1.3442 - val_accuracy: 0.7340\n",
      "Epoch 47/120\n",
      "7000/7000 [==============================] - 0s 66us/step - loss: 1.2803 - accuracy: 0.7617 - val_loss: 1.3361 - val_accuracy: 0.7370\n",
      "Epoch 48/120\n",
      "7000/7000 [==============================] - 0s 66us/step - loss: 1.2699 - accuracy: 0.7644 - val_loss: 1.3277 - val_accuracy: 0.7450\n",
      "Epoch 49/120\n",
      "7000/7000 [==============================] - 0s 65us/step - loss: 1.2595 - accuracy: 0.7670 - val_loss: 1.3188 - val_accuracy: 0.7460\n",
      "Epoch 50/120\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 1.2501 - accuracy: 0.7684 - val_loss: 1.3128 - val_accuracy: 0.7460\n",
      "Epoch 51/120\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 1.2404 - accuracy: 0.7716 - val_loss: 1.3052 - val_accuracy: 0.7510\n",
      "Epoch 52/120\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 1.2317 - accuracy: 0.7737 - val_loss: 1.2979 - val_accuracy: 0.7500\n",
      "Epoch 53/120\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 1.2228 - accuracy: 0.7767 - val_loss: 1.2922 - val_accuracy: 0.7480\n",
      "Epoch 54/120\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 1.2139 - accuracy: 0.7770 - val_loss: 1.2835 - val_accuracy: 0.7540\n",
      "Epoch 55/120\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.2055 - accuracy: 0.7820 - val_loss: 1.2812 - val_accuracy: 0.7540\n",
      "Epoch 56/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 0s 58us/step - loss: 1.1974 - accuracy: 0.7837 - val_loss: 1.2735 - val_accuracy: 0.7560\n",
      "Epoch 57/120\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 1.1894 - accuracy: 0.7876 - val_loss: 1.2702 - val_accuracy: 0.7530\n",
      "Epoch 58/120\n",
      "7000/7000 [==============================] - 0s 65us/step - loss: 1.1820 - accuracy: 0.7891 - val_loss: 1.2633 - val_accuracy: 0.7540\n",
      "Epoch 59/120\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 1.1742 - accuracy: 0.7897 - val_loss: 1.2579 - val_accuracy: 0.7550\n",
      "Epoch 60/120\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 1.1671 - accuracy: 0.7906 - val_loss: 1.2530 - val_accuracy: 0.7620\n",
      "Epoch 61/120\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 1.1595 - accuracy: 0.7957 - val_loss: 1.2458 - val_accuracy: 0.7660\n",
      "Epoch 62/120\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 1.1528 - accuracy: 0.7971 - val_loss: 1.2404 - val_accuracy: 0.7640\n",
      "Epoch 63/120\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 1.1454 - accuracy: 0.7994 - val_loss: 1.2374 - val_accuracy: 0.7580\n",
      "Epoch 64/120\n",
      "7000/7000 [==============================] - 0s 71us/step - loss: 1.1388 - accuracy: 0.8009 - val_loss: 1.2329 - val_accuracy: 0.7660\n",
      "Epoch 65/120\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 1.1321 - accuracy: 0.8030 - val_loss: 1.2282 - val_accuracy: 0.7660\n",
      "Epoch 66/120\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 1.1252 - accuracy: 0.8064 - val_loss: 1.2247 - val_accuracy: 0.7620\n",
      "Epoch 67/120\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 1.1191 - accuracy: 0.8079 - val_loss: 1.2199 - val_accuracy: 0.7690\n",
      "Epoch 68/120\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 1.1126 - accuracy: 0.8093 - val_loss: 1.2193 - val_accuracy: 0.7610\n",
      "Epoch 69/120\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 1.1064 - accuracy: 0.8127 - val_loss: 1.2118 - val_accuracy: 0.7670\n",
      "Epoch 70/120\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 1.1001 - accuracy: 0.8111 - val_loss: 1.2091 - val_accuracy: 0.7680\n",
      "Epoch 71/120\n",
      "7000/7000 [==============================] - 0s 71us/step - loss: 1.0943 - accuracy: 0.8130 - val_loss: 1.2036 - val_accuracy: 0.7670\n",
      "Epoch 72/120\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 1.0884 - accuracy: 0.8144 - val_loss: 1.2022 - val_accuracy: 0.7640\n",
      "Epoch 73/120\n",
      "7000/7000 [==============================] - 1s 74us/step - loss: 1.0822 - accuracy: 0.8163 - val_loss: 1.1970 - val_accuracy: 0.7700\n",
      "Epoch 74/120\n",
      "7000/7000 [==============================] - 1s 102us/step - loss: 1.0768 - accuracy: 0.8180 - val_loss: 1.1922 - val_accuracy: 0.7700\n",
      "Epoch 75/120\n",
      "7000/7000 [==============================] - 1s 78us/step - loss: 1.0708 - accuracy: 0.8194 - val_loss: 1.1892 - val_accuracy: 0.7710\n",
      "Epoch 76/120\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 1.0650 - accuracy: 0.8217 - val_loss: 1.1859 - val_accuracy: 0.7720\n",
      "Epoch 77/120\n",
      "7000/7000 [==============================] - 0s 66us/step - loss: 1.0597 - accuracy: 0.8217 - val_loss: 1.1861 - val_accuracy: 0.7690\n",
      "Epoch 78/120\n",
      "7000/7000 [==============================] - 1s 81us/step - loss: 1.0541 - accuracy: 0.8253 - val_loss: 1.1840 - val_accuracy: 0.7630\n",
      "Epoch 79/120\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 1.0491 - accuracy: 0.8246 - val_loss: 1.1787 - val_accuracy: 0.7700\n",
      "Epoch 80/120\n",
      "7000/7000 [==============================] - 1s 79us/step - loss: 1.0434 - accuracy: 0.8276 - val_loss: 1.1733 - val_accuracy: 0.7720\n",
      "Epoch 81/120\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.0386 - accuracy: 0.8279 - val_loss: 1.1683 - val_accuracy: 0.7750\n",
      "Epoch 82/120\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 1.0333 - accuracy: 0.8294 - val_loss: 1.1668 - val_accuracy: 0.7720\n",
      "Epoch 83/120\n",
      "7000/7000 [==============================] - 1s 79us/step - loss: 1.0278 - accuracy: 0.8306 - val_loss: 1.1658 - val_accuracy: 0.7700\n",
      "Epoch 84/120\n",
      "7000/7000 [==============================] - 1s 77us/step - loss: 1.0228 - accuracy: 0.8334 - val_loss: 1.1635 - val_accuracy: 0.7650\n",
      "Epoch 85/120\n",
      "7000/7000 [==============================] - 1s 73us/step - loss: 1.0180 - accuracy: 0.8369 - val_loss: 1.1582 - val_accuracy: 0.7760\n",
      "Epoch 86/120\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 1.0129 - accuracy: 0.8371 - val_loss: 1.1612 - val_accuracy: 0.7610\n",
      "Epoch 87/120\n",
      "7000/7000 [==============================] - 0s 66us/step - loss: 1.0084 - accuracy: 0.8374 - val_loss: 1.1569 - val_accuracy: 0.7690\n",
      "Epoch 88/120\n",
      "7000/7000 [==============================] - 1s 72us/step - loss: 1.0030 - accuracy: 0.8346 - val_loss: 1.1565 - val_accuracy: 0.7610\n",
      "Epoch 89/120\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.9986 - accuracy: 0.8426 - val_loss: 1.1498 - val_accuracy: 0.7660\n",
      "Epoch 90/120\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.9937 - accuracy: 0.8406 - val_loss: 1.1439 - val_accuracy: 0.7730\n",
      "Epoch 91/120\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 0.9889 - accuracy: 0.8421 - val_loss: 1.1453 - val_accuracy: 0.7660\n",
      "Epoch 92/120\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.9844 - accuracy: 0.8429 - val_loss: 1.1414 - val_accuracy: 0.7730\n",
      "Epoch 93/120\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.9797 - accuracy: 0.8447 - val_loss: 1.1393 - val_accuracy: 0.7700\n",
      "Epoch 94/120\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.9751 - accuracy: 0.8501 - val_loss: 1.1342 - val_accuracy: 0.7720\n",
      "Epoch 95/120\n",
      "7000/7000 [==============================] - 1s 83us/step - loss: 0.9705 - accuracy: 0.8477 - val_loss: 1.1340 - val_accuracy: 0.7700\n",
      "Epoch 96/120\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 0.9661 - accuracy: 0.8510 - val_loss: 1.1302 - val_accuracy: 0.7670\n",
      "Epoch 97/120\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 0.9616 - accuracy: 0.8506 - val_loss: 1.1284 - val_accuracy: 0.7720\n",
      "Epoch 98/120\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 0.9573 - accuracy: 0.8503 - val_loss: 1.1261 - val_accuracy: 0.7670\n",
      "Epoch 99/120\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.9533 - accuracy: 0.8539 - val_loss: 1.1273 - val_accuracy: 0.7610\n",
      "Epoch 100/120\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.9486 - accuracy: 0.8536 - val_loss: 1.1208 - val_accuracy: 0.7690\n",
      "Epoch 101/120\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.9449 - accuracy: 0.8549 - val_loss: 1.1193 - val_accuracy: 0.7670\n",
      "Epoch 102/120\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.9404 - accuracy: 0.8571 - val_loss: 1.1197 - val_accuracy: 0.7670\n",
      "Epoch 103/120\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.9362 - accuracy: 0.8586 - val_loss: 1.1158 - val_accuracy: 0.7710\n",
      "Epoch 104/120\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.9322 - accuracy: 0.8610 - val_loss: 1.1129 - val_accuracy: 0.7700\n",
      "Epoch 105/120\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.9281 - accuracy: 0.8601 - val_loss: 1.1083 - val_accuracy: 0.7700\n",
      "Epoch 106/120\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.9240 - accuracy: 0.8606 - val_loss: 1.1098 - val_accuracy: 0.7720\n",
      "Epoch 107/120\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.9197 - accuracy: 0.8633 - val_loss: 1.1073 - val_accuracy: 0.7700\n",
      "Epoch 108/120\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.9160 - accuracy: 0.8634 - val_loss: 1.1063 - val_accuracy: 0.7700\n",
      "Epoch 109/120\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.9121 - accuracy: 0.8647 - val_loss: 1.1047 - val_accuracy: 0.7690\n",
      "Epoch 110/120\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.9080 - accuracy: 0.8659 - val_loss: 1.1002 - val_accuracy: 0.7700\n",
      "Epoch 111/120\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.9046 - accuracy: 0.8664 - val_loss: 1.0985 - val_accuracy: 0.7690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/120\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.9000 - accuracy: 0.8679 - val_loss: 1.0975 - val_accuracy: 0.7730\n",
      "Epoch 113/120\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8964 - accuracy: 0.8691 - val_loss: 1.0935 - val_accuracy: 0.7720\n",
      "Epoch 114/120\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.8925 - accuracy: 0.8680 - val_loss: 1.0941 - val_accuracy: 0.7710\n",
      "Epoch 115/120\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.8888 - accuracy: 0.8697 - val_loss: 1.0914 - val_accuracy: 0.7680\n",
      "Epoch 116/120\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.8850 - accuracy: 0.8716 - val_loss: 1.0922 - val_accuracy: 0.7700\n",
      "Epoch 117/120\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.8813 - accuracy: 0.8716 - val_loss: 1.0885 - val_accuracy: 0.7680\n",
      "Epoch 118/120\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8772 - accuracy: 0.8749 - val_loss: 1.0835 - val_accuracy: 0.7720\n",
      "Epoch 119/120\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.8741 - accuracy: 0.8743 - val_loss: 1.0820 - val_accuracy: 0.7730\n",
      "Epoch 120/120\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.8704 - accuracy: 0.8759 - val_loss: 1.0850 - val_accuracy: 0.7670\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "random.seed(123)\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(50, activation='relu',kernel_regularizer=regularizers.l2(0.005), input_shape=(2000,))) #2 hidden layers\n",
    "model.add(keras.layers.Dense(25, kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(keras.layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "L2_model = model.fit(X_train_tokenized,\n",
    "                    y_train_bin,\n",
    "                    epochs=120,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L2_model_dict = L2_model.history\n",
    "L2_model_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, look at the training accuracy as well as the validation accuracy for both the L2 and the model without regularization (for 120 epochs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "acc_values = L2_model_dict['accuracy'] \n",
    "val_acc_values = L2_model_dict['val_accuracy']\n",
    "model_acc = model_val_dict['accuracy']\n",
    "model_val_acc = model_val_dict['val_accuracy']\n",
    "\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "ax.plot(epochs, acc_values, label='Training acc L2')\n",
    "ax.plot(epochs, val_acc_values, label='Validation acc L2')\n",
    "ax.plot(epochs, model_acc, label='Training acc')\n",
    "ax.plot(epochs, model_val_acc, label='Validation acc')\n",
    "ax.set_title('Training & validation accuracy L2 vs regular')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of L2 regularization are quite disappointing here. Notice the discrepancy between validation and training accuracy seems to have decreased slightly, but the end result is definitely not getting better. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at L1 regularization. Will this work better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 1000 samples\n",
      "Epoch 1/120\n",
      "7000/7000 [==============================] - 4s 537us/step - loss: 15.9552 - accuracy: 0.2124 - val_loss: 15.5659 - val_accuracy: 0.2520\n",
      "Epoch 2/120\n",
      "7000/7000 [==============================] - 2s 345us/step - loss: 15.2470 - accuracy: 0.2367 - val_loss: 14.8697 - val_accuracy: 0.2640\n",
      "Epoch 3/120\n",
      "7000/7000 [==============================] - 2s 283us/step - loss: 14.5583 - accuracy: 0.2527 - val_loss: 14.1926 - val_accuracy: 0.2830\n",
      "Epoch 4/120\n",
      "7000/7000 [==============================] - 3s 363us/step - loss: 13.8884 - accuracy: 0.2807 - val_loss: 13.5309 - val_accuracy: 0.3090\n",
      "Epoch 5/120\n",
      "7000/7000 [==============================] - 2s 304us/step - loss: 13.2359 - accuracy: 0.3004 - val_loss: 12.8871 - val_accuracy: 0.3370\n",
      "Epoch 6/120\n",
      "7000/7000 [==============================] - 3s 422us/step - loss: 12.6012 - accuracy: 0.3180 - val_loss: 12.2590 - val_accuracy: 0.3650\n",
      "Epoch 7/120\n",
      "7000/7000 [==============================] - 2s 308us/step - loss: 11.9833 - accuracy: 0.3396 - val_loss: 11.6503 - val_accuracy: 0.3810\n",
      "Epoch 8/120\n",
      "7000/7000 [==============================] - 2s 306us/step - loss: 11.3826 - accuracy: 0.3663 - val_loss: 11.0550 - val_accuracy: 0.4000\n",
      "Epoch 9/120\n",
      "7000/7000 [==============================] - 2s 318us/step - loss: 10.7984 - accuracy: 0.3907 - val_loss: 10.4789 - val_accuracy: 0.4190\n",
      "Epoch 10/120\n",
      "7000/7000 [==============================] - 2s 308us/step - loss: 10.2313 - accuracy: 0.4140 - val_loss: 9.9220 - val_accuracy: 0.4450\n",
      "Epoch 11/120\n",
      "7000/7000 [==============================] - 2s 347us/step - loss: 9.6819 - accuracy: 0.4410 - val_loss: 9.3818 - val_accuracy: 0.4700\n",
      "Epoch 12/120\n",
      "7000/7000 [==============================] - 2s 291us/step - loss: 9.1513 - accuracy: 0.4649 - val_loss: 8.8624 - val_accuracy: 0.4950\n",
      "Epoch 13/120\n",
      "7000/7000 [==============================] - 2s 309us/step - loss: 8.6398 - accuracy: 0.4883 - val_loss: 8.3625 - val_accuracy: 0.5010\n",
      "Epoch 14/120\n",
      "7000/7000 [==============================] - 2s 324us/step - loss: 8.1485 - accuracy: 0.5004 - val_loss: 7.8836 - val_accuracy: 0.5160\n",
      "Epoch 15/120\n",
      "7000/7000 [==============================] - 3s 390us/step - loss: 7.6774 - accuracy: 0.5146 - val_loss: 7.4233 - val_accuracy: 0.5320\n",
      "Epoch 16/120\n",
      "7000/7000 [==============================] - 2s 342us/step - loss: 7.2267 - accuracy: 0.5280 - val_loss: 6.9849 - val_accuracy: 0.5420\n",
      "Epoch 17/120\n",
      "7000/7000 [==============================] - 2s 317us/step - loss: 6.7958 - accuracy: 0.5419 - val_loss: 6.5655 - val_accuracy: 0.5520\n",
      "Epoch 18/120\n",
      "7000/7000 [==============================] - 2s 293us/step - loss: 6.3849 - accuracy: 0.5497 - val_loss: 6.1657 - val_accuracy: 0.5620\n",
      "Epoch 19/120\n",
      "7000/7000 [==============================] - 2s 299us/step - loss: 5.9937 - accuracy: 0.5569 - val_loss: 5.7857 - val_accuracy: 0.5860\n",
      "Epoch 20/120\n",
      "7000/7000 [==============================] - 2s 296us/step - loss: 5.6225 - accuracy: 0.5721 - val_loss: 5.4254 - val_accuracy: 0.5770\n",
      "Epoch 21/120\n",
      "7000/7000 [==============================] - 2s 301us/step - loss: 5.2709 - accuracy: 0.5770 - val_loss: 5.0841 - val_accuracy: 0.5890\n",
      "Epoch 22/120\n",
      "7000/7000 [==============================] - 2s 309us/step - loss: 4.9389 - accuracy: 0.5837 - val_loss: 4.7644 - val_accuracy: 0.6000\n",
      "Epoch 23/120\n",
      "7000/7000 [==============================] - 2s 305us/step - loss: 4.6264 - accuracy: 0.5903 - val_loss: 4.4615 - val_accuracy: 0.6000\n",
      "Epoch 24/120\n",
      "7000/7000 [==============================] - 2s 310us/step - loss: 4.3329 - accuracy: 0.5969 - val_loss: 4.1781 - val_accuracy: 0.6000\n",
      "Epoch 25/120\n",
      "7000/7000 [==============================] - 2s 313us/step - loss: 4.0585 - accuracy: 0.6014 - val_loss: 3.9137 - val_accuracy: 0.5990\n",
      "Epoch 26/120\n",
      "7000/7000 [==============================] - 2s 315us/step - loss: 3.8040 - accuracy: 0.6037 - val_loss: 3.6692 - val_accuracy: 0.6080\n",
      "Epoch 27/120\n",
      "7000/7000 [==============================] - 2s 317us/step - loss: 3.5678 - accuracy: 0.6100 - val_loss: 3.4441 - val_accuracy: 0.6150\n",
      "Epoch 28/120\n",
      "7000/7000 [==============================] - 1s 97us/step - loss: 3.3508 - accuracy: 0.6161 - val_loss: 3.2360 - val_accuracy: 0.6100\n",
      "Epoch 29/120\n",
      "7000/7000 [==============================] - 0s 71us/step - loss: 3.1524 - accuracy: 0.6181 - val_loss: 3.0478 - val_accuracy: 0.6150\n",
      "Epoch 30/120\n",
      "7000/7000 [==============================] - 1s 72us/step - loss: 2.9728 - accuracy: 0.6204 - val_loss: 2.8778 - val_accuracy: 0.6090\n",
      "Epoch 31/120\n",
      "7000/7000 [==============================] - 0s 65us/step - loss: 2.8109 - accuracy: 0.6226 - val_loss: 2.7228 - val_accuracy: 0.6160\n",
      "Epoch 32/120\n",
      "7000/7000 [==============================] - 0s 67us/step - loss: 2.6676 - accuracy: 0.6279 - val_loss: 2.5892 - val_accuracy: 0.6170\n",
      "Epoch 33/120\n",
      "7000/7000 [==============================] - 0s 71us/step - loss: 2.5420 - accuracy: 0.6286 - val_loss: 2.4708 - val_accuracy: 0.6300\n",
      "Epoch 34/120\n",
      "7000/7000 [==============================] - 1s 72us/step - loss: 2.4333 - accuracy: 0.6356 - val_loss: 2.3701 - val_accuracy: 0.6270\n",
      "Epoch 35/120\n",
      "7000/7000 [==============================] - 1s 96us/step - loss: 2.3411 - accuracy: 0.6351 - val_loss: 2.2865 - val_accuracy: 0.6360\n",
      "Epoch 36/120\n",
      "7000/7000 [==============================] - 1s 84us/step - loss: 2.2650 - accuracy: 0.6366 - val_loss: 2.2184 - val_accuracy: 0.6410\n",
      "Epoch 37/120\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 2.2041 - accuracy: 0.6461 - val_loss: 2.1623 - val_accuracy: 0.6370\n",
      "Epoch 38/120\n",
      "7000/7000 [==============================] - 0s 71us/step - loss: 2.1569 - accuracy: 0.6450 - val_loss: 2.1233 - val_accuracy: 0.6360\n",
      "Epoch 39/120\n",
      "7000/7000 [==============================] - 0s 65us/step - loss: 2.1218 - accuracy: 0.6444 - val_loss: 2.0904 - val_accuracy: 0.6540\n",
      "Epoch 40/120\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 2.0941 - accuracy: 0.6507 - val_loss: 2.0658 - val_accuracy: 0.6440\n",
      "Epoch 41/120\n",
      "7000/7000 [==============================] - 0s 66us/step - loss: 2.0701 - accuracy: 0.6516 - val_loss: 2.0430 - val_accuracy: 0.6570\n",
      "Epoch 42/120\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 2.0488 - accuracy: 0.6526 - val_loss: 2.0236 - val_accuracy: 0.6590\n",
      "Epoch 43/120\n",
      "7000/7000 [==============================] - 0s 53us/step - loss: 2.0293 - accuracy: 0.6577 - val_loss: 2.0028 - val_accuracy: 0.6640\n",
      "Epoch 44/120\n",
      "7000/7000 [==============================] - 0s 50us/step - loss: 2.0104 - accuracy: 0.6610 - val_loss: 1.9829 - val_accuracy: 0.6650\n",
      "Epoch 45/120\n",
      "7000/7000 [==============================] - 0s 51us/step - loss: 1.9927 - accuracy: 0.6617 - val_loss: 1.9651 - val_accuracy: 0.6600\n",
      "Epoch 46/120\n",
      "7000/7000 [==============================] - 0s 50us/step - loss: 1.9760 - accuracy: 0.6637 - val_loss: 1.9497 - val_accuracy: 0.6620\n",
      "Epoch 47/120\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 1.9602 - accuracy: 0.6680 - val_loss: 1.9337 - val_accuracy: 0.6620\n",
      "Epoch 48/120\n",
      "7000/7000 [==============================] - 0s 50us/step - loss: 1.9448 - accuracy: 0.6687 - val_loss: 1.9178 - val_accuracy: 0.6690\n",
      "Epoch 49/120\n",
      "7000/7000 [==============================] - 0s 51us/step - loss: 1.9298 - accuracy: 0.6701 - val_loss: 1.9037 - val_accuracy: 0.6610\n",
      "Epoch 50/120\n",
      "7000/7000 [==============================] - 0s 50us/step - loss: 1.9159 - accuracy: 0.6714 - val_loss: 1.8882 - val_accuracy: 0.6640\n",
      "Epoch 51/120\n",
      "7000/7000 [==============================] - 0s 51us/step - loss: 1.9014 - accuracy: 0.6741 - val_loss: 1.8761 - val_accuracy: 0.6730\n",
      "Epoch 52/120\n",
      "7000/7000 [==============================] - 0s 50us/step - loss: 1.8884 - accuracy: 0.6751 - val_loss: 1.8634 - val_accuracy: 0.6690\n",
      "Epoch 53/120\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 1.8759 - accuracy: 0.6766 - val_loss: 1.8488 - val_accuracy: 0.6660\n",
      "Epoch 54/120\n",
      "7000/7000 [==============================] - 0s 51us/step - loss: 1.8624 - accuracy: 0.6776 - val_loss: 1.8358 - val_accuracy: 0.6720\n",
      "Epoch 55/120\n",
      "7000/7000 [==============================] - 0s 51us/step - loss: 1.8508 - accuracy: 0.6781 - val_loss: 1.8249 - val_accuracy: 0.6720\n",
      "Epoch 56/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 0s 50us/step - loss: 1.8386 - accuracy: 0.6790 - val_loss: 1.8135 - val_accuracy: 0.6720\n",
      "Epoch 57/120\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 1.8271 - accuracy: 0.6796 - val_loss: 1.8052 - val_accuracy: 0.6720\n",
      "Epoch 58/120\n",
      "7000/7000 [==============================] - 0s 47us/step - loss: 1.8160 - accuracy: 0.6801 - val_loss: 1.7909 - val_accuracy: 0.6710\n",
      "Epoch 59/120\n",
      "7000/7000 [==============================] - 0s 47us/step - loss: 1.8053 - accuracy: 0.6799 - val_loss: 1.7828 - val_accuracy: 0.6750\n",
      "Epoch 60/120\n",
      "7000/7000 [==============================] - 0s 47us/step - loss: 1.7951 - accuracy: 0.6799 - val_loss: 1.7734 - val_accuracy: 0.6720\n",
      "Epoch 61/120\n",
      "7000/7000 [==============================] - 0s 47us/step - loss: 1.7846 - accuracy: 0.6821 - val_loss: 1.7595 - val_accuracy: 0.6730\n",
      "Epoch 62/120\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 1.7749 - accuracy: 0.6804 - val_loss: 1.7501 - val_accuracy: 0.6720\n",
      "Epoch 63/120\n",
      "7000/7000 [==============================] - 0s 47us/step - loss: 1.7649 - accuracy: 0.6826 - val_loss: 1.7422 - val_accuracy: 0.6710\n",
      "Epoch 64/120\n",
      "7000/7000 [==============================] - 0s 46us/step - loss: 1.7550 - accuracy: 0.6843 - val_loss: 1.7340 - val_accuracy: 0.6740\n",
      "Epoch 65/120\n",
      "7000/7000 [==============================] - 0s 46us/step - loss: 1.7461 - accuracy: 0.6836 - val_loss: 1.7243 - val_accuracy: 0.6690\n",
      "Epoch 66/120\n",
      "7000/7000 [==============================] - 0s 47us/step - loss: 1.7368 - accuracy: 0.6843 - val_loss: 1.7187 - val_accuracy: 0.6680\n",
      "Epoch 67/120\n",
      "7000/7000 [==============================] - 0s 47us/step - loss: 1.7277 - accuracy: 0.6859 - val_loss: 1.7056 - val_accuracy: 0.6750\n",
      "Epoch 68/120\n",
      "7000/7000 [==============================] - 0s 47us/step - loss: 1.7187 - accuracy: 0.6850 - val_loss: 1.6995 - val_accuracy: 0.6780\n",
      "Epoch 69/120\n",
      "7000/7000 [==============================] - 0s 47us/step - loss: 1.7102 - accuracy: 0.6860 - val_loss: 1.6902 - val_accuracy: 0.6770\n",
      "Epoch 70/120\n",
      "7000/7000 [==============================] - 0s 46us/step - loss: 1.7013 - accuracy: 0.6861 - val_loss: 1.6831 - val_accuracy: 0.6710\n",
      "Epoch 71/120\n",
      "7000/7000 [==============================] - 0s 46us/step - loss: 1.6937 - accuracy: 0.6867 - val_loss: 1.6730 - val_accuracy: 0.6760\n",
      "Epoch 72/120\n",
      "7000/7000 [==============================] - 0s 47us/step - loss: 1.6850 - accuracy: 0.6880 - val_loss: 1.6646 - val_accuracy: 0.6820\n",
      "Epoch 73/120\n",
      "7000/7000 [==============================] - 0s 47us/step - loss: 1.6768 - accuracy: 0.6873 - val_loss: 1.6570 - val_accuracy: 0.6720\n",
      "Epoch 74/120\n",
      "7000/7000 [==============================] - 0s 47us/step - loss: 1.6687 - accuracy: 0.6879 - val_loss: 1.6473 - val_accuracy: 0.6810\n",
      "Epoch 75/120\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 1.6607 - accuracy: 0.6861 - val_loss: 1.6453 - val_accuracy: 0.6750\n",
      "Epoch 76/120\n",
      "7000/7000 [==============================] - 0s 46us/step - loss: 1.6533 - accuracy: 0.6864 - val_loss: 1.6346 - val_accuracy: 0.6820\n",
      "Epoch 77/120\n",
      "7000/7000 [==============================] - 0s 46us/step - loss: 1.6453 - accuracy: 0.6881 - val_loss: 1.6273 - val_accuracy: 0.6740\n",
      "Epoch 78/120\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 1.6375 - accuracy: 0.6867 - val_loss: 1.6191 - val_accuracy: 0.6810\n",
      "Epoch 79/120\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 1.6303 - accuracy: 0.6886 - val_loss: 1.6134 - val_accuracy: 0.6760\n",
      "Epoch 80/120\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 1.6227 - accuracy: 0.6890 - val_loss: 1.6062 - val_accuracy: 0.6840\n",
      "Epoch 81/120\n",
      "7000/7000 [==============================] - 0s 47us/step - loss: 1.6157 - accuracy: 0.6903 - val_loss: 1.5997 - val_accuracy: 0.6790\n",
      "Epoch 82/120\n",
      "7000/7000 [==============================] - 0s 46us/step - loss: 1.6087 - accuracy: 0.6903 - val_loss: 1.5926 - val_accuracy: 0.6820\n",
      "Epoch 83/120\n",
      "7000/7000 [==============================] - 0s 46us/step - loss: 1.6012 - accuracy: 0.6904 - val_loss: 1.5861 - val_accuracy: 0.6770\n",
      "Epoch 84/120\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 1.5948 - accuracy: 0.6901 - val_loss: 1.5768 - val_accuracy: 0.6770\n",
      "Epoch 85/120\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 1.5875 - accuracy: 0.6909 - val_loss: 1.5738 - val_accuracy: 0.6800\n",
      "Epoch 86/120\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 1.5810 - accuracy: 0.6914 - val_loss: 1.5691 - val_accuracy: 0.6790\n",
      "Epoch 87/120\n",
      "7000/7000 [==============================] - 0s 47us/step - loss: 1.5748 - accuracy: 0.6917 - val_loss: 1.5594 - val_accuracy: 0.6820\n",
      "Epoch 88/120\n",
      "7000/7000 [==============================] - 0s 47us/step - loss: 1.5681 - accuracy: 0.6920 - val_loss: 1.5520 - val_accuracy: 0.6740\n",
      "Epoch 89/120\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 1.5611 - accuracy: 0.6923 - val_loss: 1.5462 - val_accuracy: 0.6750\n",
      "Epoch 90/120\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 1.5547 - accuracy: 0.6916 - val_loss: 1.5407 - val_accuracy: 0.6760\n",
      "Epoch 91/120\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 1.5483 - accuracy: 0.6914 - val_loss: 1.5353 - val_accuracy: 0.6810\n",
      "Epoch 92/120\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 1.5421 - accuracy: 0.6944 - val_loss: 1.5277 - val_accuracy: 0.6760\n",
      "Epoch 93/120\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 1.5361 - accuracy: 0.6941 - val_loss: 1.5235 - val_accuracy: 0.6800\n",
      "Epoch 94/120\n",
      "7000/7000 [==============================] - 0s 46us/step - loss: 1.5297 - accuracy: 0.6931 - val_loss: 1.5162 - val_accuracy: 0.6840\n",
      "Epoch 95/120\n",
      "7000/7000 [==============================] - 0s 46us/step - loss: 1.5233 - accuracy: 0.6951 - val_loss: 1.5099 - val_accuracy: 0.6850\n",
      "Epoch 96/120\n",
      "7000/7000 [==============================] - 0s 47us/step - loss: 1.5176 - accuracy: 0.6967 - val_loss: 1.5063 - val_accuracy: 0.6840\n",
      "Epoch 97/120\n",
      "7000/7000 [==============================] - 0s 47us/step - loss: 1.5114 - accuracy: 0.6950 - val_loss: 1.5016 - val_accuracy: 0.6810\n",
      "Epoch 98/120\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 1.5056 - accuracy: 0.6966 - val_loss: 1.4946 - val_accuracy: 0.6870\n",
      "Epoch 99/120\n",
      "7000/7000 [==============================] - 0s 47us/step - loss: 1.4996 - accuracy: 0.6983 - val_loss: 1.4891 - val_accuracy: 0.6810\n",
      "Epoch 100/120\n",
      "7000/7000 [==============================] - 0s 46us/step - loss: 1.4942 - accuracy: 0.6980 - val_loss: 1.4807 - val_accuracy: 0.6810\n",
      "Epoch 101/120\n",
      "7000/7000 [==============================] - 0s 46us/step - loss: 1.4880 - accuracy: 0.6986 - val_loss: 1.4798 - val_accuracy: 0.6870\n",
      "Epoch 102/120\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 1.4822 - accuracy: 0.6997 - val_loss: 1.4720 - val_accuracy: 0.6870\n",
      "Epoch 103/120\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 1.4770 - accuracy: 0.6999 - val_loss: 1.4674 - val_accuracy: 0.6880\n",
      "Epoch 104/120\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 1.4709 - accuracy: 0.7000 - val_loss: 1.4633 - val_accuracy: 0.6850\n",
      "Epoch 105/120\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 1.4657 - accuracy: 0.6993 - val_loss: 1.4555 - val_accuracy: 0.6880\n",
      "Epoch 106/120\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.4599 - accuracy: 0.7003 - val_loss: 1.4566 - val_accuracy: 0.6840\n",
      "Epoch 107/120\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 1.4552 - accuracy: 0.7003 - val_loss: 1.4475 - val_accuracy: 0.6890\n",
      "Epoch 108/120\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 1.4493 - accuracy: 0.7039 - val_loss: 1.4402 - val_accuracy: 0.6850\n",
      "Epoch 109/120\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.4438 - accuracy: 0.7037 - val_loss: 1.4407 - val_accuracy: 0.6910\n",
      "Epoch 110/120\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 1.4386 - accuracy: 0.7017 - val_loss: 1.4295 - val_accuracy: 0.6940\n",
      "Epoch 111/120\n",
      "7000/7000 [==============================] - 0s 53us/step - loss: 1.4329 - accuracy: 0.7014 - val_loss: 1.4258 - val_accuracy: 0.6900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/120\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.4280 - accuracy: 0.7024 - val_loss: 1.4224 - val_accuracy: 0.6910\n",
      "Epoch 113/120\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.4234 - accuracy: 0.7036 - val_loss: 1.4155 - val_accuracy: 0.6900\n",
      "Epoch 114/120\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.4183 - accuracy: 0.7036 - val_loss: 1.4085 - val_accuracy: 0.6940\n",
      "Epoch 115/120\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.4129 - accuracy: 0.7024 - val_loss: 1.4053 - val_accuracy: 0.6900\n",
      "Epoch 116/120\n",
      "7000/7000 [==============================] - 0s 52us/step - loss: 1.4084 - accuracy: 0.7053 - val_loss: 1.4023 - val_accuracy: 0.6880\n",
      "Epoch 117/120\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.4034 - accuracy: 0.7057 - val_loss: 1.3945 - val_accuracy: 0.6930\n",
      "Epoch 118/120\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.3978 - accuracy: 0.7080 - val_loss: 1.3924 - val_accuracy: 0.6890\n",
      "Epoch 119/120\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.3932 - accuracy: 0.7069 - val_loss: 1.3857 - val_accuracy: 0.6890\n",
      "Epoch 120/120\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 1.3880 - accuracy: 0.7086 - val_loss: 1.3876 - val_accuracy: 0.6890\n"
     ]
    }
   ],
   "source": [
    "random.seed(123)\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(50, activation='relu',kernel_regularizer=regularizers.l1(0.005), input_shape=(2000,))) #2 hidden layers\n",
    "model.add(keras.layers.Dense(25, kernel_regularizer=regularizers.l1(0.005), activation='relu'))\n",
    "model.add(keras.layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "L1_model = model.fit(X_train_tokenized,\n",
    "                    y_train_bin,\n",
    "                    epochs=120,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "L1_model_dict = L1_model.history\n",
    "\n",
    "acc_values = L1_model_dict['accuracy'] \n",
    "val_acc_values = L1_model_dict['val_accuracy']\n",
    "\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "ax.plot(epochs, acc_values, label='Training acc L1')\n",
    "ax.plot(epochs, val_acc_values, label='Validation acc L1')\n",
    "ax.set_title('Training & validation accuracy with L1 regularization')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the training and validation accuracy don't diverge as much as before. Unfortunately, the validation accuracy doesn't reach rates much higher than 70%. It does seem like you can still improve the model by training much longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "7000/7000 [==============================] - 1s 163us/step - loss: 16.0069 - accuracy: 0.1487 - val_loss: 15.6023 - val_accuracy: 0.1800\n",
      "Epoch 2/1000\n",
      "7000/7000 [==============================] - 1s 123us/step - loss: 15.2825 - accuracy: 0.1889 - val_loss: 14.8999 - val_accuracy: 0.2130\n",
      "Epoch 3/1000\n",
      "7000/7000 [==============================] - 1s 140us/step - loss: 14.5923 - accuracy: 0.2080 - val_loss: 14.2232 - val_accuracy: 0.2300\n",
      "Epoch 4/1000\n",
      "7000/7000 [==============================] - 0s 64us/step - loss: 13.9254 - accuracy: 0.2237 - val_loss: 13.5662 - val_accuracy: 0.2440\n",
      "Epoch 5/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 13.2776 - accuracy: 0.2307 - val_loss: 12.9270 - val_accuracy: 0.2410\n",
      "Epoch 6/1000\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 12.6480 - accuracy: 0.2394 - val_loss: 12.3059 - val_accuracy: 0.2510\n",
      "Epoch 7/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 12.0362 - accuracy: 0.2540 - val_loss: 11.7036 - val_accuracy: 0.2620\n",
      "Epoch 8/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 11.4420 - accuracy: 0.2664 - val_loss: 11.1183 - val_accuracy: 0.2830\n",
      "Epoch 9/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 10.8657 - accuracy: 0.2816 - val_loss: 10.5507 - val_accuracy: 0.3010\n",
      "Epoch 10/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 10.3073 - accuracy: 0.2949 - val_loss: 10.0011 - val_accuracy: 0.3110\n",
      "Epoch 11/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 9.7669 - accuracy: 0.3031 - val_loss: 9.4699 - val_accuracy: 0.3250\n",
      "Epoch 12/1000\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 9.2453 - accuracy: 0.3220 - val_loss: 8.9589 - val_accuracy: 0.3530\n",
      "Epoch 13/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 8.7422 - accuracy: 0.3414 - val_loss: 8.4665 - val_accuracy: 0.3800\n",
      "Epoch 14/1000\n",
      "7000/7000 [==============================] - 1s 72us/step - loss: 8.2568 - accuracy: 0.3703 - val_loss: 7.9918 - val_accuracy: 0.4020\n",
      "Epoch 15/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 7.7892 - accuracy: 0.3970 - val_loss: 7.5326 - val_accuracy: 0.4130\n",
      "Epoch 16/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 7.3396 - accuracy: 0.4129 - val_loss: 7.0922 - val_accuracy: 0.4240\n",
      "Epoch 17/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 6.9088 - accuracy: 0.4303 - val_loss: 6.6719 - val_accuracy: 0.4390\n",
      "Epoch 18/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 6.4974 - accuracy: 0.4457 - val_loss: 6.2717 - val_accuracy: 0.4710\n",
      "Epoch 19/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 6.1050 - accuracy: 0.4649 - val_loss: 5.8888 - val_accuracy: 0.4600\n",
      "Epoch 20/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 5.7308 - accuracy: 0.4694 - val_loss: 5.5242 - val_accuracy: 0.4680\n",
      "Epoch 21/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 5.3760 - accuracy: 0.4859 - val_loss: 5.1811 - val_accuracy: 0.4900\n",
      "Epoch 22/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 5.0413 - accuracy: 0.4954 - val_loss: 4.8558 - val_accuracy: 0.4930\n",
      "Epoch 23/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 4.7266 - accuracy: 0.5044 - val_loss: 4.5535 - val_accuracy: 0.5060\n",
      "Epoch 24/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 4.4320 - accuracy: 0.5150 - val_loss: 4.2681 - val_accuracy: 0.5160\n",
      "Epoch 25/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 4.1572 - accuracy: 0.5287 - val_loss: 4.0013 - val_accuracy: 0.5240\n",
      "Epoch 26/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 3.9012 - accuracy: 0.5331 - val_loss: 3.7556 - val_accuracy: 0.5340\n",
      "Epoch 27/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 3.6635 - accuracy: 0.5436 - val_loss: 3.5262 - val_accuracy: 0.5440\n",
      "Epoch 28/1000\n",
      "7000/7000 [==============================] - ETA: 0s - loss: 3.4594 - accuracy: 0.55 - 0s 61us/step - loss: 3.4448 - accuracy: 0.5563 - val_loss: 3.3207 - val_accuracy: 0.5500\n",
      "Epoch 29/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 3.2447 - accuracy: 0.5661 - val_loss: 3.1256 - val_accuracy: 0.5470\n",
      "Epoch 30/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 3.0631 - accuracy: 0.5657 - val_loss: 2.9544 - val_accuracy: 0.5650\n",
      "Epoch 31/1000\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 2.9007 - accuracy: 0.5756 - val_loss: 2.8048 - val_accuracy: 0.5550\n",
      "Epoch 32/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 2.7565 - accuracy: 0.5750 - val_loss: 2.6654 - val_accuracy: 0.5660\n",
      "Epoch 33/1000\n",
      "7000/7000 [==============================] - 0s 66us/step - loss: 2.6297 - accuracy: 0.5811 - val_loss: 2.5484 - val_accuracy: 0.5820\n",
      "Epoch 34/1000\n",
      "7000/7000 [==============================] - 1s 72us/step - loss: 2.5209 - accuracy: 0.5884 - val_loss: 2.4464 - val_accuracy: 0.5770\n",
      "Epoch 35/1000\n",
      "7000/7000 [==============================] - 1s 88us/step - loss: 2.4287 - accuracy: 0.5867 - val_loss: 2.3637 - val_accuracy: 0.5800\n",
      "Epoch 36/1000\n",
      "7000/7000 [==============================] - 0s 67us/step - loss: 2.3531 - accuracy: 0.5946 - val_loss: 2.2961 - val_accuracy: 0.5910\n",
      "Epoch 37/1000\n",
      "7000/7000 [==============================] - 0s 68us/step - loss: 2.2924 - accuracy: 0.6017 - val_loss: 2.2406 - val_accuracy: 0.5970\n",
      "Epoch 38/1000\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 2.2451 - accuracy: 0.6014 - val_loss: 2.2011 - val_accuracy: 0.6000\n",
      "Epoch 39/1000\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 2.2085 - accuracy: 0.6077 - val_loss: 2.1681 - val_accuracy: 0.6040\n",
      "Epoch 40/1000\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 2.1796 - accuracy: 0.6154 - val_loss: 2.1431 - val_accuracy: 0.6150\n",
      "Epoch 41/1000\n",
      "7000/7000 [==============================] - 1s 72us/step - loss: 2.1545 - accuracy: 0.6216 - val_loss: 2.1246 - val_accuracy: 0.6030\n",
      "Epoch 42/1000\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 2.1326 - accuracy: 0.6234 - val_loss: 2.0961 - val_accuracy: 0.6170\n",
      "Epoch 43/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 2.1114 - accuracy: 0.6294 - val_loss: 2.0756 - val_accuracy: 0.6230\n",
      "Epoch 44/1000\n",
      "7000/7000 [==============================] - 0s 65us/step - loss: 2.0918 - accuracy: 0.6339 - val_loss: 2.0553 - val_accuracy: 0.6180\n",
      "Epoch 45/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 2.0735 - accuracy: 0.6364 - val_loss: 2.0381 - val_accuracy: 0.6300\n",
      "Epoch 46/1000\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 2.0552 - accuracy: 0.6396 - val_loss: 2.0197 - val_accuracy: 0.6330\n",
      "Epoch 47/1000\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 2.0379 - accuracy: 0.6430 - val_loss: 2.0050 - val_accuracy: 0.6330\n",
      "Epoch 48/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 2.0213 - accuracy: 0.6493 - val_loss: 1.9869 - val_accuracy: 0.6360\n",
      "Epoch 49/1000\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 2.0048 - accuracy: 0.6530 - val_loss: 1.9717 - val_accuracy: 0.6340\n",
      "Epoch 50/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.9888 - accuracy: 0.6547 - val_loss: 1.9550 - val_accuracy: 0.6420\n",
      "Epoch 51/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.9735 - accuracy: 0.6579 - val_loss: 1.9402 - val_accuracy: 0.6440\n",
      "Epoch 52/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.9583 - accuracy: 0.6639 - val_loss: 1.9254 - val_accuracy: 0.6500\n",
      "Epoch 53/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.9437 - accuracy: 0.6644 - val_loss: 1.9119 - val_accuracy: 0.6510\n",
      "Epoch 54/1000\n",
      "7000/7000 [==============================] - 0s 52us/step - loss: 1.9289 - accuracy: 0.6646 - val_loss: 1.9037 - val_accuracy: 0.6420\n",
      "Epoch 55/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 0s 51us/step - loss: 1.9152 - accuracy: 0.6686 - val_loss: 1.8852 - val_accuracy: 0.6570\n",
      "Epoch 56/1000\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 1.9015 - accuracy: 0.6707 - val_loss: 1.8763 - val_accuracy: 0.6660\n",
      "Epoch 57/1000\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 1.8885 - accuracy: 0.6749 - val_loss: 1.8590 - val_accuracy: 0.6620\n",
      "Epoch 58/1000\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 1.8751 - accuracy: 0.6763 - val_loss: 1.8467 - val_accuracy: 0.6680\n",
      "Epoch 59/1000\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 1.8627 - accuracy: 0.6790 - val_loss: 1.8358 - val_accuracy: 0.6670\n",
      "Epoch 60/1000\n",
      "7000/7000 [==============================] - 0s 46us/step - loss: 1.8501 - accuracy: 0.6804 - val_loss: 1.8227 - val_accuracy: 0.6780\n",
      "Epoch 61/1000\n",
      "7000/7000 [==============================] - 0s 47us/step - loss: 1.8380 - accuracy: 0.6843 - val_loss: 1.8112 - val_accuracy: 0.6740\n",
      "Epoch 62/1000\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 1.8258 - accuracy: 0.6866 - val_loss: 1.8017 - val_accuracy: 0.6750\n",
      "Epoch 63/1000\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 1.8144 - accuracy: 0.6881 - val_loss: 1.7899 - val_accuracy: 0.6760\n",
      "Epoch 64/1000\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 1.8025 - accuracy: 0.6899 - val_loss: 1.7795 - val_accuracy: 0.6730\n",
      "Epoch 65/1000\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 1.7914 - accuracy: 0.6906 - val_loss: 1.7681 - val_accuracy: 0.6720\n",
      "Epoch 66/1000\n",
      "7000/7000 [==============================] - 0s 46us/step - loss: 1.7808 - accuracy: 0.6916 - val_loss: 1.7572 - val_accuracy: 0.6760\n",
      "Epoch 67/1000\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 1.7696 - accuracy: 0.6924 - val_loss: 1.7468 - val_accuracy: 0.6810\n",
      "Epoch 68/1000\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 1.7591 - accuracy: 0.6923 - val_loss: 1.7345 - val_accuracy: 0.6800\n",
      "Epoch 69/1000\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 1.7480 - accuracy: 0.6954 - val_loss: 1.7286 - val_accuracy: 0.6800\n",
      "Epoch 70/1000\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 1.7385 - accuracy: 0.6969 - val_loss: 1.7180 - val_accuracy: 0.6790\n",
      "Epoch 71/1000\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 1.7285 - accuracy: 0.6981 - val_loss: 1.7086 - val_accuracy: 0.6860\n",
      "Epoch 72/1000\n",
      "7000/7000 [==============================] - 0s 46us/step - loss: 1.7187 - accuracy: 0.6983 - val_loss: 1.6967 - val_accuracy: 0.6850\n",
      "Epoch 73/1000\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 1.7082 - accuracy: 0.6993 - val_loss: 1.6897 - val_accuracy: 0.6830\n",
      "Epoch 74/1000\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 1.6991 - accuracy: 0.7009 - val_loss: 1.6808 - val_accuracy: 0.6820\n",
      "Epoch 75/1000\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 1.6894 - accuracy: 0.7031 - val_loss: 1.6709 - val_accuracy: 0.6870\n",
      "Epoch 76/1000\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 1.6805 - accuracy: 0.7019 - val_loss: 1.6613 - val_accuracy: 0.6860\n",
      "Epoch 77/1000\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 1.6713 - accuracy: 0.7036 - val_loss: 1.6530 - val_accuracy: 0.6870\n",
      "Epoch 78/1000\n",
      "7000/7000 [==============================] - 0s 47us/step - loss: 1.6623 - accuracy: 0.7049 - val_loss: 1.6479 - val_accuracy: 0.6860\n",
      "Epoch 79/1000\n",
      "7000/7000 [==============================] - 0s 50us/step - loss: 1.6532 - accuracy: 0.7060 - val_loss: 1.6367 - val_accuracy: 0.6920\n",
      "Epoch 80/1000\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 1.6450 - accuracy: 0.7066 - val_loss: 1.6324 - val_accuracy: 0.6840\n",
      "Epoch 81/1000\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 1.6360 - accuracy: 0.7080 - val_loss: 1.6181 - val_accuracy: 0.6930\n",
      "Epoch 82/1000\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 1.6273 - accuracy: 0.7073 - val_loss: 1.6164 - val_accuracy: 0.6900\n",
      "Epoch 83/1000\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 1.6194 - accuracy: 0.7086 - val_loss: 1.6090 - val_accuracy: 0.6910\n",
      "Epoch 84/1000\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 1.6109 - accuracy: 0.7091 - val_loss: 1.5989 - val_accuracy: 0.6990\n",
      "Epoch 85/1000\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 1.6027 - accuracy: 0.7103 - val_loss: 1.5919 - val_accuracy: 0.6890\n",
      "Epoch 86/1000\n",
      "7000/7000 [==============================] - 0s 65us/step - loss: 1.5951 - accuracy: 0.7124 - val_loss: 1.5836 - val_accuracy: 0.6910\n",
      "Epoch 87/1000\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 1.5870 - accuracy: 0.7099 - val_loss: 1.5767 - val_accuracy: 0.6960\n",
      "Epoch 88/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 1.5793 - accuracy: 0.7119 - val_loss: 1.5694 - val_accuracy: 0.6940\n",
      "Epoch 89/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.5716 - accuracy: 0.7123 - val_loss: 1.5642 - val_accuracy: 0.6930\n",
      "Epoch 90/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 1.5647 - accuracy: 0.7134 - val_loss: 1.5531 - val_accuracy: 0.6980\n",
      "Epoch 91/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 1.5564 - accuracy: 0.7130 - val_loss: 1.5462 - val_accuracy: 0.6960\n",
      "Epoch 92/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 1.5494 - accuracy: 0.7149 - val_loss: 1.5401 - val_accuracy: 0.6980\n",
      "Epoch 93/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 1.5421 - accuracy: 0.7157 - val_loss: 1.5311 - val_accuracy: 0.6970\n",
      "Epoch 94/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 1.5352 - accuracy: 0.7137 - val_loss: 1.5278 - val_accuracy: 0.7040\n",
      "Epoch 95/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 1.5289 - accuracy: 0.7160 - val_loss: 1.5219 - val_accuracy: 0.6980\n",
      "Epoch 96/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 1.5217 - accuracy: 0.7140 - val_loss: 1.5168 - val_accuracy: 0.6940\n",
      "Epoch 97/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 1.5153 - accuracy: 0.7150 - val_loss: 1.5056 - val_accuracy: 0.6990\n",
      "Epoch 98/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 1.5084 - accuracy: 0.7160 - val_loss: 1.5012 - val_accuracy: 0.7040\n",
      "Epoch 99/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 1.5020 - accuracy: 0.7147 - val_loss: 1.4987 - val_accuracy: 0.7010\n",
      "Epoch 100/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 1.4947 - accuracy: 0.7194 - val_loss: 1.4885 - val_accuracy: 0.6990\n",
      "Epoch 101/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 1.4887 - accuracy: 0.7176 - val_loss: 1.4854 - val_accuracy: 0.7010\n",
      "Epoch 102/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 1.4827 - accuracy: 0.7170 - val_loss: 1.4804 - val_accuracy: 0.7010\n",
      "Epoch 103/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 1.4763 - accuracy: 0.7171 - val_loss: 1.4703 - val_accuracy: 0.6990\n",
      "Epoch 104/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 1.4698 - accuracy: 0.7190 - val_loss: 1.4638 - val_accuracy: 0.7020\n",
      "Epoch 105/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.4640 - accuracy: 0.7170 - val_loss: 1.4625 - val_accuracy: 0.6980\n",
      "Epoch 106/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 1.4577 - accuracy: 0.7186 - val_loss: 1.4550 - val_accuracy: 0.7000\n",
      "Epoch 107/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 1.4522 - accuracy: 0.7173 - val_loss: 1.4465 - val_accuracy: 0.7000\n",
      "Epoch 108/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 1.4457 - accuracy: 0.7184 - val_loss: 1.4400 - val_accuracy: 0.7030\n",
      "Epoch 109/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 1.4403 - accuracy: 0.7203 - val_loss: 1.4393 - val_accuracy: 0.7090\n",
      "Epoch 110/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 0s 60us/step - loss: 1.4341 - accuracy: 0.7209 - val_loss: 1.4291 - val_accuracy: 0.7050\n",
      "Epoch 111/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 1.4286 - accuracy: 0.7193 - val_loss: 1.4280 - val_accuracy: 0.7050\n",
      "Epoch 112/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 1.4227 - accuracy: 0.7201 - val_loss: 1.4188 - val_accuracy: 0.7060\n",
      "Epoch 113/1000\n",
      "7000/7000 [==============================] - 0s 51us/step - loss: 1.4173 - accuracy: 0.7206 - val_loss: 1.4145 - val_accuracy: 0.7030\n",
      "Epoch 114/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.4115 - accuracy: 0.7213 - val_loss: 1.4115 - val_accuracy: 0.7050\n",
      "Epoch 115/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.4061 - accuracy: 0.7236 - val_loss: 1.4085 - val_accuracy: 0.7070\n",
      "Epoch 116/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.4009 - accuracy: 0.7223 - val_loss: 1.4008 - val_accuracy: 0.7050\n",
      "Epoch 117/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.3958 - accuracy: 0.7217 - val_loss: 1.3950 - val_accuracy: 0.7130\n",
      "Epoch 118/1000\n",
      "7000/7000 [==============================] - 0s 52us/step - loss: 1.3907 - accuracy: 0.7233 - val_loss: 1.3939 - val_accuracy: 0.7080\n",
      "Epoch 119/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.3849 - accuracy: 0.7231 - val_loss: 1.3879 - val_accuracy: 0.7080\n",
      "Epoch 120/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.3800 - accuracy: 0.7220 - val_loss: 1.3817 - val_accuracy: 0.7080\n",
      "Epoch 121/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.3747 - accuracy: 0.7236 - val_loss: 1.3798 - val_accuracy: 0.7010\n",
      "Epoch 122/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.3697 - accuracy: 0.7230 - val_loss: 1.3734 - val_accuracy: 0.7060\n",
      "Epoch 123/1000\n",
      "7000/7000 [==============================] - 0s 53us/step - loss: 1.3649 - accuracy: 0.7237 - val_loss: 1.3724 - val_accuracy: 0.7040\n",
      "Epoch 124/1000\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 1.3599 - accuracy: 0.7240 - val_loss: 1.3625 - val_accuracy: 0.7090\n",
      "Epoch 125/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.3546 - accuracy: 0.7257 - val_loss: 1.3571 - val_accuracy: 0.7090\n",
      "Epoch 126/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.3499 - accuracy: 0.7233 - val_loss: 1.3517 - val_accuracy: 0.7110\n",
      "Epoch 127/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.3454 - accuracy: 0.7247 - val_loss: 1.3474 - val_accuracy: 0.7110\n",
      "Epoch 128/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.3405 - accuracy: 0.7260 - val_loss: 1.3475 - val_accuracy: 0.7130\n",
      "Epoch 129/1000\n",
      "7000/7000 [==============================] - 0s 53us/step - loss: 1.3359 - accuracy: 0.7261 - val_loss: 1.3430 - val_accuracy: 0.7120\n",
      "Epoch 130/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.3314 - accuracy: 0.7247 - val_loss: 1.3354 - val_accuracy: 0.7100\n",
      "Epoch 131/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.3268 - accuracy: 0.7271 - val_loss: 1.3322 - val_accuracy: 0.7110\n",
      "Epoch 132/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.3227 - accuracy: 0.7271 - val_loss: 1.3277 - val_accuracy: 0.7130\n",
      "Epoch 133/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.3174 - accuracy: 0.7260 - val_loss: 1.3255 - val_accuracy: 0.7170\n",
      "Epoch 134/1000\n",
      "7000/7000 [==============================] - 0s 53us/step - loss: 1.3129 - accuracy: 0.7291 - val_loss: 1.3304 - val_accuracy: 0.7060\n",
      "Epoch 135/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.3093 - accuracy: 0.7287 - val_loss: 1.3163 - val_accuracy: 0.7150\n",
      "Epoch 136/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.3043 - accuracy: 0.7279 - val_loss: 1.3122 - val_accuracy: 0.7180\n",
      "Epoch 137/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.3007 - accuracy: 0.7276 - val_loss: 1.3138 - val_accuracy: 0.7170\n",
      "Epoch 138/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.2961 - accuracy: 0.7299 - val_loss: 1.3065 - val_accuracy: 0.7090\n",
      "Epoch 139/1000\n",
      "7000/7000 [==============================] - 0s 51us/step - loss: 1.2922 - accuracy: 0.7287 - val_loss: 1.2989 - val_accuracy: 0.7140\n",
      "Epoch 140/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.2876 - accuracy: 0.7296 - val_loss: 1.3015 - val_accuracy: 0.7110\n",
      "Epoch 141/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.2844 - accuracy: 0.7293 - val_loss: 1.2956 - val_accuracy: 0.7190\n",
      "Epoch 142/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.2801 - accuracy: 0.7284 - val_loss: 1.2901 - val_accuracy: 0.7150\n",
      "Epoch 143/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.2761 - accuracy: 0.7299 - val_loss: 1.2850 - val_accuracy: 0.7150\n",
      "Epoch 144/1000\n",
      "7000/7000 [==============================] - 0s 52us/step - loss: 1.2723 - accuracy: 0.7284 - val_loss: 1.2857 - val_accuracy: 0.7160\n",
      "Epoch 145/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.2681 - accuracy: 0.7319 - val_loss: 1.2807 - val_accuracy: 0.7150\n",
      "Epoch 146/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.2652 - accuracy: 0.7316 - val_loss: 1.2762 - val_accuracy: 0.7220\n",
      "Epoch 147/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.2611 - accuracy: 0.7324 - val_loss: 1.2712 - val_accuracy: 0.7190\n",
      "Epoch 148/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.2577 - accuracy: 0.7299 - val_loss: 1.2737 - val_accuracy: 0.7150\n",
      "Epoch 149/1000\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 1.2535 - accuracy: 0.7293 - val_loss: 1.2670 - val_accuracy: 0.7110\n",
      "Epoch 150/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.2498 - accuracy: 0.7339 - val_loss: 1.2596 - val_accuracy: 0.7180\n",
      "Epoch 151/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.2468 - accuracy: 0.7317 - val_loss: 1.2563 - val_accuracy: 0.7200\n",
      "Epoch 152/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.2428 - accuracy: 0.7333 - val_loss: 1.2583 - val_accuracy: 0.7160\n",
      "Epoch 153/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.2397 - accuracy: 0.7323 - val_loss: 1.2579 - val_accuracy: 0.7190\n",
      "Epoch 154/1000\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 1.2359 - accuracy: 0.7337 - val_loss: 1.2636 - val_accuracy: 0.7070\n",
      "Epoch 155/1000\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 1.2331 - accuracy: 0.7311 - val_loss: 1.2460 - val_accuracy: 0.7160\n",
      "Epoch 156/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.2286 - accuracy: 0.7329 - val_loss: 1.2455 - val_accuracy: 0.7180\n",
      "Epoch 157/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.2260 - accuracy: 0.7336 - val_loss: 1.2422 - val_accuracy: 0.7230\n",
      "Epoch 158/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.2228 - accuracy: 0.7333 - val_loss: 1.2422 - val_accuracy: 0.7170\n",
      "Epoch 159/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.2189 - accuracy: 0.7353 - val_loss: 1.2357 - val_accuracy: 0.7140\n",
      "Epoch 160/1000\n",
      "7000/7000 [==============================] - 0s 53us/step - loss: 1.2156 - accuracy: 0.7319 - val_loss: 1.2355 - val_accuracy: 0.7160\n",
      "Epoch 161/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.2121 - accuracy: 0.7343 - val_loss: 1.2285 - val_accuracy: 0.7170\n",
      "Epoch 162/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 1.2088 - accuracy: 0.7354 - val_loss: 1.2269 - val_accuracy: 0.7230\n",
      "Epoch 163/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.2059 - accuracy: 0.7363 - val_loss: 1.2233 - val_accuracy: 0.7250\n",
      "Epoch 164/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.2031 - accuracy: 0.7354 - val_loss: 1.2176 - val_accuracy: 0.7220\n",
      "Epoch 165/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 0s 54us/step - loss: 1.1994 - accuracy: 0.7350 - val_loss: 1.2180 - val_accuracy: 0.7210\n",
      "Epoch 166/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.1960 - accuracy: 0.7366 - val_loss: 1.2148 - val_accuracy: 0.7230\n",
      "Epoch 167/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.1935 - accuracy: 0.7347 - val_loss: 1.2113 - val_accuracy: 0.7230\n",
      "Epoch 168/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.1909 - accuracy: 0.7356 - val_loss: 1.2091 - val_accuracy: 0.7240\n",
      "Epoch 169/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.1881 - accuracy: 0.7364 - val_loss: 1.2066 - val_accuracy: 0.7200\n",
      "Epoch 170/1000\n",
      "7000/7000 [==============================] - 0s 52us/step - loss: 1.1851 - accuracy: 0.7363 - val_loss: 1.2043 - val_accuracy: 0.7270\n",
      "Epoch 171/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.1823 - accuracy: 0.7381 - val_loss: 1.1983 - val_accuracy: 0.7230\n",
      "Epoch 172/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.1791 - accuracy: 0.7399 - val_loss: 1.1966 - val_accuracy: 0.7190\n",
      "Epoch 173/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.1762 - accuracy: 0.7377 - val_loss: 1.1969 - val_accuracy: 0.7200\n",
      "Epoch 174/1000\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 1.1728 - accuracy: 0.7360 - val_loss: 1.1896 - val_accuracy: 0.7230\n",
      "Epoch 175/1000\n",
      "7000/7000 [==============================] - 0s 51us/step - loss: 1.1708 - accuracy: 0.7386 - val_loss: 1.1883 - val_accuracy: 0.7200\n",
      "Epoch 176/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.1684 - accuracy: 0.7379 - val_loss: 1.1897 - val_accuracy: 0.7160\n",
      "Epoch 177/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 1.1655 - accuracy: 0.7387 - val_loss: 1.1863 - val_accuracy: 0.7250\n",
      "Epoch 178/1000\n",
      "7000/7000 [==============================] - 0s 65us/step - loss: 1.1627 - accuracy: 0.7420 - val_loss: 1.1837 - val_accuracy: 0.7220\n",
      "Epoch 179/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 1.1604 - accuracy: 0.7393 - val_loss: 1.1782 - val_accuracy: 0.7250\n",
      "Epoch 180/1000\n",
      "7000/7000 [==============================] - 0s 52us/step - loss: 1.1576 - accuracy: 0.7404 - val_loss: 1.1853 - val_accuracy: 0.7180\n",
      "Epoch 181/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.1552 - accuracy: 0.7413 - val_loss: 1.1785 - val_accuracy: 0.7270\n",
      "Epoch 182/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.1533 - accuracy: 0.7414 - val_loss: 1.1730 - val_accuracy: 0.7290\n",
      "Epoch 183/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 1.1512 - accuracy: 0.7407 - val_loss: 1.1730 - val_accuracy: 0.7270\n",
      "Epoch 184/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.1482 - accuracy: 0.7419 - val_loss: 1.1689 - val_accuracy: 0.7300\n",
      "Epoch 185/1000\n",
      "7000/7000 [==============================] - 0s 52us/step - loss: 1.1456 - accuracy: 0.7423 - val_loss: 1.1687 - val_accuracy: 0.7210\n",
      "Epoch 186/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 1.1442 - accuracy: 0.7420 - val_loss: 1.1672 - val_accuracy: 0.7240\n",
      "Epoch 187/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.1416 - accuracy: 0.7406 - val_loss: 1.1662 - val_accuracy: 0.7230\n",
      "Epoch 188/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.1393 - accuracy: 0.7430 - val_loss: 1.1653 - val_accuracy: 0.7260\n",
      "Epoch 189/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.1376 - accuracy: 0.7414 - val_loss: 1.1624 - val_accuracy: 0.7300\n",
      "Epoch 190/1000\n",
      "7000/7000 [==============================] - 0s 52us/step - loss: 1.1354 - accuracy: 0.7420 - val_loss: 1.1610 - val_accuracy: 0.7260\n",
      "Epoch 191/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.1333 - accuracy: 0.7423 - val_loss: 1.1631 - val_accuracy: 0.7210\n",
      "Epoch 192/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.1309 - accuracy: 0.7429 - val_loss: 1.1522 - val_accuracy: 0.7290\n",
      "Epoch 193/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.1286 - accuracy: 0.7419 - val_loss: 1.1524 - val_accuracy: 0.7310\n",
      "Epoch 194/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.1264 - accuracy: 0.7451 - val_loss: 1.1503 - val_accuracy: 0.7270\n",
      "Epoch 195/1000\n",
      "7000/7000 [==============================] - 0s 53us/step - loss: 1.1248 - accuracy: 0.7441 - val_loss: 1.1500 - val_accuracy: 0.7260\n",
      "Epoch 196/1000\n",
      "7000/7000 [==============================] - 1s 83us/step - loss: 1.1229 - accuracy: 0.7430 - val_loss: 1.1472 - val_accuracy: 0.7260\n",
      "Epoch 197/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 1.1211 - accuracy: 0.7437 - val_loss: 1.1463 - val_accuracy: 0.7290\n",
      "Epoch 198/1000\n",
      "7000/7000 [==============================] - 1s 76us/step - loss: 1.1194 - accuracy: 0.7443 - val_loss: 1.1464 - val_accuracy: 0.7320\n",
      "Epoch 199/1000\n",
      "7000/7000 [==============================] - 1s 76us/step - loss: 1.1180 - accuracy: 0.7461 - val_loss: 1.1434 - val_accuracy: 0.7250\n",
      "Epoch 200/1000\n",
      "7000/7000 [==============================] - 1s 88us/step - loss: 1.1153 - accuracy: 0.7439 - val_loss: 1.1469 - val_accuracy: 0.7270\n",
      "Epoch 201/1000\n",
      "7000/7000 [==============================] - 1s 87us/step - loss: 1.1142 - accuracy: 0.7444 - val_loss: 1.1389 - val_accuracy: 0.7270\n",
      "Epoch 202/1000\n",
      "7000/7000 [==============================] - 1s 82us/step - loss: 1.1122 - accuracy: 0.7469 - val_loss: 1.1374 - val_accuracy: 0.7250\n",
      "Epoch 203/1000\n",
      "7000/7000 [==============================] - 1s 72us/step - loss: 1.1103 - accuracy: 0.7463 - val_loss: 1.1427 - val_accuracy: 0.7240\n",
      "Epoch 204/1000\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 1.1083 - accuracy: 0.7441 - val_loss: 1.1391 - val_accuracy: 0.7260\n",
      "Epoch 205/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 1.1070 - accuracy: 0.7473 - val_loss: 1.1400 - val_accuracy: 0.7280\n",
      "Epoch 206/1000\n",
      "7000/7000 [==============================] - 1s 80us/step - loss: 1.1051 - accuracy: 0.7453 - val_loss: 1.1351 - val_accuracy: 0.7270\n",
      "Epoch 207/1000\n",
      "7000/7000 [==============================] - 1s 88us/step - loss: 1.1041 - accuracy: 0.7451 - val_loss: 1.1403 - val_accuracy: 0.7230\n",
      "Epoch 208/1000\n",
      "7000/7000 [==============================] - 1s 87us/step - loss: 1.1019 - accuracy: 0.7477 - val_loss: 1.1294 - val_accuracy: 0.7290\n",
      "Epoch 209/1000\n",
      "7000/7000 [==============================] - 1s 86us/step - loss: 1.1009 - accuracy: 0.7469 - val_loss: 1.1290 - val_accuracy: 0.7310\n",
      "Epoch 210/1000\n",
      "7000/7000 [==============================] - 1s 92us/step - loss: 1.0992 - accuracy: 0.7464 - val_loss: 1.1307 - val_accuracy: 0.7310\n",
      "Epoch 211/1000\n",
      "7000/7000 [==============================] - 1s 80us/step - loss: 1.0980 - accuracy: 0.7474 - val_loss: 1.1274 - val_accuracy: 0.7260\n",
      "Epoch 212/1000\n",
      "7000/7000 [==============================] - 1s 75us/step - loss: 1.0965 - accuracy: 0.7487 - val_loss: 1.1299 - val_accuracy: 0.7280\n",
      "Epoch 213/1000\n",
      "7000/7000 [==============================] - 1s 72us/step - loss: 1.0941 - accuracy: 0.7483 - val_loss: 1.1238 - val_accuracy: 0.7290\n",
      "Epoch 214/1000\n",
      "7000/7000 [==============================] - 1s 75us/step - loss: 1.0928 - accuracy: 0.7464 - val_loss: 1.1219 - val_accuracy: 0.7330\n",
      "Epoch 215/1000\n",
      "7000/7000 [==============================] - 1s 75us/step - loss: 1.0915 - accuracy: 0.7484 - val_loss: 1.1239 - val_accuracy: 0.7280\n",
      "Epoch 216/1000\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 1.0898 - accuracy: 0.7487 - val_loss: 1.1225 - val_accuracy: 0.7290\n",
      "Epoch 217/1000\n",
      "7000/7000 [==============================] - 0s 65us/step - loss: 1.0882 - accuracy: 0.7487 - val_loss: 1.1207 - val_accuracy: 0.7260\n",
      "Epoch 218/1000\n",
      "7000/7000 [==============================] - ETA: 0s - loss: 1.0873 - accuracy: 0.74 - 0s 67us/step - loss: 1.0871 - accuracy: 0.7481 - val_loss: 1.1280 - val_accuracy: 0.7200\n",
      "Epoch 219/1000\n",
      "7000/7000 [==============================] - 1s 80us/step - loss: 1.0863 - accuracy: 0.7473 - val_loss: 1.1146 - val_accuracy: 0.7340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220/1000\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 1.0844 - accuracy: 0.7506 - val_loss: 1.1229 - val_accuracy: 0.7240\n",
      "Epoch 221/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 1.0834 - accuracy: 0.7510 - val_loss: 1.1125 - val_accuracy: 0.7320\n",
      "Epoch 222/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 1.0818 - accuracy: 0.7497 - val_loss: 1.1118 - val_accuracy: 0.7310\n",
      "Epoch 223/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 1.0802 - accuracy: 0.7487 - val_loss: 1.1105 - val_accuracy: 0.7280\n",
      "Epoch 224/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 1.0791 - accuracy: 0.7496 - val_loss: 1.1119 - val_accuracy: 0.7300\n",
      "Epoch 225/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 1.0778 - accuracy: 0.7506 - val_loss: 1.1109 - val_accuracy: 0.7280\n",
      "Epoch 226/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 1.0768 - accuracy: 0.7504 - val_loss: 1.1080 - val_accuracy: 0.7330\n",
      "Epoch 227/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 1.0753 - accuracy: 0.7506 - val_loss: 1.1046 - val_accuracy: 0.7370\n",
      "Epoch 228/1000\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 1.0745 - accuracy: 0.7517 - val_loss: 1.1075 - val_accuracy: 0.7310\n",
      "Epoch 229/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 1.0730 - accuracy: 0.7523 - val_loss: 1.1078 - val_accuracy: 0.7320\n",
      "Epoch 230/1000\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 1.0719 - accuracy: 0.7513 - val_loss: 1.1013 - val_accuracy: 0.7370\n",
      "Epoch 231/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 1.0707 - accuracy: 0.7531 - val_loss: 1.1061 - val_accuracy: 0.7330\n",
      "Epoch 232/1000\n",
      "7000/7000 [==============================] - ETA: 0s - loss: 1.0694 - accuracy: 0.75 - 0s 61us/step - loss: 1.0693 - accuracy: 0.7513 - val_loss: 1.1051 - val_accuracy: 0.7270\n",
      "Epoch 233/1000\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 1.0688 - accuracy: 0.7529 - val_loss: 1.1003 - val_accuracy: 0.7370\n",
      "Epoch 234/1000\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 1.0666 - accuracy: 0.7519 - val_loss: 1.1112 - val_accuracy: 0.7280\n",
      "Epoch 235/1000\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 1.0656 - accuracy: 0.7539 - val_loss: 1.0993 - val_accuracy: 0.7340\n",
      "Epoch 236/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 1.0644 - accuracy: 0.7526 - val_loss: 1.0975 - val_accuracy: 0.7270\n",
      "Epoch 237/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 1.0633 - accuracy: 0.7523 - val_loss: 1.0996 - val_accuracy: 0.7250\n",
      "Epoch 238/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 1.0626 - accuracy: 0.7530 - val_loss: 1.1065 - val_accuracy: 0.7230\n",
      "Epoch 239/1000\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 1.0613 - accuracy: 0.7546 - val_loss: 1.0941 - val_accuracy: 0.7400\n",
      "Epoch 240/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 1.0605 - accuracy: 0.7544 - val_loss: 1.0965 - val_accuracy: 0.7310\n",
      "Epoch 241/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 1.0582 - accuracy: 0.7551 - val_loss: 1.0987 - val_accuracy: 0.7360\n",
      "Epoch 242/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 1.0573 - accuracy: 0.7553 - val_loss: 1.0963 - val_accuracy: 0.7270\n",
      "Epoch 243/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 1.0556 - accuracy: 0.7569 - val_loss: 1.0915 - val_accuracy: 0.7330\n",
      "Epoch 244/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 1.0551 - accuracy: 0.7536 - val_loss: 1.0947 - val_accuracy: 0.7320\n",
      "Epoch 245/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 1.0549 - accuracy: 0.7540 - val_loss: 1.0959 - val_accuracy: 0.7270\n",
      "Epoch 246/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 1.0526 - accuracy: 0.7539 - val_loss: 1.0875 - val_accuracy: 0.7380\n",
      "Epoch 247/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 1.0519 - accuracy: 0.7540 - val_loss: 1.0883 - val_accuracy: 0.7270\n",
      "Epoch 248/1000\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 1.0514 - accuracy: 0.7554 - val_loss: 1.0930 - val_accuracy: 0.7320\n",
      "Epoch 249/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 1.0490 - accuracy: 0.7551 - val_loss: 1.0875 - val_accuracy: 0.7340\n",
      "Epoch 250/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 1.0491 - accuracy: 0.7573 - val_loss: 1.0923 - val_accuracy: 0.7220\n",
      "Epoch 251/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 1.0475 - accuracy: 0.7576 - val_loss: 1.0815 - val_accuracy: 0.7360\n",
      "Epoch 252/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 1.0467 - accuracy: 0.7570 - val_loss: 1.0852 - val_accuracy: 0.7250\n",
      "Epoch 253/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 1.0458 - accuracy: 0.7547 - val_loss: 1.0817 - val_accuracy: 0.7360\n",
      "Epoch 254/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 1.0450 - accuracy: 0.7581 - val_loss: 1.0799 - val_accuracy: 0.7380\n",
      "Epoch 255/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 1.0436 - accuracy: 0.7570 - val_loss: 1.0836 - val_accuracy: 0.7260\n",
      "Epoch 256/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 1.0421 - accuracy: 0.7580 - val_loss: 1.0834 - val_accuracy: 0.7330\n",
      "Epoch 257/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.0407 - accuracy: 0.7560 - val_loss: 1.0800 - val_accuracy: 0.7320\n",
      "Epoch 258/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.0405 - accuracy: 0.7574 - val_loss: 1.0777 - val_accuracy: 0.7330\n",
      "Epoch 259/1000\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 1.0399 - accuracy: 0.7554 - val_loss: 1.0836 - val_accuracy: 0.7350\n",
      "Epoch 260/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.0380 - accuracy: 0.7584 - val_loss: 1.0758 - val_accuracy: 0.7340\n",
      "Epoch 261/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.0373 - accuracy: 0.7573 - val_loss: 1.0806 - val_accuracy: 0.7360\n",
      "Epoch 262/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.0373 - accuracy: 0.7574 - val_loss: 1.0748 - val_accuracy: 0.7290\n",
      "Epoch 263/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.0349 - accuracy: 0.7597 - val_loss: 1.0792 - val_accuracy: 0.7360\n",
      "Epoch 264/1000\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 1.0341 - accuracy: 0.7584 - val_loss: 1.0786 - val_accuracy: 0.7410\n",
      "Epoch 265/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.0333 - accuracy: 0.7594 - val_loss: 1.0741 - val_accuracy: 0.7410\n",
      "Epoch 266/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.0322 - accuracy: 0.7583 - val_loss: 1.0708 - val_accuracy: 0.7340\n",
      "Epoch 267/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.0320 - accuracy: 0.7604 - val_loss: 1.0727 - val_accuracy: 0.7360\n",
      "Epoch 268/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 1.0303 - accuracy: 0.7597 - val_loss: 1.0724 - val_accuracy: 0.7430\n",
      "Epoch 269/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.0286 - accuracy: 0.7591 - val_loss: 1.0686 - val_accuracy: 0.7370\n",
      "Epoch 270/1000\n",
      "7000/7000 [==============================] - 0s 53us/step - loss: 1.0280 - accuracy: 0.7601 - val_loss: 1.0759 - val_accuracy: 0.7380\n",
      "Epoch 271/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.0276 - accuracy: 0.7599 - val_loss: 1.0771 - val_accuracy: 0.7280\n",
      "Epoch 272/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.0271 - accuracy: 0.7580 - val_loss: 1.0729 - val_accuracy: 0.7290\n",
      "Epoch 273/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 1.0258 - accuracy: 0.7580 - val_loss: 1.0712 - val_accuracy: 0.7300\n",
      "Epoch 274/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 1.0241 - accuracy: 0.7599 - val_loss: 1.0685 - val_accuracy: 0.7390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 275/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 1.0235 - accuracy: 0.7619 - val_loss: 1.0721 - val_accuracy: 0.7370\n",
      "Epoch 276/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.0223 - accuracy: 0.7620 - val_loss: 1.0741 - val_accuracy: 0.7350\n",
      "Epoch 277/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.0220 - accuracy: 0.7600 - val_loss: 1.0622 - val_accuracy: 0.7360\n",
      "Epoch 278/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.0203 - accuracy: 0.7590 - val_loss: 1.0675 - val_accuracy: 0.7350\n",
      "Epoch 279/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.0202 - accuracy: 0.7599 - val_loss: 1.0676 - val_accuracy: 0.7360\n",
      "Epoch 280/1000\n",
      "7000/7000 [==============================] - 0s 52us/step - loss: 1.0196 - accuracy: 0.7610 - val_loss: 1.0642 - val_accuracy: 0.7340\n",
      "Epoch 281/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.0183 - accuracy: 0.7616 - val_loss: 1.0656 - val_accuracy: 0.7310\n",
      "Epoch 282/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.0174 - accuracy: 0.7610 - val_loss: 1.0596 - val_accuracy: 0.7380\n",
      "Epoch 283/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.0164 - accuracy: 0.7613 - val_loss: 1.0607 - val_accuracy: 0.7440\n",
      "Epoch 284/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.0153 - accuracy: 0.7603 - val_loss: 1.0576 - val_accuracy: 0.7370\n",
      "Epoch 285/1000\n",
      "7000/7000 [==============================] - 0s 52us/step - loss: 1.0142 - accuracy: 0.7600 - val_loss: 1.0621 - val_accuracy: 0.7380\n",
      "Epoch 286/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.0138 - accuracy: 0.7633 - val_loss: 1.0569 - val_accuracy: 0.7400\n",
      "Epoch 287/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.0122 - accuracy: 0.7617 - val_loss: 1.0598 - val_accuracy: 0.7410\n",
      "Epoch 288/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.0116 - accuracy: 0.7613 - val_loss: 1.0566 - val_accuracy: 0.7370\n",
      "Epoch 289/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.0115 - accuracy: 0.7609 - val_loss: 1.0538 - val_accuracy: 0.7370\n",
      "Epoch 290/1000\n",
      "7000/7000 [==============================] - 0s 52us/step - loss: 1.0107 - accuracy: 0.7609 - val_loss: 1.0603 - val_accuracy: 0.7370\n",
      "Epoch 291/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.0102 - accuracy: 0.7623 - val_loss: 1.0553 - val_accuracy: 0.7390\n",
      "Epoch 292/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.0086 - accuracy: 0.7607 - val_loss: 1.0542 - val_accuracy: 0.7410\n",
      "Epoch 293/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.0075 - accuracy: 0.7637 - val_loss: 1.0554 - val_accuracy: 0.7350\n",
      "Epoch 294/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.0071 - accuracy: 0.7603 - val_loss: 1.0521 - val_accuracy: 0.7380\n",
      "Epoch 295/1000\n",
      "7000/7000 [==============================] - 0s 53us/step - loss: 1.0069 - accuracy: 0.7623 - val_loss: 1.0529 - val_accuracy: 0.7370\n",
      "Epoch 296/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.0055 - accuracy: 0.7657 - val_loss: 1.0471 - val_accuracy: 0.7430\n",
      "Epoch 297/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.0041 - accuracy: 0.7631 - val_loss: 1.0524 - val_accuracy: 0.7420\n",
      "Epoch 298/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.0039 - accuracy: 0.7619 - val_loss: 1.0499 - val_accuracy: 0.7400\n",
      "Epoch 299/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.0037 - accuracy: 0.7640 - val_loss: 1.0490 - val_accuracy: 0.7380\n",
      "Epoch 300/1000\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 1.0025 - accuracy: 0.7629 - val_loss: 1.0500 - val_accuracy: 0.7360\n",
      "Epoch 301/1000\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 1.0016 - accuracy: 0.7656 - val_loss: 1.0479 - val_accuracy: 0.7440\n",
      "Epoch 302/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.0013 - accuracy: 0.7631 - val_loss: 1.0511 - val_accuracy: 0.7440\n",
      "Epoch 303/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.9996 - accuracy: 0.7650 - val_loss: 1.0524 - val_accuracy: 0.7380\n",
      "Epoch 304/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.9999 - accuracy: 0.7654 - val_loss: 1.0507 - val_accuracy: 0.7300\n",
      "Epoch 305/1000\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 0.9998 - accuracy: 0.7633 - val_loss: 1.0468 - val_accuracy: 0.7380\n",
      "Epoch 306/1000\n",
      "7000/7000 [==============================] - 0s 53us/step - loss: 0.9986 - accuracy: 0.7647 - val_loss: 1.0469 - val_accuracy: 0.7350\n",
      "Epoch 307/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.9973 - accuracy: 0.7650 - val_loss: 1.0464 - val_accuracy: 0.7390\n",
      "Epoch 308/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.9961 - accuracy: 0.7639 - val_loss: 1.0463 - val_accuracy: 0.7380\n",
      "Epoch 309/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.9950 - accuracy: 0.7650 - val_loss: 1.0421 - val_accuracy: 0.7420\n",
      "Epoch 310/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.9952 - accuracy: 0.7653 - val_loss: 1.0441 - val_accuracy: 0.7420\n",
      "Epoch 311/1000\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 0.9935 - accuracy: 0.7671 - val_loss: 1.0421 - val_accuracy: 0.7420\n",
      "Epoch 312/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.9931 - accuracy: 0.7650 - val_loss: 1.0468 - val_accuracy: 0.7450\n",
      "Epoch 313/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.9929 - accuracy: 0.7671 - val_loss: 1.0443 - val_accuracy: 0.7320\n",
      "Epoch 314/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.9925 - accuracy: 0.7676 - val_loss: 1.0428 - val_accuracy: 0.7450\n",
      "Epoch 315/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.9906 - accuracy: 0.7666 - val_loss: 1.0429 - val_accuracy: 0.7470\n",
      "Epoch 316/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.9902 - accuracy: 0.7676 - val_loss: 1.0384 - val_accuracy: 0.7410\n",
      "Epoch 317/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.9897 - accuracy: 0.7673 - val_loss: 1.0439 - val_accuracy: 0.7350\n",
      "Epoch 318/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.9889 - accuracy: 0.7680 - val_loss: 1.0403 - val_accuracy: 0.7410\n",
      "Epoch 319/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.9882 - accuracy: 0.7676 - val_loss: 1.0409 - val_accuracy: 0.7430\n",
      "Epoch 320/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.9880 - accuracy: 0.7669 - val_loss: 1.0402 - val_accuracy: 0.7430\n",
      "Epoch 321/1000\n",
      "7000/7000 [==============================] - 0s 53us/step - loss: 0.9869 - accuracy: 0.7676 - val_loss: 1.0410 - val_accuracy: 0.7400\n",
      "Epoch 322/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.9858 - accuracy: 0.7676 - val_loss: 1.0361 - val_accuracy: 0.7440\n",
      "Epoch 323/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.9855 - accuracy: 0.7670 - val_loss: 1.0403 - val_accuracy: 0.7410\n",
      "Epoch 324/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.9851 - accuracy: 0.7681 - val_loss: 1.0387 - val_accuracy: 0.7360\n",
      "Epoch 325/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.9844 - accuracy: 0.7671 - val_loss: 1.0334 - val_accuracy: 0.7400\n",
      "Epoch 326/1000\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 0.9841 - accuracy: 0.7670 - val_loss: 1.0369 - val_accuracy: 0.7380\n",
      "Epoch 327/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.9826 - accuracy: 0.7671 - val_loss: 1.0401 - val_accuracy: 0.7400\n",
      "Epoch 328/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.9814 - accuracy: 0.7683 - val_loss: 1.0436 - val_accuracy: 0.7410\n",
      "Epoch 329/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.9824 - accuracy: 0.7660 - val_loss: 1.0341 - val_accuracy: 0.7390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 330/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.9809 - accuracy: 0.7679 - val_loss: 1.0420 - val_accuracy: 0.7410\n",
      "Epoch 331/1000\n",
      "7000/7000 [==============================] - 0s 52us/step - loss: 0.9821 - accuracy: 0.7677 - val_loss: 1.0392 - val_accuracy: 0.7390\n",
      "Epoch 332/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.9800 - accuracy: 0.7703 - val_loss: 1.0320 - val_accuracy: 0.7400\n",
      "Epoch 333/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.9784 - accuracy: 0.7679 - val_loss: 1.0320 - val_accuracy: 0.7470\n",
      "Epoch 334/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.9784 - accuracy: 0.7666 - val_loss: 1.0289 - val_accuracy: 0.7450\n",
      "Epoch 335/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.9771 - accuracy: 0.7711 - val_loss: 1.0474 - val_accuracy: 0.7480\n",
      "Epoch 336/1000\n",
      "7000/7000 [==============================] - 0s 53us/step - loss: 0.9775 - accuracy: 0.7707 - val_loss: 1.0480 - val_accuracy: 0.7430\n",
      "Epoch 337/1000\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 0.9774 - accuracy: 0.7689 - val_loss: 1.0267 - val_accuracy: 0.7410\n",
      "Epoch 338/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.9760 - accuracy: 0.7704 - val_loss: 1.0291 - val_accuracy: 0.7450\n",
      "Epoch 339/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.9754 - accuracy: 0.7694 - val_loss: 1.0338 - val_accuracy: 0.7480\n",
      "Epoch 340/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.9753 - accuracy: 0.7723 - val_loss: 1.0349 - val_accuracy: 0.7460\n",
      "Epoch 341/1000\n",
      "7000/7000 [==============================] - 0s 53us/step - loss: 0.9732 - accuracy: 0.7696 - val_loss: 1.0300 - val_accuracy: 0.7390\n",
      "Epoch 342/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.9744 - accuracy: 0.7687 - val_loss: 1.0332 - val_accuracy: 0.7510\n",
      "Epoch 343/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.9720 - accuracy: 0.7709 - val_loss: 1.0275 - val_accuracy: 0.7360\n",
      "Epoch 344/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.9723 - accuracy: 0.7701 - val_loss: 1.0252 - val_accuracy: 0.7460\n",
      "Epoch 345/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.9714 - accuracy: 0.7700 - val_loss: 1.0307 - val_accuracy: 0.7410\n",
      "Epoch 346/1000\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 0.9718 - accuracy: 0.7700 - val_loss: 1.0296 - val_accuracy: 0.7360\n",
      "Epoch 347/1000\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 0.9710 - accuracy: 0.7723 - val_loss: 1.0238 - val_accuracy: 0.7430\n",
      "Epoch 348/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.9697 - accuracy: 0.7714 - val_loss: 1.0274 - val_accuracy: 0.7320\n",
      "Epoch 349/1000\n",
      "7000/7000 [==============================] - 0s 64us/step - loss: 0.9695 - accuracy: 0.7694 - val_loss: 1.0267 - val_accuracy: 0.7440\n",
      "Epoch 350/1000\n",
      "7000/7000 [==============================] - 1s 82us/step - loss: 0.9686 - accuracy: 0.7706 - val_loss: 1.0207 - val_accuracy: 0.7450\n",
      "Epoch 351/1000\n",
      "7000/7000 [==============================] - 1s 92us/step - loss: 0.9675 - accuracy: 0.7719 - val_loss: 1.0352 - val_accuracy: 0.7500\n",
      "Epoch 352/1000\n",
      "7000/7000 [==============================] - 1s 92us/step - loss: 0.9683 - accuracy: 0.7691 - val_loss: 1.0240 - val_accuracy: 0.7460\n",
      "Epoch 353/1000\n",
      "7000/7000 [==============================] - 1s 84us/step - loss: 0.9668 - accuracy: 0.7720 - val_loss: 1.0272 - val_accuracy: 0.7470\n",
      "Epoch 354/1000\n",
      "7000/7000 [==============================] - 1s 74us/step - loss: 0.9668 - accuracy: 0.7719 - val_loss: 1.0218 - val_accuracy: 0.7420\n",
      "Epoch 355/1000\n",
      "7000/7000 [==============================] - 1s 74us/step - loss: 0.9655 - accuracy: 0.7720 - val_loss: 1.0177 - val_accuracy: 0.7500\n",
      "Epoch 356/1000\n",
      "7000/7000 [==============================] - 0s 66us/step - loss: 0.9650 - accuracy: 0.7709 - val_loss: 1.0187 - val_accuracy: 0.7450\n",
      "Epoch 357/1000\n",
      "7000/7000 [==============================] - 0s 67us/step - loss: 0.9655 - accuracy: 0.7704 - val_loss: 1.0265 - val_accuracy: 0.7460\n",
      "Epoch 358/1000\n",
      "7000/7000 [==============================] - 0s 64us/step - loss: 0.9640 - accuracy: 0.7729 - val_loss: 1.0246 - val_accuracy: 0.7400\n",
      "Epoch 359/1000\n",
      "7000/7000 [==============================] - 0s 67us/step - loss: 0.9635 - accuracy: 0.7719 - val_loss: 1.0402 - val_accuracy: 0.7420\n",
      "Epoch 360/1000\n",
      "7000/7000 [==============================] - 1s 76us/step - loss: 0.9632 - accuracy: 0.7716 - val_loss: 1.0222 - val_accuracy: 0.7410\n",
      "Epoch 361/1000\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 0.9618 - accuracy: 0.7723 - val_loss: 1.0226 - val_accuracy: 0.7430\n",
      "Epoch 362/1000\n",
      "7000/7000 [==============================] - 0s 68us/step - loss: 0.9611 - accuracy: 0.7711 - val_loss: 1.0305 - val_accuracy: 0.7460\n",
      "Epoch 363/1000\n",
      "7000/7000 [==============================] - 1s 78us/step - loss: 0.9615 - accuracy: 0.7733 - val_loss: 1.0337 - val_accuracy: 0.7450\n",
      "Epoch 364/1000\n",
      "7000/7000 [==============================] - 1s 72us/step - loss: 0.9607 - accuracy: 0.7730 - val_loss: 1.0154 - val_accuracy: 0.7500\n",
      "Epoch 365/1000\n",
      "7000/7000 [==============================] - 1s 77us/step - loss: 0.9606 - accuracy: 0.7711 - val_loss: 1.0219 - val_accuracy: 0.7380\n",
      "Epoch 366/1000\n",
      "7000/7000 [==============================] - 1s 74us/step - loss: 0.9603 - accuracy: 0.7730 - val_loss: 1.0225 - val_accuracy: 0.7370\n",
      "Epoch 367/1000\n",
      "7000/7000 [==============================] - 0s 68us/step - loss: 0.9595 - accuracy: 0.7714 - val_loss: 1.0147 - val_accuracy: 0.7480\n",
      "Epoch 368/1000\n",
      "7000/7000 [==============================] - 1s 80us/step - loss: 0.9585 - accuracy: 0.7731 - val_loss: 1.0147 - val_accuracy: 0.7480\n",
      "Epoch 369/1000\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 0.9576 - accuracy: 0.7719 - val_loss: 1.0171 - val_accuracy: 0.7470\n",
      "Epoch 370/1000\n",
      "7000/7000 [==============================] - 0s 67us/step - loss: 0.9588 - accuracy: 0.7714 - val_loss: 1.0231 - val_accuracy: 0.7490\n",
      "Epoch 371/1000\n",
      "7000/7000 [==============================] - 1s 77us/step - loss: 0.9576 - accuracy: 0.7723 - val_loss: 1.0144 - val_accuracy: 0.7460\n",
      "Epoch 372/1000\n",
      "7000/7000 [==============================] - 1s 78us/step - loss: 0.9566 - accuracy: 0.7706 - val_loss: 1.0198 - val_accuracy: 0.7480\n",
      "Epoch 373/1000\n",
      "7000/7000 [==============================] - 1s 76us/step - loss: 0.9560 - accuracy: 0.7740 - val_loss: 1.0187 - val_accuracy: 0.7450\n",
      "Epoch 374/1000\n",
      "7000/7000 [==============================] - 1s 74us/step - loss: 0.9557 - accuracy: 0.7727 - val_loss: 1.0145 - val_accuracy: 0.7480\n",
      "Epoch 375/1000\n",
      "7000/7000 [==============================] - 1s 77us/step - loss: 0.9556 - accuracy: 0.7730 - val_loss: 1.0218 - val_accuracy: 0.7450\n",
      "Epoch 376/1000\n",
      "7000/7000 [==============================] - 1s 72us/step - loss: 0.9551 - accuracy: 0.7740 - val_loss: 1.0148 - val_accuracy: 0.7480\n",
      "Epoch 377/1000\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 0.9549 - accuracy: 0.7737 - val_loss: 1.0125 - val_accuracy: 0.7500\n",
      "Epoch 378/1000\n",
      "7000/7000 [==============================] - 0s 65us/step - loss: 0.9529 - accuracy: 0.7774 - val_loss: 1.0250 - val_accuracy: 0.7460\n",
      "Epoch 379/1000\n",
      "7000/7000 [==============================] - 0s 68us/step - loss: 0.9535 - accuracy: 0.7743 - val_loss: 1.0121 - val_accuracy: 0.7480\n",
      "Epoch 380/1000\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 0.9529 - accuracy: 0.7721 - val_loss: 1.0125 - val_accuracy: 0.7500\n",
      "Epoch 381/1000\n",
      "7000/7000 [==============================] - 0s 67us/step - loss: 0.9519 - accuracy: 0.7733 - val_loss: 1.0203 - val_accuracy: 0.7320\n",
      "Epoch 382/1000\n",
      "7000/7000 [==============================] - 0s 67us/step - loss: 0.9524 - accuracy: 0.7727 - val_loss: 1.0135 - val_accuracy: 0.7450\n",
      "Epoch 383/1000\n",
      "7000/7000 [==============================] - 0s 68us/step - loss: 0.9530 - accuracy: 0.7737 - val_loss: 1.0124 - val_accuracy: 0.7490\n",
      "Epoch 384/1000\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 0.9515 - accuracy: 0.7737 - val_loss: 1.0122 - val_accuracy: 0.7420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 385/1000\n",
      "7000/7000 [==============================] - 0s 68us/step - loss: 0.9509 - accuracy: 0.7746 - val_loss: 1.0209 - val_accuracy: 0.7440\n",
      "Epoch 386/1000\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 0.9505 - accuracy: 0.7743 - val_loss: 1.0139 - val_accuracy: 0.7520\n",
      "Epoch 387/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.9488 - accuracy: 0.7739 - val_loss: 1.0079 - val_accuracy: 0.7490\n",
      "Epoch 388/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.9487 - accuracy: 0.7730 - val_loss: 1.0094 - val_accuracy: 0.7470\n",
      "Epoch 389/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.9477 - accuracy: 0.7764 - val_loss: 1.0190 - val_accuracy: 0.7540\n",
      "Epoch 390/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.9467 - accuracy: 0.7751 - val_loss: 1.0118 - val_accuracy: 0.7360\n",
      "Epoch 391/1000\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 0.9473 - accuracy: 0.7736 - val_loss: 1.0127 - val_accuracy: 0.7420\n",
      "Epoch 392/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.9461 - accuracy: 0.7746 - val_loss: 1.0092 - val_accuracy: 0.7450\n",
      "Epoch 393/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.9455 - accuracy: 0.7756 - val_loss: 1.0118 - val_accuracy: 0.7510\n",
      "Epoch 394/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.9457 - accuracy: 0.7770 - val_loss: 1.0052 - val_accuracy: 0.7490\n",
      "Epoch 395/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.9446 - accuracy: 0.7753 - val_loss: 1.0129 - val_accuracy: 0.7410\n",
      "Epoch 396/1000\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 0.9448 - accuracy: 0.7770 - val_loss: 1.0141 - val_accuracy: 0.7360\n",
      "Epoch 397/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.9448 - accuracy: 0.7749 - val_loss: 1.0254 - val_accuracy: 0.7360\n",
      "Epoch 398/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.9442 - accuracy: 0.7733 - val_loss: 1.0058 - val_accuracy: 0.7400\n",
      "Epoch 399/1000\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 0.9442 - accuracy: 0.7749 - val_loss: 1.0069 - val_accuracy: 0.7440\n",
      "Epoch 400/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.9429 - accuracy: 0.7747 - val_loss: 1.0148 - val_accuracy: 0.7510\n",
      "Epoch 401/1000\n",
      "7000/7000 [==============================] - 0s 52us/step - loss: 0.9415 - accuracy: 0.7753 - val_loss: 1.0034 - val_accuracy: 0.7500\n",
      "Epoch 402/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.9407 - accuracy: 0.7771 - val_loss: 1.0067 - val_accuracy: 0.7510\n",
      "Epoch 403/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.9411 - accuracy: 0.7749 - val_loss: 1.0032 - val_accuracy: 0.7500\n",
      "Epoch 404/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.9404 - accuracy: 0.7769 - val_loss: 1.0110 - val_accuracy: 0.7470\n",
      "Epoch 405/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.9408 - accuracy: 0.7746 - val_loss: 1.0170 - val_accuracy: 0.7460\n",
      "Epoch 406/1000\n",
      "7000/7000 [==============================] - 0s 52us/step - loss: 0.9407 - accuracy: 0.7747 - val_loss: 1.0012 - val_accuracy: 0.7460\n",
      "Epoch 407/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.9392 - accuracy: 0.7751 - val_loss: 1.0083 - val_accuracy: 0.7530\n",
      "Epoch 408/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.9398 - accuracy: 0.7766 - val_loss: 1.0256 - val_accuracy: 0.7360\n",
      "Epoch 409/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.9400 - accuracy: 0.7781 - val_loss: 1.0403 - val_accuracy: 0.7330\n",
      "Epoch 410/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.9382 - accuracy: 0.7757 - val_loss: 1.0058 - val_accuracy: 0.7420\n",
      "Epoch 411/1000\n",
      "7000/7000 [==============================] - 0s 53us/step - loss: 0.9371 - accuracy: 0.7770 - val_loss: 1.0001 - val_accuracy: 0.7460\n",
      "Epoch 412/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.9362 - accuracy: 0.7769 - val_loss: 1.0106 - val_accuracy: 0.7480\n",
      "Epoch 413/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.9356 - accuracy: 0.7770 - val_loss: 1.0000 - val_accuracy: 0.7480\n",
      "Epoch 414/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.9360 - accuracy: 0.7767 - val_loss: 1.0045 - val_accuracy: 0.7490\n",
      "Epoch 415/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.9353 - accuracy: 0.7746 - val_loss: 0.9991 - val_accuracy: 0.7450\n",
      "Epoch 416/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.9350 - accuracy: 0.7764 - val_loss: 0.9996 - val_accuracy: 0.7430\n",
      "Epoch 417/1000\n",
      "7000/7000 [==============================] - 1s 73us/step - loss: 0.9343 - accuracy: 0.7790 - val_loss: 1.0251 - val_accuracy: 0.7440\n",
      "Epoch 418/1000\n",
      "7000/7000 [==============================] - 1s 75us/step - loss: 0.9347 - accuracy: 0.7784 - val_loss: 1.0162 - val_accuracy: 0.7460\n",
      "Epoch 419/1000\n",
      "7000/7000 [==============================] - 1s 88us/step - loss: 0.9337 - accuracy: 0.7787 - val_loss: 1.0030 - val_accuracy: 0.7430\n",
      "Epoch 420/1000\n",
      "7000/7000 [==============================] - 1s 77us/step - loss: 0.9337 - accuracy: 0.7787 - val_loss: 0.9971 - val_accuracy: 0.7540\n",
      "Epoch 421/1000\n",
      "7000/7000 [==============================] - 1s 76us/step - loss: 0.9326 - accuracy: 0.7784 - val_loss: 0.9966 - val_accuracy: 0.7460\n",
      "Epoch 422/1000\n",
      "7000/7000 [==============================] - 1s 76us/step - loss: 0.9325 - accuracy: 0.7763 - val_loss: 1.0026 - val_accuracy: 0.7530\n",
      "Epoch 423/1000\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 0.9323 - accuracy: 0.7746 - val_loss: 1.0213 - val_accuracy: 0.7400\n",
      "Epoch 424/1000\n",
      "7000/7000 [==============================] - 0s 64us/step - loss: 0.9319 - accuracy: 0.7783 - val_loss: 1.0064 - val_accuracy: 0.7520\n",
      "Epoch 425/1000\n",
      "7000/7000 [==============================] - 0s 68us/step - loss: 0.9312 - accuracy: 0.7784 - val_loss: 0.9969 - val_accuracy: 0.7460\n",
      "Epoch 426/1000\n",
      "7000/7000 [==============================] - 1s 72us/step - loss: 0.9289 - accuracy: 0.7800 - val_loss: 1.0126 - val_accuracy: 0.7380\n",
      "Epoch 427/1000\n",
      "7000/7000 [==============================] - 0s 71us/step - loss: 0.9313 - accuracy: 0.7771 - val_loss: 1.0019 - val_accuracy: 0.7390\n",
      "Epoch 428/1000\n",
      "7000/7000 [==============================] - 0s 71us/step - loss: 0.9305 - accuracy: 0.7791 - val_loss: 0.9963 - val_accuracy: 0.7460\n",
      "Epoch 429/1000\n",
      "7000/7000 [==============================] - 1s 78us/step - loss: 0.9292 - accuracy: 0.7794 - val_loss: 1.0130 - val_accuracy: 0.7490\n",
      "Epoch 430/1000\n",
      "7000/7000 [==============================] - 1s 76us/step - loss: 0.9280 - accuracy: 0.7759 - val_loss: 1.0277 - val_accuracy: 0.7240\n",
      "Epoch 431/1000\n",
      "7000/7000 [==============================] - 1s 75us/step - loss: 0.9310 - accuracy: 0.7790 - val_loss: 0.9949 - val_accuracy: 0.7490\n",
      "Epoch 432/1000\n",
      "7000/7000 [==============================] - 0s 65us/step - loss: 0.9273 - accuracy: 0.7800 - val_loss: 1.0056 - val_accuracy: 0.7510 0s - loss: 0.9240 - accuracy: 0.77\n",
      "Epoch 433/1000\n",
      "7000/7000 [==============================] - 0s 68us/step - loss: 0.9278 - accuracy: 0.7784 - val_loss: 1.0021 - val_accuracy: 0.7500\n",
      "Epoch 434/1000\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 0.9269 - accuracy: 0.7776 - val_loss: 1.0044 - val_accuracy: 0.7580\n",
      "Epoch 435/1000\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 0.9264 - accuracy: 0.7781 - val_loss: 0.9946 - val_accuracy: 0.7460\n",
      "Epoch 436/1000\n",
      "7000/7000 [==============================] - 0s 67us/step - loss: 0.9271 - accuracy: 0.7776 - val_loss: 0.9938 - val_accuracy: 0.7450\n",
      "Epoch 437/1000\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 0.9261 - accuracy: 0.7786 - val_loss: 1.0026 - val_accuracy: 0.7430\n",
      "Epoch 438/1000\n",
      "7000/7000 [==============================] - 1s 79us/step - loss: 0.9245 - accuracy: 0.7804 - val_loss: 0.9945 - val_accuracy: 0.7460\n",
      "Epoch 439/1000\n",
      "7000/7000 [==============================] - 1s 77us/step - loss: 0.9252 - accuracy: 0.7804 - val_loss: 0.9965 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 440/1000\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 0.9247 - accuracy: 0.7776 - val_loss: 1.0087 - val_accuracy: 0.7510\n",
      "Epoch 441/1000\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 0.9250 - accuracy: 0.7783 - val_loss: 1.0004 - val_accuracy: 0.7470\n",
      "Epoch 442/1000\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 0.9237 - accuracy: 0.7794 - val_loss: 1.0005 - val_accuracy: 0.7450\n",
      "Epoch 443/1000\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 0.9224 - accuracy: 0.7783 - val_loss: 0.9947 - val_accuracy: 0.7520\n",
      "Epoch 444/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.9217 - accuracy: 0.7794 - val_loss: 1.0149 - val_accuracy: 0.7370\n",
      "Epoch 445/1000\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 0.9226 - accuracy: 0.7794 - val_loss: 0.9974 - val_accuracy: 0.7530\n",
      "Epoch 446/1000\n",
      "7000/7000 [==============================] - 0s 64us/step - loss: 0.9217 - accuracy: 0.7799 - val_loss: 0.9940 - val_accuracy: 0.7480\n",
      "Epoch 447/1000\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 0.9205 - accuracy: 0.7820 - val_loss: 1.0443 - val_accuracy: 0.7340\n",
      "Epoch 448/1000\n",
      "7000/7000 [==============================] - 0s 68us/step - loss: 0.9222 - accuracy: 0.7789 - val_loss: 0.9971 - val_accuracy: 0.7500\n",
      "Epoch 449/1000\n",
      "7000/7000 [==============================] - 0s 71us/step - loss: 0.9224 - accuracy: 0.7777 - val_loss: 1.0034 - val_accuracy: 0.7400\n",
      "Epoch 450/1000\n",
      "7000/7000 [==============================] - 1s 76us/step - loss: 0.9206 - accuracy: 0.7804 - val_loss: 0.9969 - val_accuracy: 0.7530\n",
      "Epoch 451/1000\n",
      "7000/7000 [==============================] - 1s 77us/step - loss: 0.9207 - accuracy: 0.7797 - val_loss: 0.9944 - val_accuracy: 0.7480\n",
      "Epoch 452/1000\n",
      "7000/7000 [==============================] - 0s 66us/step - loss: 0.9185 - accuracy: 0.7794 - val_loss: 0.9888 - val_accuracy: 0.7460\n",
      "Epoch 453/1000\n",
      "7000/7000 [==============================] - 1s 72us/step - loss: 0.9190 - accuracy: 0.7806 - val_loss: 0.9943 - val_accuracy: 0.7420\n",
      "Epoch 454/1000\n",
      "7000/7000 [==============================] - 0s 66us/step - loss: 0.9182 - accuracy: 0.7791 - val_loss: 0.9910 - val_accuracy: 0.7460\n",
      "Epoch 455/1000\n",
      "7000/7000 [==============================] - 1s 74us/step - loss: 0.9192 - accuracy: 0.7779 - val_loss: 0.9954 - val_accuracy: 0.7470\n",
      "Epoch 456/1000\n",
      "7000/7000 [==============================] - 1s 72us/step - loss: 0.9175 - accuracy: 0.7793 - val_loss: 1.0016 - val_accuracy: 0.7340\n",
      "Epoch 457/1000\n",
      "7000/7000 [==============================] - 1s 75us/step - loss: 0.9162 - accuracy: 0.7800 - val_loss: 0.9898 - val_accuracy: 0.7480\n",
      "Epoch 458/1000\n",
      "7000/7000 [==============================] - 0s 68us/step - loss: 0.9159 - accuracy: 0.7809 - val_loss: 0.9905 - val_accuracy: 0.7400\n",
      "Epoch 459/1000\n",
      "7000/7000 [==============================] - 1s 73us/step - loss: 0.9165 - accuracy: 0.7810 - val_loss: 0.9862 - val_accuracy: 0.7520\n",
      "Epoch 460/1000\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 0.9164 - accuracy: 0.7804 - val_loss: 0.9852 - val_accuracy: 0.7520\n",
      "Epoch 461/1000\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 0.9154 - accuracy: 0.7784 - val_loss: 0.9895 - val_accuracy: 0.7520\n",
      "Epoch 462/1000\n",
      "7000/7000 [==============================] - 0s 66us/step - loss: 0.9171 - accuracy: 0.7813 - val_loss: 0.9871 - val_accuracy: 0.7460\n",
      "Epoch 463/1000\n",
      "7000/7000 [==============================] - 0s 65us/step - loss: 0.9136 - accuracy: 0.7823 - val_loss: 0.9909 - val_accuracy: 0.7470\n",
      "Epoch 464/1000\n",
      "7000/7000 [==============================] - 1s 73us/step - loss: 0.9140 - accuracy: 0.7817 - val_loss: 0.9873 - val_accuracy: 0.7510\n",
      "Epoch 465/1000\n",
      "7000/7000 [==============================] - 1s 73us/step - loss: 0.9128 - accuracy: 0.7803 - val_loss: 0.9915 - val_accuracy: 0.7520\n",
      "Epoch 466/1000\n",
      "7000/7000 [==============================] - 0s 65us/step - loss: 0.9132 - accuracy: 0.7796 - val_loss: 0.9882 - val_accuracy: 0.7490\n",
      "Epoch 467/1000\n",
      "7000/7000 [==============================] - 0s 68us/step - loss: 0.9128 - accuracy: 0.7816 - val_loss: 0.9866 - val_accuracy: 0.7600\n",
      "Epoch 468/1000\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 0.9127 - accuracy: 0.7790 - val_loss: 0.9843 - val_accuracy: 0.7540\n",
      "Epoch 469/1000\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 0.9118 - accuracy: 0.7796 - val_loss: 0.9862 - val_accuracy: 0.7440\n",
      "Epoch 470/1000\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 0.9113 - accuracy: 0.7810 - val_loss: 0.9921 - val_accuracy: 0.7520\n",
      "Epoch 471/1000\n",
      "7000/7000 [==============================] - 1s 75us/step - loss: 0.9121 - accuracy: 0.7806 - val_loss: 0.9917 - val_accuracy: 0.7530\n",
      "Epoch 472/1000\n",
      "7000/7000 [==============================] - 1s 88us/step - loss: 0.9136 - accuracy: 0.7809 - val_loss: 0.9928 - val_accuracy: 0.7500\n",
      "Epoch 473/1000\n",
      "7000/7000 [==============================] - 1s 78us/step - loss: 0.9107 - accuracy: 0.7817 - val_loss: 0.9906 - val_accuracy: 0.7560\n",
      "Epoch 474/1000\n",
      "7000/7000 [==============================] - 1s 84us/step - loss: 0.9133 - accuracy: 0.7810 - val_loss: 1.0199 - val_accuracy: 0.7460\n",
      "Epoch 475/1000\n",
      "7000/7000 [==============================] - 1s 83us/step - loss: 0.9121 - accuracy: 0.7791 - val_loss: 0.9885 - val_accuracy: 0.7530\n",
      "Epoch 476/1000\n",
      "7000/7000 [==============================] - 1s 73us/step - loss: 0.9097 - accuracy: 0.7807 - val_loss: 0.9897 - val_accuracy: 0.7550\n",
      "Epoch 477/1000\n",
      "7000/7000 [==============================] - 1s 72us/step - loss: 0.9096 - accuracy: 0.7813 - val_loss: 0.9959 - val_accuracy: 0.7490\n",
      "Epoch 478/1000\n",
      "7000/7000 [==============================] - 1s 80us/step - loss: 0.9104 - accuracy: 0.7801 - val_loss: 0.9987 - val_accuracy: 0.7560\n",
      "Epoch 479/1000\n",
      "7000/7000 [==============================] - 1s 75us/step - loss: 0.9101 - accuracy: 0.7807 - val_loss: 0.9836 - val_accuracy: 0.7510\n",
      "Epoch 480/1000\n",
      "7000/7000 [==============================] - 0s 67us/step - loss: 0.9093 - accuracy: 0.7820 - val_loss: 0.9851 - val_accuracy: 0.7490\n",
      "Epoch 481/1000\n",
      "7000/7000 [==============================] - 0s 71us/step - loss: 0.9078 - accuracy: 0.7806 - val_loss: 0.9843 - val_accuracy: 0.7520\n",
      "Epoch 482/1000\n",
      "7000/7000 [==============================] - 1s 74us/step - loss: 0.9080 - accuracy: 0.7803 - val_loss: 0.9899 - val_accuracy: 0.7550\n",
      "Epoch 483/1000\n",
      "7000/7000 [==============================] - 1s 72us/step - loss: 0.9079 - accuracy: 0.7830 - val_loss: 0.9800 - val_accuracy: 0.7500\n",
      "Epoch 484/1000\n",
      "7000/7000 [==============================] - 1s 76us/step - loss: 0.9075 - accuracy: 0.7804 - val_loss: 0.9864 - val_accuracy: 0.7480\n",
      "Epoch 485/1000\n",
      "7000/7000 [==============================] - 1s 81us/step - loss: 0.9062 - accuracy: 0.7823 - val_loss: 0.9880 - val_accuracy: 0.7460\n",
      "Epoch 486/1000\n",
      "7000/7000 [==============================] - 1s 80us/step - loss: 0.9060 - accuracy: 0.7843 - val_loss: 0.9979 - val_accuracy: 0.7500\n",
      "Epoch 487/1000\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 0.9084 - accuracy: 0.7813 - val_loss: 0.9902 - val_accuracy: 0.7490\n",
      "Epoch 488/1000\n",
      "7000/7000 [==============================] - 1s 72us/step - loss: 0.9062 - accuracy: 0.7817 - val_loss: 0.9848 - val_accuracy: 0.7550\n",
      "Epoch 489/1000\n",
      "7000/7000 [==============================] - 1s 73us/step - loss: 0.9059 - accuracy: 0.7816 - val_loss: 0.9870 - val_accuracy: 0.7550\n",
      "Epoch 490/1000\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 0.9044 - accuracy: 0.7820 - val_loss: 0.9808 - val_accuracy: 0.7520\n",
      "Epoch 491/1000\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 0.9050 - accuracy: 0.7834 - val_loss: 0.9893 - val_accuracy: 0.7560\n",
      "Epoch 492/1000\n",
      "7000/7000 [==============================] - 0s 66us/step - loss: 0.9047 - accuracy: 0.7824 - val_loss: 0.9846 - val_accuracy: 0.7390\n",
      "Epoch 493/1000\n",
      "7000/7000 [==============================] - 0s 71us/step - loss: 0.9037 - accuracy: 0.7810 - val_loss: 0.9879 - val_accuracy: 0.7570\n",
      "Epoch 494/1000\n",
      "7000/7000 [==============================] - 1s 86us/step - loss: 0.9037 - accuracy: 0.7817 - val_loss: 0.9828 - val_accuracy: 0.7560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 495/1000\n",
      "7000/7000 [==============================] - 0s 65us/step - loss: 0.9028 - accuracy: 0.7817 - val_loss: 0.9882 - val_accuracy: 0.7530\n",
      "Epoch 496/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.9024 - accuracy: 0.7820 - val_loss: 0.9971 - val_accuracy: 0.7430\n",
      "Epoch 497/1000\n",
      "7000/7000 [==============================] - 0s 66us/step - loss: 0.9034 - accuracy: 0.7816 - val_loss: 0.9765 - val_accuracy: 0.7530\n",
      "Epoch 498/1000\n",
      "7000/7000 [==============================] - 1s 74us/step - loss: 0.9012 - accuracy: 0.7851 - val_loss: 0.9793 - val_accuracy: 0.7440\n",
      "Epoch 499/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 0.9009 - accuracy: 0.7833 - val_loss: 0.9777 - val_accuracy: 0.7540\n",
      "Epoch 500/1000\n",
      "7000/7000 [==============================] - 1s 78us/step - loss: 0.9022 - accuracy: 0.7820 - val_loss: 0.9829 - val_accuracy: 0.7540\n",
      "Epoch 501/1000\n",
      "7000/7000 [==============================] - 0s 68us/step - loss: 0.9011 - accuracy: 0.7837 - val_loss: 0.9818 - val_accuracy: 0.7510\n",
      "Epoch 502/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.8991 - accuracy: 0.7856 - val_loss: 0.9817 - val_accuracy: 0.7500\n",
      "Epoch 503/1000\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 0.8991 - accuracy: 0.7827 - val_loss: 0.9786 - val_accuracy: 0.7470\n",
      "Epoch 504/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.8994 - accuracy: 0.7820 - val_loss: 0.9928 - val_accuracy: 0.7540\n",
      "Epoch 505/1000\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 0.8994 - accuracy: 0.7820 - val_loss: 0.9803 - val_accuracy: 0.7550\n",
      "Epoch 506/1000\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 0.8995 - accuracy: 0.7820 - val_loss: 0.9841 - val_accuracy: 0.7530\n",
      "Epoch 507/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.8986 - accuracy: 0.7840 - val_loss: 0.9762 - val_accuracy: 0.7550\n",
      "Epoch 508/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.8976 - accuracy: 0.7843 - val_loss: 0.9852 - val_accuracy: 0.7570\n",
      "Epoch 509/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.8990 - accuracy: 0.7820 - val_loss: 0.9821 - val_accuracy: 0.7490\n",
      "Epoch 510/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.8995 - accuracy: 0.7847 - val_loss: 0.9839 - val_accuracy: 0.7560\n",
      "Epoch 511/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.8953 - accuracy: 0.7837 - val_loss: 0.9813 - val_accuracy: 0.7510\n",
      "Epoch 512/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.8963 - accuracy: 0.7833 - val_loss: 0.9859 - val_accuracy: 0.7520\n",
      "Epoch 513/1000\n",
      "7000/7000 [==============================] - 0s 65us/step - loss: 0.8957 - accuracy: 0.7839 - val_loss: 1.0014 - val_accuracy: 0.7470\n",
      "Epoch 514/1000\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 0.8966 - accuracy: 0.7826 - val_loss: 0.9779 - val_accuracy: 0.7570\n",
      "Epoch 515/1000\n",
      "7000/7000 [==============================] - 0s 66us/step - loss: 0.8939 - accuracy: 0.7837 - val_loss: 0.9828 - val_accuracy: 0.7480\n",
      "Epoch 516/1000\n",
      "7000/7000 [==============================] - 0s 68us/step - loss: 0.8944 - accuracy: 0.7847 - val_loss: 0.9742 - val_accuracy: 0.7570\n",
      "Epoch 517/1000\n",
      "7000/7000 [==============================] - 1s 74us/step - loss: 0.8933 - accuracy: 0.7857 - val_loss: 0.9768 - val_accuracy: 0.7560\n",
      "Epoch 518/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.8944 - accuracy: 0.7853 - val_loss: 0.9777 - val_accuracy: 0.7510\n",
      "Epoch 519/1000\n",
      "7000/7000 [==============================] - 0s 66us/step - loss: 0.8948 - accuracy: 0.7817 - val_loss: 0.9879 - val_accuracy: 0.7570\n",
      "Epoch 520/1000\n",
      "7000/7000 [==============================] - 1s 79us/step - loss: 0.8959 - accuracy: 0.7851 - val_loss: 1.0169 - val_accuracy: 0.7380\n",
      "Epoch 521/1000\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 0.8959 - accuracy: 0.7846 - val_loss: 0.9762 - val_accuracy: 0.7560\n",
      "Epoch 522/1000\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 0.8961 - accuracy: 0.7856 - val_loss: 0.9849 - val_accuracy: 0.7550\n",
      "Epoch 523/1000\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 0.8917 - accuracy: 0.7829 - val_loss: 0.9769 - val_accuracy: 0.7550\n",
      "Epoch 524/1000\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 0.8916 - accuracy: 0.7846 - val_loss: 0.9833 - val_accuracy: 0.7540\n",
      "Epoch 525/1000\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 0.8930 - accuracy: 0.7860 - val_loss: 0.9764 - val_accuracy: 0.7610\n",
      "Epoch 526/1000\n",
      "7000/7000 [==============================] - 0s 64us/step - loss: 0.8914 - accuracy: 0.7831 - val_loss: 0.9846 - val_accuracy: 0.7560\n",
      "Epoch 527/1000\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 0.8926 - accuracy: 0.7841 - val_loss: 0.9851 - val_accuracy: 0.7580\n",
      "Epoch 528/1000\n",
      "7000/7000 [==============================] - 0s 68us/step - loss: 0.8908 - accuracy: 0.7859 - val_loss: 0.9742 - val_accuracy: 0.7430\n",
      "Epoch 529/1000\n",
      "7000/7000 [==============================] - 0s 67us/step - loss: 0.8901 - accuracy: 0.7837 - val_loss: 0.9941 - val_accuracy: 0.7550\n",
      "Epoch 530/1000\n",
      "7000/7000 [==============================] - 0s 68us/step - loss: 0.8923 - accuracy: 0.7813 - val_loss: 0.9754 - val_accuracy: 0.7560\n",
      "Epoch 531/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 0.8892 - accuracy: 0.7854 - val_loss: 0.9866 - val_accuracy: 0.7380\n",
      "Epoch 532/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.8888 - accuracy: 0.7863 - val_loss: 0.9775 - val_accuracy: 0.7540\n",
      "Epoch 533/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.8891 - accuracy: 0.7857 - val_loss: 0.9694 - val_accuracy: 0.7490\n",
      "Epoch 534/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.8879 - accuracy: 0.7846 - val_loss: 0.9955 - val_accuracy: 0.7350\n",
      "Epoch 535/1000\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 0.8898 - accuracy: 0.7849 - val_loss: 0.9737 - val_accuracy: 0.7600\n",
      "Epoch 536/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.8900 - accuracy: 0.7837 - val_loss: 0.9849 - val_accuracy: 0.7450\n",
      "Epoch 537/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.8875 - accuracy: 0.7871 - val_loss: 0.9766 - val_accuracy: 0.7570\n",
      "Epoch 538/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.8872 - accuracy: 0.7864 - val_loss: 0.9749 - val_accuracy: 0.7540\n",
      "Epoch 539/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.8860 - accuracy: 0.7866 - val_loss: 0.9834 - val_accuracy: 0.7520\n",
      "Epoch 540/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8878 - accuracy: 0.7851 - val_loss: 0.9743 - val_accuracy: 0.7560\n",
      "Epoch 541/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.8879 - accuracy: 0.7864 - val_loss: 0.9802 - val_accuracy: 0.7450\n",
      "Epoch 542/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.8881 - accuracy: 0.7851 - val_loss: 0.9746 - val_accuracy: 0.7530\n",
      "Epoch 543/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.8865 - accuracy: 0.7881 - val_loss: 0.9733 - val_accuracy: 0.7460\n",
      "Epoch 544/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.8847 - accuracy: 0.7867 - val_loss: 0.9719 - val_accuracy: 0.7510\n",
      "Epoch 545/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8839 - accuracy: 0.7859 - val_loss: 0.9755 - val_accuracy: 0.7590\n",
      "Epoch 546/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.8858 - accuracy: 0.7807 - val_loss: 0.9712 - val_accuracy: 0.7510\n",
      "Epoch 547/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.8831 - accuracy: 0.7871 - val_loss: 0.9719 - val_accuracy: 0.7690\n",
      "Epoch 548/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.8841 - accuracy: 0.7876 - val_loss: 0.9718 - val_accuracy: 0.7670\n",
      "Epoch 549/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.8866 - accuracy: 0.7863 - val_loss: 1.0177 - val_accuracy: 0.7320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 550/1000\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 0.8830 - accuracy: 0.7863 - val_loss: 0.9713 - val_accuracy: 0.7480\n",
      "Epoch 551/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.8851 - accuracy: 0.7844 - val_loss: 0.9675 - val_accuracy: 0.7530\n",
      "Epoch 552/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.8835 - accuracy: 0.7867 - val_loss: 0.9646 - val_accuracy: 0.7570\n",
      "Epoch 553/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.8811 - accuracy: 0.7859 - val_loss: 1.0053 - val_accuracy: 0.7420\n",
      "Epoch 554/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.8872 - accuracy: 0.7844 - val_loss: 0.9727 - val_accuracy: 0.7580\n",
      "Epoch 555/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8825 - accuracy: 0.7870 - val_loss: 0.9691 - val_accuracy: 0.7580\n",
      "Epoch 556/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 0.8825 - accuracy: 0.7863 - val_loss: 0.9822 - val_accuracy: 0.7530\n",
      "Epoch 557/1000\n",
      "7000/7000 [==============================] - 0s 64us/step - loss: 0.8803 - accuracy: 0.7876 - val_loss: 0.9745 - val_accuracy: 0.7570\n",
      "Epoch 558/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.8814 - accuracy: 0.7856 - val_loss: 0.9744 - val_accuracy: 0.7570\n",
      "Epoch 559/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.8804 - accuracy: 0.7857 - val_loss: 0.9851 - val_accuracy: 0.7570\n",
      "Epoch 560/1000\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 0.8805 - accuracy: 0.7871 - val_loss: 0.9703 - val_accuracy: 0.7550\n",
      "Epoch 561/1000\n",
      "7000/7000 [==============================] - 0s 68us/step - loss: 0.8821 - accuracy: 0.7876 - val_loss: 0.9943 - val_accuracy: 0.7490\n",
      "Epoch 562/1000\n",
      "7000/7000 [==============================] - 1s 78us/step - loss: 0.8811 - accuracy: 0.7863 - val_loss: 0.9724 - val_accuracy: 0.7600\n",
      "Epoch 563/1000\n",
      "7000/7000 [==============================] - 0s 67us/step - loss: 0.8795 - accuracy: 0.7883 - val_loss: 0.9669 - val_accuracy: 0.7520\n",
      "Epoch 564/1000\n",
      "7000/7000 [==============================] - 0s 71us/step - loss: 0.8788 - accuracy: 0.7880 - val_loss: 0.9892 - val_accuracy: 0.7440\n",
      "Epoch 565/1000\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 0.8808 - accuracy: 0.7870 - val_loss: 0.9647 - val_accuracy: 0.7560\n",
      "Epoch 566/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 0.8787 - accuracy: 0.7873 - val_loss: 0.9708 - val_accuracy: 0.7530\n",
      "Epoch 567/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.8771 - accuracy: 0.7870 - val_loss: 0.9714 - val_accuracy: 0.7590\n",
      "Epoch 568/1000\n",
      "7000/7000 [==============================] - 1s 76us/step - loss: 0.8800 - accuracy: 0.7863 - val_loss: 0.9843 - val_accuracy: 0.7450\n",
      "Epoch 569/1000\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 0.8775 - accuracy: 0.7886 - val_loss: 0.9737 - val_accuracy: 0.7530\n",
      "Epoch 570/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.8788 - accuracy: 0.7864 - val_loss: 0.9678 - val_accuracy: 0.7580\n",
      "Epoch 571/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.8769 - accuracy: 0.7884 - val_loss: 0.9727 - val_accuracy: 0.7580\n",
      "Epoch 572/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.8775 - accuracy: 0.7861 - val_loss: 0.9721 - val_accuracy: 0.7540\n",
      "Epoch 573/1000\n",
      "7000/7000 [==============================] - 1s 82us/step - loss: 0.8765 - accuracy: 0.7891 - val_loss: 0.9700 - val_accuracy: 0.7490\n",
      "Epoch 574/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.8752 - accuracy: 0.7901 - val_loss: 1.0210 - val_accuracy: 0.7320\n",
      "Epoch 575/1000\n",
      "7000/7000 [==============================] - 1s 75us/step - loss: 0.8760 - accuracy: 0.7873 - val_loss: 0.9815 - val_accuracy: 0.7500\n",
      "Epoch 576/1000\n",
      "7000/7000 [==============================] - 1s 76us/step - loss: 0.8761 - accuracy: 0.7877 - val_loss: 0.9856 - val_accuracy: 0.7530\n",
      "Epoch 577/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 0.8768 - accuracy: 0.7901 - val_loss: 0.9697 - val_accuracy: 0.7570\n",
      "Epoch 578/1000\n",
      "7000/7000 [==============================] - 1s 84us/step - loss: 0.8750 - accuracy: 0.7871 - val_loss: 0.9736 - val_accuracy: 0.7480\n",
      "Epoch 579/1000\n",
      "7000/7000 [==============================] - 1s 75us/step - loss: 0.8748 - accuracy: 0.7871 - val_loss: 0.9660 - val_accuracy: 0.7530\n",
      "Epoch 580/1000\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 0.8759 - accuracy: 0.7871 - val_loss: 0.9795 - val_accuracy: 0.7580\n",
      "Epoch 581/1000\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 0.8731 - accuracy: 0.7881 - val_loss: 0.9726 - val_accuracy: 0.7560\n",
      "Epoch 582/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 0.8760 - accuracy: 0.7876 - val_loss: 0.9620 - val_accuracy: 0.7600\n",
      "Epoch 583/1000\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 0.8740 - accuracy: 0.7891 - val_loss: 0.9619 - val_accuracy: 0.7600\n",
      "Epoch 584/1000\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 0.8741 - accuracy: 0.7901 - val_loss: 0.9818 - val_accuracy: 0.7440\n",
      "Epoch 585/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.8726 - accuracy: 0.7877 - val_loss: 0.9810 - val_accuracy: 0.7490\n",
      "Epoch 586/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 0.8735 - accuracy: 0.7891 - val_loss: 0.9704 - val_accuracy: 0.7510\n",
      "Epoch 587/1000\n",
      "7000/7000 [==============================] - 0s 71us/step - loss: 0.8736 - accuracy: 0.7906 - val_loss: 0.9857 - val_accuracy: 0.7510\n",
      "Epoch 588/1000\n",
      "7000/7000 [==============================] - 1s 77us/step - loss: 0.8732 - accuracy: 0.7879 - val_loss: 0.9757 - val_accuracy: 0.7560\n",
      "Epoch 589/1000\n",
      "7000/7000 [==============================] - 0s 64us/step - loss: 0.8722 - accuracy: 0.7891 - val_loss: 0.9821 - val_accuracy: 0.7450\n",
      "Epoch 590/1000\n",
      "7000/7000 [==============================] - 0s 64us/step - loss: 0.8719 - accuracy: 0.7896 - val_loss: 0.9836 - val_accuracy: 0.7510\n",
      "Epoch 591/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 0.8725 - accuracy: 0.7924 - val_loss: 0.9813 - val_accuracy: 0.7480\n",
      "Epoch 592/1000\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 0.8705 - accuracy: 0.7880 - val_loss: 0.9639 - val_accuracy: 0.7490\n",
      "Epoch 593/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.8710 - accuracy: 0.7907 - val_loss: 0.9619 - val_accuracy: 0.7620\n",
      "Epoch 594/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.8697 - accuracy: 0.7893 - val_loss: 0.9696 - val_accuracy: 0.7540\n",
      "Epoch 595/1000\n",
      "7000/7000 [==============================] - 0s 64us/step - loss: 0.8715 - accuracy: 0.7874 - val_loss: 0.9653 - val_accuracy: 0.7580\n",
      "Epoch 596/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 0.8719 - accuracy: 0.7880 - val_loss: 0.9738 - val_accuracy: 0.7580\n",
      "Epoch 597/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.8717 - accuracy: 0.7907 - val_loss: 0.9586 - val_accuracy: 0.7600\n",
      "Epoch 598/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 0.8710 - accuracy: 0.7886 - val_loss: 1.0065 - val_accuracy: 0.7390\n",
      "Epoch 599/1000\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 0.8686 - accuracy: 0.7904 - val_loss: 1.0055 - val_accuracy: 0.7370\n",
      "Epoch 600/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 0.8709 - accuracy: 0.7881 - val_loss: 0.9597 - val_accuracy: 0.7570\n",
      "Epoch 601/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.8697 - accuracy: 0.7896 - val_loss: 0.9735 - val_accuracy: 0.7450\n",
      "Epoch 602/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.8696 - accuracy: 0.7889 - val_loss: 0.9722 - val_accuracy: 0.7570\n",
      "Epoch 603/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.8654 - accuracy: 0.7916 - val_loss: 0.9687 - val_accuracy: 0.7480\n",
      "Epoch 604/1000\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 0.8668 - accuracy: 0.7906 - val_loss: 0.9648 - val_accuracy: 0.7560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 605/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.8658 - accuracy: 0.7924 - val_loss: 0.9808 - val_accuracy: 0.7440\n",
      "Epoch 606/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.8704 - accuracy: 0.7879 - val_loss: 0.9633 - val_accuracy: 0.7590\n",
      "Epoch 607/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 0.8671 - accuracy: 0.7883 - val_loss: 0.9620 - val_accuracy: 0.7600\n",
      "Epoch 608/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.8668 - accuracy: 0.7901 - val_loss: 0.9666 - val_accuracy: 0.7550\n",
      "Epoch 609/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.8699 - accuracy: 0.7869 - val_loss: 0.9662 - val_accuracy: 0.7570\n",
      "Epoch 610/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.8646 - accuracy: 0.7927 - val_loss: 0.9634 - val_accuracy: 0.7490\n",
      "Epoch 611/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 0.8676 - accuracy: 0.7907 - val_loss: 0.9697 - val_accuracy: 0.7610\n",
      "Epoch 612/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.8645 - accuracy: 0.7894 - val_loss: 0.9750 - val_accuracy: 0.7550\n",
      "Epoch 613/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.8705 - accuracy: 0.7931 - val_loss: 0.9922 - val_accuracy: 0.7430\n",
      "Epoch 614/1000\n",
      "7000/7000 [==============================] - 0s 65us/step - loss: 0.8671 - accuracy: 0.7910 - val_loss: 0.9658 - val_accuracy: 0.7530\n",
      "Epoch 615/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.8678 - accuracy: 0.7911 - val_loss: 0.9760 - val_accuracy: 0.7450\n",
      "Epoch 616/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.8663 - accuracy: 0.7893 - val_loss: 0.9584 - val_accuracy: 0.7600\n",
      "Epoch 617/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8649 - accuracy: 0.7887 - val_loss: 0.9642 - val_accuracy: 0.7540\n",
      "Epoch 618/1000\n",
      "7000/7000 [==============================] - 0s 64us/step - loss: 0.8651 - accuracy: 0.7919 - val_loss: 0.9763 - val_accuracy: 0.7380\n",
      "Epoch 619/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.8658 - accuracy: 0.7886 - val_loss: 0.9573 - val_accuracy: 0.7620\n",
      "Epoch 620/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.8659 - accuracy: 0.7917 - val_loss: 0.9717 - val_accuracy: 0.7480\n",
      "Epoch 621/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.8633 - accuracy: 0.7930 - val_loss: 0.9776 - val_accuracy: 0.7480\n",
      "Epoch 622/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8648 - accuracy: 0.7907 - val_loss: 0.9591 - val_accuracy: 0.7570\n",
      "Epoch 623/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.8660 - accuracy: 0.7924 - val_loss: 0.9686 - val_accuracy: 0.7630\n",
      "Epoch 624/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.8628 - accuracy: 0.7910 - val_loss: 0.9879 - val_accuracy: 0.7420\n",
      "Epoch 625/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.8649 - accuracy: 0.7910 - val_loss: 0.9734 - val_accuracy: 0.7540\n",
      "Epoch 626/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.8621 - accuracy: 0.7913 - val_loss: 1.0046 - val_accuracy: 0.7390\n",
      "Epoch 627/1000\n",
      "7000/7000 [==============================] - 0s 53us/step - loss: 0.8628 - accuracy: 0.7887 - val_loss: 1.0150 - val_accuracy: 0.7350\n",
      "Epoch 628/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.8654 - accuracy: 0.7923 - val_loss: 0.9620 - val_accuracy: 0.7600\n",
      "Epoch 629/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.8591 - accuracy: 0.7903 - val_loss: 0.9741 - val_accuracy: 0.7520\n",
      "Epoch 630/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.8613 - accuracy: 0.7909 - val_loss: 0.9616 - val_accuracy: 0.7540\n",
      "Epoch 631/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.8603 - accuracy: 0.7916 - val_loss: 0.9732 - val_accuracy: 0.7520\n",
      "Epoch 632/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.8638 - accuracy: 0.7909 - val_loss: 0.9622 - val_accuracy: 0.7530\n",
      "Epoch 633/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.8613 - accuracy: 0.7909 - val_loss: 0.9592 - val_accuracy: 0.7570\n",
      "Epoch 634/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.8614 - accuracy: 0.7923 - val_loss: 0.9626 - val_accuracy: 0.7650\n",
      "Epoch 635/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.8624 - accuracy: 0.7891 - val_loss: 0.9543 - val_accuracy: 0.7660\n",
      "Epoch 636/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.8661 - accuracy: 0.7916 - val_loss: 0.9549 - val_accuracy: 0.7540\n",
      "Epoch 637/1000\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 0.8619 - accuracy: 0.7901 - val_loss: 0.9813 - val_accuracy: 0.7400\n",
      "Epoch 638/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.8581 - accuracy: 0.7927 - val_loss: 0.9656 - val_accuracy: 0.7460\n",
      "Epoch 639/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 0.8584 - accuracy: 0.7911 - val_loss: 0.9762 - val_accuracy: 0.7470\n",
      "Epoch 640/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.8583 - accuracy: 0.7917 - val_loss: 0.9575 - val_accuracy: 0.7550\n",
      "Epoch 641/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 0.8595 - accuracy: 0.7919 - val_loss: 0.9552 - val_accuracy: 0.7540\n",
      "Epoch 642/1000\n",
      "7000/7000 [==============================] - 0s 53us/step - loss: 0.8594 - accuracy: 0.7920 - val_loss: 0.9844 - val_accuracy: 0.7470\n",
      "Epoch 643/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.8610 - accuracy: 0.7881 - val_loss: 0.9534 - val_accuracy: 0.7600\n",
      "Epoch 644/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.8593 - accuracy: 0.7910 - val_loss: 0.9692 - val_accuracy: 0.7460\n",
      "Epoch 645/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.8597 - accuracy: 0.7914 - val_loss: 0.9604 - val_accuracy: 0.7530\n",
      "Epoch 646/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.8585 - accuracy: 0.7914 - val_loss: 1.0338 - val_accuracy: 0.7360\n",
      "Epoch 647/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.8624 - accuracy: 0.7911 - val_loss: 0.9622 - val_accuracy: 0.7630\n",
      "Epoch 648/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.8593 - accuracy: 0.7921 - val_loss: 0.9623 - val_accuracy: 0.7490\n",
      "Epoch 649/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.8582 - accuracy: 0.7920 - val_loss: 0.9854 - val_accuracy: 0.7380\n",
      "Epoch 650/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.8579 - accuracy: 0.7934 - val_loss: 0.9663 - val_accuracy: 0.7530\n",
      "Epoch 651/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.8557 - accuracy: 0.7924 - val_loss: 0.9622 - val_accuracy: 0.7550\n",
      "Epoch 652/1000\n",
      "7000/7000 [==============================] - 0s 53us/step - loss: 0.8558 - accuracy: 0.7944 - val_loss: 0.9591 - val_accuracy: 0.7520\n",
      "Epoch 653/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.8537 - accuracy: 0.7974 - val_loss: 0.9896 - val_accuracy: 0.7480\n",
      "Epoch 654/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.8551 - accuracy: 0.7924 - val_loss: 0.9946 - val_accuracy: 0.7510\n",
      "Epoch 655/1000\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 0.8564 - accuracy: 0.7951 - val_loss: 0.9514 - val_accuracy: 0.7580\n",
      "Epoch 656/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 0.8528 - accuracy: 0.7944 - val_loss: 0.9560 - val_accuracy: 0.7590\n",
      "Epoch 657/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.8563 - accuracy: 0.7933 - val_loss: 0.9664 - val_accuracy: 0.7530\n",
      "Epoch 658/1000\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 0.8559 - accuracy: 0.7941 - val_loss: 0.9599 - val_accuracy: 0.7520\n",
      "Epoch 659/1000\n",
      "7000/7000 [==============================] - 0s 64us/step - loss: 0.8527 - accuracy: 0.7940 - val_loss: 0.9573 - val_accuracy: 0.7540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 660/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.8547 - accuracy: 0.7937 - val_loss: 0.9667 - val_accuracy: 0.7520\n",
      "Epoch 661/1000\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 0.8537 - accuracy: 0.7923 - val_loss: 0.9599 - val_accuracy: 0.7540\n",
      "Epoch 662/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8540 - accuracy: 0.7933 - val_loss: 0.9550 - val_accuracy: 0.7620\n",
      "Epoch 663/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.8580 - accuracy: 0.7927 - val_loss: 0.9734 - val_accuracy: 0.7590\n",
      "Epoch 664/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.8553 - accuracy: 0.7924 - val_loss: 0.9577 - val_accuracy: 0.7550\n",
      "Epoch 665/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.8516 - accuracy: 0.7943 - val_loss: 0.9672 - val_accuracy: 0.7460\n",
      "Epoch 666/1000\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 0.8522 - accuracy: 0.7939 - val_loss: 0.9676 - val_accuracy: 0.7580\n",
      "Epoch 667/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.8565 - accuracy: 0.7917 - val_loss: 0.9777 - val_accuracy: 0.7500\n",
      "Epoch 668/1000\n",
      "7000/7000 [==============================] - 1s 81us/step - loss: 0.8534 - accuracy: 0.7959 - val_loss: 0.9625 - val_accuracy: 0.7490\n",
      "Epoch 669/1000\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 0.8571 - accuracy: 0.7919 - val_loss: 0.9557 - val_accuracy: 0.7610\n",
      "Epoch 670/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 0.8525 - accuracy: 0.7937 - val_loss: 0.9673 - val_accuracy: 0.7460\n",
      "Epoch 671/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.8564 - accuracy: 0.7956 - val_loss: 0.9575 - val_accuracy: 0.7560\n",
      "Epoch 672/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.8501 - accuracy: 0.7934 - val_loss: 0.9569 - val_accuracy: 0.7610\n",
      "Epoch 673/1000\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 0.8573 - accuracy: 0.7929 - val_loss: 0.9580 - val_accuracy: 0.7590\n",
      "Epoch 674/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.8521 - accuracy: 0.7934 - val_loss: 0.9635 - val_accuracy: 0.7560\n",
      "Epoch 675/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.8527 - accuracy: 0.7950 - val_loss: 0.9972 - val_accuracy: 0.7460\n",
      "Epoch 676/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.8515 - accuracy: 0.7931 - val_loss: 0.9703 - val_accuracy: 0.7550\n",
      "Epoch 677/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.8541 - accuracy: 0.7931 - val_loss: 0.9567 - val_accuracy: 0.7570\n",
      "Epoch 678/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.8511 - accuracy: 0.7936 - val_loss: 0.9567 - val_accuracy: 0.7550\n",
      "Epoch 679/1000\n",
      "7000/7000 [==============================] - 0s 64us/step - loss: 0.8495 - accuracy: 0.7956 - val_loss: 0.9623 - val_accuracy: 0.7570\n",
      "Epoch 680/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 0.8494 - accuracy: 0.7900 - val_loss: 0.9744 - val_accuracy: 0.7490\n",
      "Epoch 681/1000\n",
      "7000/7000 [==============================] - 0s 65us/step - loss: 0.8554 - accuracy: 0.7906 - val_loss: 0.9557 - val_accuracy: 0.7640\n",
      "Epoch 682/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.8490 - accuracy: 0.7953 - val_loss: 0.9695 - val_accuracy: 0.7470\n",
      "Epoch 683/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.8518 - accuracy: 0.7939 - val_loss: 0.9521 - val_accuracy: 0.7520\n",
      "Epoch 684/1000\n",
      "7000/7000 [==============================] - 1s 76us/step - loss: 0.8482 - accuracy: 0.7959 - val_loss: 0.9721 - val_accuracy: 0.7450\n",
      "Epoch 685/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.8527 - accuracy: 0.7941 - val_loss: 0.9697 - val_accuracy: 0.7450\n",
      "Epoch 686/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 0.8575 - accuracy: 0.7911 - val_loss: 0.9888 - val_accuracy: 0.7510\n",
      "Epoch 687/1000\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 0.8530 - accuracy: 0.7946 - val_loss: 0.9922 - val_accuracy: 0.7450\n",
      "Epoch 688/1000\n",
      "7000/7000 [==============================] - 1s 74us/step - loss: 0.8494 - accuracy: 0.7944 - val_loss: 0.9653 - val_accuracy: 0.7500\n",
      "Epoch 689/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.8486 - accuracy: 0.7943 - val_loss: 0.9711 - val_accuracy: 0.7500\n",
      "Epoch 690/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 0.8520 - accuracy: 0.7919 - val_loss: 0.9562 - val_accuracy: 0.7540\n",
      "Epoch 691/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.8497 - accuracy: 0.7956 - val_loss: 0.9943 - val_accuracy: 0.7500\n",
      "Epoch 692/1000\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 0.8514 - accuracy: 0.7953 - val_loss: 0.9589 - val_accuracy: 0.7590\n",
      "Epoch 693/1000\n",
      "7000/7000 [==============================] - 1s 78us/step - loss: 0.8481 - accuracy: 0.7960 - val_loss: 0.9771 - val_accuracy: 0.7400\n",
      "Epoch 694/1000\n",
      "7000/7000 [==============================] - 1s 76us/step - loss: 0.8500 - accuracy: 0.7947 - val_loss: 0.9585 - val_accuracy: 0.7570\n",
      "Epoch 695/1000\n",
      "7000/7000 [==============================] - 1s 74us/step - loss: 0.8501 - accuracy: 0.7961 - val_loss: 0.9731 - val_accuracy: 0.7500\n",
      "Epoch 696/1000\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 0.8467 - accuracy: 0.7941 - val_loss: 0.9607 - val_accuracy: 0.7580\n",
      "Epoch 697/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.8487 - accuracy: 0.7954 - val_loss: 0.9534 - val_accuracy: 0.7500\n",
      "Epoch 698/1000\n",
      "7000/7000 [==============================] - 0s 64us/step - loss: 0.8457 - accuracy: 0.7959 - val_loss: 0.9550 - val_accuracy: 0.7570\n",
      "Epoch 699/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 0.8466 - accuracy: 0.7954 - val_loss: 0.9718 - val_accuracy: 0.7450\n",
      "Epoch 700/1000\n",
      "7000/7000 [==============================] - 0s 68us/step - loss: 0.8462 - accuracy: 0.7950 - val_loss: 0.9730 - val_accuracy: 0.7460\n",
      "Epoch 701/1000\n",
      "7000/7000 [==============================] - 1s 76us/step - loss: 0.8508 - accuracy: 0.7941 - val_loss: 1.0085 - val_accuracy: 0.7350\n",
      "Epoch 702/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.8488 - accuracy: 0.7929 - val_loss: 0.9579 - val_accuracy: 0.7590\n",
      "Epoch 703/1000\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 0.8462 - accuracy: 0.7969 - val_loss: 0.9624 - val_accuracy: 0.7580\n",
      "Epoch 704/1000\n",
      "7000/7000 [==============================] - 1s 76us/step - loss: 0.8442 - accuracy: 0.7960 - val_loss: 0.9640 - val_accuracy: 0.7510\n",
      "Epoch 705/1000\n",
      "7000/7000 [==============================] - 0s 67us/step - loss: 0.8447 - accuracy: 0.7981 - val_loss: 0.9656 - val_accuracy: 0.7540\n",
      "Epoch 706/1000\n",
      "7000/7000 [==============================] - 0s 68us/step - loss: 0.8435 - accuracy: 0.7950 - val_loss: 0.9683 - val_accuracy: 0.7450\n",
      "Epoch 707/1000\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 0.8477 - accuracy: 0.7923 - val_loss: 0.9583 - val_accuracy: 0.7550\n",
      "Epoch 708/1000\n",
      "7000/7000 [==============================] - 0s 66us/step - loss: 0.8477 - accuracy: 0.7960 - val_loss: 0.9553 - val_accuracy: 0.7570\n",
      "Epoch 709/1000\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 0.8471 - accuracy: 0.7971 - val_loss: 0.9528 - val_accuracy: 0.7540\n",
      "Epoch 710/1000\n",
      "7000/7000 [==============================] - 0s 68us/step - loss: 0.8460 - accuracy: 0.7950 - val_loss: 0.9503 - val_accuracy: 0.7560\n",
      "Epoch 711/1000\n",
      "7000/7000 [==============================] - 0s 66us/step - loss: 0.8474 - accuracy: 0.7940 - val_loss: 0.9522 - val_accuracy: 0.7610\n",
      "Epoch 712/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.8480 - accuracy: 0.7973 - val_loss: 0.9607 - val_accuracy: 0.7490\n",
      "Epoch 713/1000\n",
      "7000/7000 [==============================] - 1s 84us/step - loss: 0.8428 - accuracy: 0.7983 - val_loss: 0.9931 - val_accuracy: 0.7220\n",
      "Epoch 714/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.8457 - accuracy: 0.7954 - val_loss: 0.9954 - val_accuracy: 0.7270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 715/1000\n",
      "7000/7000 [==============================] - 1s 84us/step - loss: 0.8493 - accuracy: 0.7949 - val_loss: 0.9636 - val_accuracy: 0.7450\n",
      "Epoch 716/1000\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 0.8454 - accuracy: 0.7964 - val_loss: 0.9614 - val_accuracy: 0.7600\n",
      "Epoch 717/1000\n",
      "7000/7000 [==============================] - 0s 64us/step - loss: 0.8462 - accuracy: 0.7951 - val_loss: 0.9663 - val_accuracy: 0.7550\n",
      "Epoch 718/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.8420 - accuracy: 0.7961 - val_loss: 0.9533 - val_accuracy: 0.7500\n",
      "Epoch 719/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.8465 - accuracy: 0.7961 - val_loss: 0.9539 - val_accuracy: 0.7590\n",
      "Epoch 720/1000\n",
      "7000/7000 [==============================] - 1s 84us/step - loss: 0.8475 - accuracy: 0.7964 - val_loss: 0.9498 - val_accuracy: 0.7560\n",
      "Epoch 721/1000\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 0.8446 - accuracy: 0.7950 - val_loss: 0.9645 - val_accuracy: 0.7580\n",
      "Epoch 722/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.8424 - accuracy: 0.7970 - val_loss: 0.9526 - val_accuracy: 0.7570\n",
      "Epoch 723/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8421 - accuracy: 0.7954 - val_loss: 0.9580 - val_accuracy: 0.7570\n",
      "Epoch 724/1000\n",
      "7000/7000 [==============================] - 0s 64us/step - loss: 0.8517 - accuracy: 0.7941 - val_loss: 0.9912 - val_accuracy: 0.7300\n",
      "Epoch 725/1000\n",
      "7000/7000 [==============================] - 1s 82us/step - loss: 0.8467 - accuracy: 0.7963 - val_loss: 0.9709 - val_accuracy: 0.7520\n",
      "Epoch 726/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.8495 - accuracy: 0.7909 - val_loss: 0.9514 - val_accuracy: 0.7560\n",
      "Epoch 727/1000\n",
      "7000/7000 [==============================] - 1s 83us/step - loss: 0.8432 - accuracy: 0.7973 - val_loss: 0.9438 - val_accuracy: 0.7580\n",
      "Epoch 728/1000\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 0.8430 - accuracy: 0.7944 - val_loss: 0.9532 - val_accuracy: 0.7550\n",
      "Epoch 729/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.8439 - accuracy: 0.7963 - val_loss: 0.9513 - val_accuracy: 0.7590\n",
      "Epoch 730/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.8455 - accuracy: 0.7970 - val_loss: 1.0297 - val_accuracy: 0.7400\n",
      "Epoch 731/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.8483 - accuracy: 0.7926 - val_loss: 0.9501 - val_accuracy: 0.7570\n",
      "Epoch 732/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.8434 - accuracy: 0.7954 - val_loss: 0.9496 - val_accuracy: 0.7550\n",
      "Epoch 733/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.8406 - accuracy: 0.7966 - val_loss: 0.9536 - val_accuracy: 0.7600\n",
      "Epoch 734/1000\n",
      "7000/7000 [==============================] - 1s 83us/step - loss: 0.8418 - accuracy: 0.7954 - val_loss: 0.9521 - val_accuracy: 0.7570\n",
      "Epoch 735/1000\n",
      "7000/7000 [==============================] - 1s 81us/step - loss: 0.8446 - accuracy: 0.7927 - val_loss: 0.9648 - val_accuracy: 0.7550\n",
      "Epoch 736/1000\n",
      "7000/7000 [==============================] - 0s 68us/step - loss: 0.8421 - accuracy: 0.7966 - val_loss: 0.9726 - val_accuracy: 0.7520\n",
      "Epoch 737/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.8415 - accuracy: 0.7973 - val_loss: 0.9522 - val_accuracy: 0.7590\n",
      "Epoch 738/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.8411 - accuracy: 0.7990 - val_loss: 0.9742 - val_accuracy: 0.7510\n",
      "Epoch 739/1000\n",
      "7000/7000 [==============================] - 1s 80us/step - loss: 0.8529 - accuracy: 0.7901 - val_loss: 0.9603 - val_accuracy: 0.7600\n",
      "Epoch 740/1000\n",
      "7000/7000 [==============================] - 1s 83us/step - loss: 0.8403 - accuracy: 0.7959 - val_loss: 0.9633 - val_accuracy: 0.7530\n",
      "Epoch 741/1000\n",
      "7000/7000 [==============================] - 1s 75us/step - loss: 0.8421 - accuracy: 0.7961 - val_loss: 0.9558 - val_accuracy: 0.7600\n",
      "Epoch 742/1000\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 0.8371 - accuracy: 0.7977 - val_loss: 0.9556 - val_accuracy: 0.7560\n",
      "Epoch 743/1000\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 0.8379 - accuracy: 0.7974 - val_loss: 1.0029 - val_accuracy: 0.7420\n",
      "Epoch 744/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 0.8394 - accuracy: 0.7979 - val_loss: 0.9696 - val_accuracy: 0.7510\n",
      "Epoch 745/1000\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 0.8407 - accuracy: 0.7956 - val_loss: 0.9500 - val_accuracy: 0.7590\n",
      "Epoch 746/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 0.8441 - accuracy: 0.7961 - val_loss: 0.9531 - val_accuracy: 0.7570\n",
      "Epoch 747/1000\n",
      "7000/7000 [==============================] - 0s 64us/step - loss: 0.8366 - accuracy: 0.7996 - val_loss: 0.9769 - val_accuracy: 0.7500\n",
      "Epoch 748/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.8436 - accuracy: 0.7951 - val_loss: 0.9495 - val_accuracy: 0.7580\n",
      "Epoch 749/1000\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 0.8392 - accuracy: 0.7989 - val_loss: 0.9487 - val_accuracy: 0.7590\n",
      "Epoch 750/1000\n",
      "7000/7000 [==============================] - 0s 65us/step - loss: 0.8347 - accuracy: 0.8021 - val_loss: 0.9450 - val_accuracy: 0.7590\n",
      "Epoch 751/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 0.8390 - accuracy: 0.7971 - val_loss: 0.9637 - val_accuracy: 0.7460\n",
      "Epoch 752/1000\n",
      "7000/7000 [==============================] - 0s 65us/step - loss: 0.8413 - accuracy: 0.7986 - val_loss: 1.1308 - val_accuracy: 0.6850\n",
      "Epoch 753/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.8509 - accuracy: 0.7911 - val_loss: 0.9532 - val_accuracy: 0.7550\n",
      "Epoch 754/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.8367 - accuracy: 0.7957 - val_loss: 0.9858 - val_accuracy: 0.7440\n",
      "Epoch 755/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.8440 - accuracy: 0.7907 - val_loss: 0.9452 - val_accuracy: 0.7570\n",
      "Epoch 756/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 0.8405 - accuracy: 0.7973 - val_loss: 0.9511 - val_accuracy: 0.7540\n",
      "Epoch 757/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.8362 - accuracy: 0.7963 - val_loss: 0.9501 - val_accuracy: 0.7600\n",
      "Epoch 758/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.8367 - accuracy: 0.7993 - val_loss: 0.9427 - val_accuracy: 0.7580\n",
      "Epoch 759/1000\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 0.8409 - accuracy: 0.7977 - val_loss: 0.9493 - val_accuracy: 0.7590\n",
      "Epoch 760/1000\n",
      "7000/7000 [==============================] - 0s 64us/step - loss: 0.8405 - accuracy: 0.7960 - val_loss: 0.9447 - val_accuracy: 0.7560\n",
      "Epoch 761/1000\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 0.8376 - accuracy: 0.7996 - val_loss: 0.9578 - val_accuracy: 0.7540\n",
      "Epoch 762/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.8414 - accuracy: 0.7981 - val_loss: 0.9522 - val_accuracy: 0.7570\n",
      "Epoch 763/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 0.8348 - accuracy: 0.7990 - val_loss: 0.9510 - val_accuracy: 0.7590\n",
      "Epoch 764/1000\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 0.8361 - accuracy: 0.7989 - val_loss: 0.9435 - val_accuracy: 0.7540\n",
      "Epoch 765/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.8337 - accuracy: 0.7986 - val_loss: 0.9569 - val_accuracy: 0.7580\n",
      "Epoch 766/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.8354 - accuracy: 0.7999 - val_loss: 1.0236 - val_accuracy: 0.7230\n",
      "Epoch 767/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.8468 - accuracy: 0.7954 - val_loss: 0.9500 - val_accuracy: 0.7600\n",
      "Epoch 768/1000\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 0.8342 - accuracy: 0.8023 - val_loss: 0.9532 - val_accuracy: 0.7590\n",
      "Epoch 769/1000\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 0.8380 - accuracy: 0.7949 - val_loss: 0.9798 - val_accuracy: 0.7510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 770/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 0.8366 - accuracy: 0.8004 - val_loss: 0.9496 - val_accuracy: 0.7540\n",
      "Epoch 771/1000\n",
      "7000/7000 [==============================] - 1s 80us/step - loss: 0.8326 - accuracy: 0.8016 - val_loss: 0.9589 - val_accuracy: 0.7630\n",
      "Epoch 772/1000\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 0.8364 - accuracy: 0.7984 - val_loss: 0.9605 - val_accuracy: 0.7560\n",
      "Epoch 773/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.8377 - accuracy: 0.7981 - val_loss: 0.9653 - val_accuracy: 0.7460\n",
      "Epoch 774/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.8328 - accuracy: 0.8001 - val_loss: 0.9672 - val_accuracy: 0.7640\n",
      "Epoch 775/1000\n",
      "7000/7000 [==============================] - 1s 80us/step - loss: 0.8366 - accuracy: 0.7991 - val_loss: 0.9599 - val_accuracy: 0.7560\n",
      "Epoch 776/1000\n",
      "7000/7000 [==============================] - 1s 83us/step - loss: 0.8343 - accuracy: 0.7966 - val_loss: 0.9663 - val_accuracy: 0.7590\n",
      "Epoch 777/1000\n",
      "7000/7000 [==============================] - 0s 66us/step - loss: 0.8361 - accuracy: 0.7986 - val_loss: 0.9522 - val_accuracy: 0.7600\n",
      "Epoch 778/1000\n",
      "7000/7000 [==============================] - 1s 91us/step - loss: 0.8378 - accuracy: 0.8017 - val_loss: 0.9556 - val_accuracy: 0.7600\n",
      "Epoch 779/1000\n",
      "7000/7000 [==============================] - 1s 84us/step - loss: 0.8362 - accuracy: 0.7984 - val_loss: 1.0145 - val_accuracy: 0.7300\n",
      "Epoch 780/1000\n",
      "7000/7000 [==============================] - 1s 75us/step - loss: 0.8389 - accuracy: 0.7991 - val_loss: 0.9943 - val_accuracy: 0.7410\n",
      "Epoch 781/1000\n",
      "7000/7000 [==============================] - 0s 66us/step - loss: 0.8339 - accuracy: 0.7970 - val_loss: 0.9470 - val_accuracy: 0.7560\n",
      "Epoch 782/1000\n",
      "7000/7000 [==============================] - 1s 95us/step - loss: 0.8405 - accuracy: 0.7960 - val_loss: 0.9588 - val_accuracy: 0.7570\n",
      "Epoch 783/1000\n",
      "7000/7000 [==============================] - 1s 87us/step - loss: 0.8330 - accuracy: 0.8007 - val_loss: 0.9536 - val_accuracy: 0.7580\n",
      "Epoch 784/1000\n",
      "7000/7000 [==============================] - 1s 80us/step - loss: 0.8390 - accuracy: 0.7976 - val_loss: 0.9568 - val_accuracy: 0.7680\n",
      "Epoch 785/1000\n",
      "7000/7000 [==============================] - 0s 65us/step - loss: 0.8331 - accuracy: 0.8007 - val_loss: 0.9482 - val_accuracy: 0.7550\n",
      "Epoch 786/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.8316 - accuracy: 0.7996 - val_loss: 0.9499 - val_accuracy: 0.7590\n",
      "Epoch 787/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.8316 - accuracy: 0.8004 - val_loss: 0.9632 - val_accuracy: 0.7440\n",
      "Epoch 788/1000\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 0.8329 - accuracy: 0.8003 - val_loss: 0.9409 - val_accuracy: 0.7580\n",
      "Epoch 789/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 0.8352 - accuracy: 0.8006 - val_loss: 0.9672 - val_accuracy: 0.7500\n",
      "Epoch 790/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.8344 - accuracy: 0.7980 - val_loss: 0.9537 - val_accuracy: 0.7530\n",
      "Epoch 791/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.8408 - accuracy: 0.7977 - val_loss: 0.9484 - val_accuracy: 0.7590\n",
      "Epoch 792/1000\n",
      "7000/7000 [==============================] - 1s 80us/step - loss: 0.8331 - accuracy: 0.7987 - val_loss: 0.9603 - val_accuracy: 0.7600\n",
      "Epoch 793/1000\n",
      "7000/7000 [==============================] - 0s 66us/step - loss: 0.8321 - accuracy: 0.8024 - val_loss: 0.9780 - val_accuracy: 0.7430\n",
      "Epoch 794/1000\n",
      "7000/7000 [==============================] - 0s 66us/step - loss: 0.8314 - accuracy: 0.8016 - val_loss: 0.9522 - val_accuracy: 0.7590\n",
      "Epoch 795/1000\n",
      "7000/7000 [==============================] - 0s 64us/step - loss: 0.8435 - accuracy: 0.7959 - val_loss: 0.9680 - val_accuracy: 0.7550\n",
      "Epoch 796/1000\n",
      "7000/7000 [==============================] - 0s 66us/step - loss: 0.8370 - accuracy: 0.7967 - val_loss: 0.9597 - val_accuracy: 0.7530\n",
      "Epoch 797/1000\n",
      "7000/7000 [==============================] - 0s 66us/step - loss: 0.8355 - accuracy: 0.7977 - val_loss: 0.9654 - val_accuracy: 0.7510\n",
      "Epoch 798/1000\n",
      "7000/7000 [==============================] - 0s 68us/step - loss: 0.8341 - accuracy: 0.7999 - val_loss: 0.9394 - val_accuracy: 0.7620\n",
      "Epoch 799/1000\n",
      "7000/7000 [==============================] - 0s 68us/step - loss: 0.8310 - accuracy: 0.8021 - val_loss: 0.9778 - val_accuracy: 0.7480\n",
      "Epoch 800/1000\n",
      "7000/7000 [==============================] - 0s 66us/step - loss: 0.8346 - accuracy: 0.7957 - val_loss: 0.9961 - val_accuracy: 0.7440\n",
      "Epoch 801/1000\n",
      "7000/7000 [==============================] - 0s 71us/step - loss: 0.8297 - accuracy: 0.7989 - val_loss: 0.9958 - val_accuracy: 0.7540\n",
      "Epoch 802/1000\n",
      "7000/7000 [==============================] - 1s 72us/step - loss: 0.8360 - accuracy: 0.7981 - val_loss: 0.9476 - val_accuracy: 0.7620\n",
      "Epoch 803/1000\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 0.8310 - accuracy: 0.8013 - val_loss: 0.9525 - val_accuracy: 0.7530\n",
      "Epoch 804/1000\n",
      "7000/7000 [==============================] - 0s 65us/step - loss: 0.8272 - accuracy: 0.8011 - val_loss: 0.9588 - val_accuracy: 0.7510\n",
      "Epoch 805/1000\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 0.8308 - accuracy: 0.8013 - val_loss: 0.9493 - val_accuracy: 0.7550\n",
      "Epoch 806/1000\n",
      "7000/7000 [==============================] - 0s 68us/step - loss: 0.8329 - accuracy: 0.7981 - val_loss: 0.9724 - val_accuracy: 0.7630\n",
      "Epoch 807/1000\n",
      "7000/7000 [==============================] - 0s 68us/step - loss: 0.8373 - accuracy: 0.7966 - val_loss: 0.9994 - val_accuracy: 0.7260\n",
      "Epoch 808/1000\n",
      "7000/7000 [==============================] - 0s 68us/step - loss: 0.8406 - accuracy: 0.7976 - val_loss: 0.9528 - val_accuracy: 0.7540\n",
      "Epoch 809/1000\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 0.8298 - accuracy: 0.8010 - val_loss: 0.9513 - val_accuracy: 0.7580\n",
      "Epoch 810/1000\n",
      "7000/7000 [==============================] - 0s 68us/step - loss: 0.8290 - accuracy: 0.8030 - val_loss: 0.9625 - val_accuracy: 0.7440\n",
      "Epoch 811/1000\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 0.8290 - accuracy: 0.8017 - val_loss: 0.9475 - val_accuracy: 0.7640\n",
      "Epoch 812/1000\n",
      "7000/7000 [==============================] - 0s 68us/step - loss: 0.8343 - accuracy: 0.7979 - val_loss: 0.9579 - val_accuracy: 0.7620\n",
      "Epoch 813/1000\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 0.8323 - accuracy: 0.7983 - val_loss: 0.9603 - val_accuracy: 0.7590\n",
      "Epoch 814/1000\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 0.8342 - accuracy: 0.7999 - val_loss: 1.0001 - val_accuracy: 0.7280\n",
      "Epoch 815/1000\n",
      "7000/7000 [==============================] - 0s 71us/step - loss: 0.8376 - accuracy: 0.7954 - val_loss: 0.9724 - val_accuracy: 0.7490\n",
      "Epoch 816/1000\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 0.8313 - accuracy: 0.7971 - val_loss: 0.9490 - val_accuracy: 0.7590\n",
      "Epoch 817/1000\n",
      "7000/7000 [==============================] - 0s 66us/step - loss: 0.8346 - accuracy: 0.7977 - val_loss: 0.9516 - val_accuracy: 0.7590\n",
      "Epoch 818/1000\n",
      "7000/7000 [==============================] - 0s 64us/step - loss: 0.8264 - accuracy: 0.7981 - val_loss: 0.9458 - val_accuracy: 0.7600\n",
      "Epoch 819/1000\n",
      "7000/7000 [==============================] - 0s 65us/step - loss: 0.8251 - accuracy: 0.8026 - val_loss: 0.9580 - val_accuracy: 0.7590\n",
      "Epoch 820/1000\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 0.8302 - accuracy: 0.7994 - val_loss: 0.9693 - val_accuracy: 0.7510\n",
      "Epoch 821/1000\n",
      "7000/7000 [==============================] - 0s 65us/step - loss: 0.8312 - accuracy: 0.7990 - val_loss: 0.9996 - val_accuracy: 0.7310\n",
      "Epoch 822/1000\n",
      "7000/7000 [==============================] - 0s 66us/step - loss: 0.8312 - accuracy: 0.8009 - val_loss: 0.9518 - val_accuracy: 0.7560\n",
      "Epoch 823/1000\n",
      "7000/7000 [==============================] - 0s 66us/step - loss: 0.8415 - accuracy: 0.7949 - val_loss: 0.9427 - val_accuracy: 0.7600\n",
      "Epoch 824/1000\n",
      "7000/7000 [==============================] - 0s 71us/step - loss: 0.8327 - accuracy: 0.8009 - val_loss: 0.9749 - val_accuracy: 0.7420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 825/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8286 - accuracy: 0.8019 - val_loss: 0.9581 - val_accuracy: 0.7570\n",
      "Epoch 826/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8301 - accuracy: 0.7986 - val_loss: 0.9507 - val_accuracy: 0.7580\n",
      "Epoch 827/1000\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 0.8326 - accuracy: 0.7987 - val_loss: 0.9467 - val_accuracy: 0.7580\n",
      "Epoch 828/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8253 - accuracy: 0.8074 - val_loss: 0.9504 - val_accuracy: 0.7600\n",
      "Epoch 829/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8278 - accuracy: 0.8031 - val_loss: 0.9457 - val_accuracy: 0.7590\n",
      "Epoch 830/1000\n",
      "7000/7000 [==============================] - 0s 52us/step - loss: 0.8301 - accuracy: 0.8029 - val_loss: 0.9968 - val_accuracy: 0.7490\n",
      "Epoch 831/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8357 - accuracy: 0.7970 - val_loss: 0.9592 - val_accuracy: 0.7550\n",
      "Epoch 832/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8243 - accuracy: 0.8037 - val_loss: 0.9664 - val_accuracy: 0.7370\n",
      "Epoch 833/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8335 - accuracy: 0.7937 - val_loss: 0.9503 - val_accuracy: 0.7620\n",
      "Epoch 834/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.8267 - accuracy: 0.8007 - val_loss: 0.9622 - val_accuracy: 0.7610\n",
      "Epoch 835/1000\n",
      "7000/7000 [==============================] - 0s 53us/step - loss: 0.8316 - accuracy: 0.7980 - val_loss: 0.9578 - val_accuracy: 0.7520\n",
      "Epoch 836/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.8295 - accuracy: 0.8016 - val_loss: 0.9514 - val_accuracy: 0.7630\n",
      "Epoch 837/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.8293 - accuracy: 0.8044 - val_loss: 0.9662 - val_accuracy: 0.7540\n",
      "Epoch 838/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8282 - accuracy: 0.7984 - val_loss: 0.9533 - val_accuracy: 0.7530\n",
      "Epoch 839/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8260 - accuracy: 0.8023 - val_loss: 0.9399 - val_accuracy: 0.7590\n",
      "Epoch 840/1000\n",
      "7000/7000 [==============================] - 0s 52us/step - loss: 0.8293 - accuracy: 0.8003 - val_loss: 1.0309 - val_accuracy: 0.7290\n",
      "Epoch 841/1000\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 0.8253 - accuracy: 0.8010 - val_loss: 0.9605 - val_accuracy: 0.7460\n",
      "Epoch 842/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.8360 - accuracy: 0.7977 - val_loss: 0.9386 - val_accuracy: 0.7600\n",
      "Epoch 843/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8226 - accuracy: 0.8006 - val_loss: 0.9576 - val_accuracy: 0.7640\n",
      "Epoch 844/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.8302 - accuracy: 0.8000 - val_loss: 0.9457 - val_accuracy: 0.7590\n",
      "Epoch 845/1000\n",
      "7000/7000 [==============================] - 0s 53us/step - loss: 0.8418 - accuracy: 0.7917 - val_loss: 0.9736 - val_accuracy: 0.7300\n",
      "Epoch 846/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8358 - accuracy: 0.7943 - val_loss: 0.9438 - val_accuracy: 0.7590\n",
      "Epoch 847/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8300 - accuracy: 0.8017 - val_loss: 0.9902 - val_accuracy: 0.7440\n",
      "Epoch 848/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.8422 - accuracy: 0.7971 - val_loss: 0.9631 - val_accuracy: 0.7500\n",
      "Epoch 849/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.8369 - accuracy: 0.7946 - val_loss: 0.9612 - val_accuracy: 0.7670\n",
      "Epoch 850/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8237 - accuracy: 0.8007 - val_loss: 0.9474 - val_accuracy: 0.7550\n",
      "Epoch 851/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.8242 - accuracy: 0.7997 - val_loss: 0.9505 - val_accuracy: 0.7520\n",
      "Epoch 852/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.8232 - accuracy: 0.8034 - val_loss: 0.9515 - val_accuracy: 0.7590\n",
      "Epoch 853/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.8290 - accuracy: 0.8003 - val_loss: 0.9753 - val_accuracy: 0.7380\n",
      "Epoch 854/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8279 - accuracy: 0.8034 - val_loss: 1.0019 - val_accuracy: 0.7430\n",
      "Epoch 855/1000\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 0.8205 - accuracy: 0.8050 - val_loss: 0.9535 - val_accuracy: 0.7530\n",
      "Epoch 856/1000\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 0.8270 - accuracy: 0.8014 - val_loss: 0.9425 - val_accuracy: 0.7560\n",
      "Epoch 857/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.8312 - accuracy: 0.7989 - val_loss: 0.9416 - val_accuracy: 0.7580\n",
      "Epoch 858/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8314 - accuracy: 0.8027 - val_loss: 0.9719 - val_accuracy: 0.7360\n",
      "Epoch 859/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.8305 - accuracy: 0.8020 - val_loss: 0.9424 - val_accuracy: 0.7590\n",
      "Epoch 860/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8214 - accuracy: 0.8057 - val_loss: 0.9520 - val_accuracy: 0.7570\n",
      "Epoch 861/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8290 - accuracy: 0.7983 - val_loss: 0.9996 - val_accuracy: 0.7420\n",
      "Epoch 862/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.8355 - accuracy: 0.7967 - val_loss: 0.9491 - val_accuracy: 0.7560\n",
      "Epoch 863/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.8253 - accuracy: 0.8034 - val_loss: 0.9889 - val_accuracy: 0.7320\n",
      "Epoch 864/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.8249 - accuracy: 0.8053 - val_loss: 0.9737 - val_accuracy: 0.7470\n",
      "Epoch 865/1000\n",
      "7000/7000 [==============================] - 0s 64us/step - loss: 0.8254 - accuracy: 0.8021 - val_loss: 0.9981 - val_accuracy: 0.7370\n",
      "Epoch 866/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.8345 - accuracy: 0.7951 - val_loss: 0.9361 - val_accuracy: 0.7570\n",
      "Epoch 867/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.8393 - accuracy: 0.7966 - val_loss: 0.9481 - val_accuracy: 0.7510\n",
      "Epoch 868/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.8333 - accuracy: 0.7999 - val_loss: 0.9633 - val_accuracy: 0.7650\n",
      "Epoch 869/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.8234 - accuracy: 0.8021 - val_loss: 0.9493 - val_accuracy: 0.7640\n",
      "Epoch 870/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8203 - accuracy: 0.8049 - val_loss: 0.9543 - val_accuracy: 0.7520\n",
      "Epoch 871/1000\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 0.8205 - accuracy: 0.8047 - val_loss: 0.9388 - val_accuracy: 0.7610\n",
      "Epoch 872/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8290 - accuracy: 0.8024 - val_loss: 1.0520 - val_accuracy: 0.7240\n",
      "Epoch 873/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.8281 - accuracy: 0.8030 - val_loss: 0.9823 - val_accuracy: 0.7550\n",
      "Epoch 874/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.8234 - accuracy: 0.8007 - val_loss: 0.9386 - val_accuracy: 0.7600\n",
      "Epoch 875/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8283 - accuracy: 0.8011 - val_loss: 0.9442 - val_accuracy: 0.7620\n",
      "Epoch 876/1000\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 0.8205 - accuracy: 0.8043 - val_loss: 0.9564 - val_accuracy: 0.7480\n",
      "Epoch 877/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.8283 - accuracy: 0.8003 - val_loss: 0.9671 - val_accuracy: 0.7590\n",
      "Epoch 878/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.8182 - accuracy: 0.8053 - val_loss: 0.9808 - val_accuracy: 0.7510\n",
      "Epoch 879/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.8257 - accuracy: 0.8044 - val_loss: 0.9416 - val_accuracy: 0.7590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 880/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8189 - accuracy: 0.8037 - val_loss: 1.0350 - val_accuracy: 0.7290\n",
      "Epoch 881/1000\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 0.8372 - accuracy: 0.7967 - val_loss: 0.9483 - val_accuracy: 0.7650\n",
      "Epoch 882/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8183 - accuracy: 0.8054 - val_loss: 0.9568 - val_accuracy: 0.7430\n",
      "Epoch 883/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8240 - accuracy: 0.8027 - val_loss: 0.9474 - val_accuracy: 0.7520\n",
      "Epoch 884/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8217 - accuracy: 0.8047 - val_loss: 0.9541 - val_accuracy: 0.7580\n",
      "Epoch 885/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8219 - accuracy: 0.8064 - val_loss: 0.9496 - val_accuracy: 0.7650\n",
      "Epoch 886/1000\n",
      "7000/7000 [==============================] - 0s 52us/step - loss: 0.8214 - accuracy: 0.8051 - val_loss: 0.9779 - val_accuracy: 0.7410\n",
      "Epoch 887/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8248 - accuracy: 0.8031 - val_loss: 0.9482 - val_accuracy: 0.7580\n",
      "Epoch 888/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.8272 - accuracy: 0.8011 - val_loss: 0.9538 - val_accuracy: 0.7540\n",
      "Epoch 889/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.8162 - accuracy: 0.8061 - val_loss: 0.9421 - val_accuracy: 0.7500\n",
      "Epoch 890/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8226 - accuracy: 0.8013 - val_loss: 0.9433 - val_accuracy: 0.7590\n",
      "Epoch 891/1000\n",
      "7000/7000 [==============================] - 0s 51us/step - loss: 0.8228 - accuracy: 0.8024 - val_loss: 0.9417 - val_accuracy: 0.7570\n",
      "Epoch 892/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8256 - accuracy: 0.7989 - val_loss: 0.9494 - val_accuracy: 0.7570\n",
      "Epoch 893/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8188 - accuracy: 0.8054 - val_loss: 0.9414 - val_accuracy: 0.7650\n",
      "Epoch 894/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8280 - accuracy: 0.8009 - val_loss: 0.9341 - val_accuracy: 0.7560\n",
      "Epoch 895/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.8149 - accuracy: 0.8051 - val_loss: 0.9866 - val_accuracy: 0.7330\n",
      "Epoch 896/1000\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 0.8200 - accuracy: 0.8021 - val_loss: 0.9483 - val_accuracy: 0.7630\n",
      "Epoch 897/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8203 - accuracy: 0.8044 - val_loss: 0.9348 - val_accuracy: 0.7610\n",
      "Epoch 898/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.8185 - accuracy: 0.8044 - val_loss: 0.9771 - val_accuracy: 0.7390\n",
      "Epoch 899/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8224 - accuracy: 0.8041 - val_loss: 0.9539 - val_accuracy: 0.7580\n",
      "Epoch 900/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.8271 - accuracy: 0.8024 - val_loss: 0.9427 - val_accuracy: 0.7590\n",
      "Epoch 901/1000\n",
      "7000/7000 [==============================] - 0s 53us/step - loss: 0.8317 - accuracy: 0.7970 - val_loss: 0.9439 - val_accuracy: 0.7550\n",
      "Epoch 902/1000\n",
      "7000/7000 [==============================] - 0s 53us/step - loss: 0.8147 - accuracy: 0.8039 - val_loss: 0.9574 - val_accuracy: 0.7580\n",
      "Epoch 903/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8278 - accuracy: 0.7974 - val_loss: 0.9436 - val_accuracy: 0.7600\n",
      "Epoch 904/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8283 - accuracy: 0.8011 - val_loss: 0.9401 - val_accuracy: 0.7590\n",
      "Epoch 905/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8201 - accuracy: 0.7999 - val_loss: 0.9852 - val_accuracy: 0.7370\n",
      "Epoch 906/1000\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 0.8292 - accuracy: 0.8006 - val_loss: 0.9899 - val_accuracy: 0.7330\n",
      "Epoch 907/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.8343 - accuracy: 0.7969 - val_loss: 0.9339 - val_accuracy: 0.7580\n",
      "Epoch 908/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8196 - accuracy: 0.8036 - val_loss: 1.0170 - val_accuracy: 0.7220\n",
      "Epoch 909/1000\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.8174 - accuracy: 0.8034 - val_loss: 0.9564 - val_accuracy: 0.7600\n",
      "Epoch 910/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.8295 - accuracy: 0.8000 - val_loss: 0.9529 - val_accuracy: 0.7600\n",
      "Epoch 911/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.8401 - accuracy: 0.7983 - val_loss: 0.9691 - val_accuracy: 0.7470\n",
      "Epoch 912/1000\n",
      "7000/7000 [==============================] - 1s 82us/step - loss: 0.8248 - accuracy: 0.8001 - val_loss: 0.9389 - val_accuracy: 0.7540\n",
      "Epoch 913/1000\n",
      "7000/7000 [==============================] - 0s 65us/step - loss: 0.8230 - accuracy: 0.8033 - val_loss: 0.9356 - val_accuracy: 0.7680\n",
      "Epoch 914/1000\n",
      "7000/7000 [==============================] - 1s 75us/step - loss: 0.8207 - accuracy: 0.8033 - val_loss: 0.9455 - val_accuracy: 0.7510\n",
      "Epoch 915/1000\n",
      "7000/7000 [==============================] - 1s 72us/step - loss: 0.8227 - accuracy: 0.8001 - val_loss: 0.9737 - val_accuracy: 0.7490\n",
      "Epoch 916/1000\n",
      "7000/7000 [==============================] - 1s 75us/step - loss: 0.8225 - accuracy: 0.8027 - val_loss: 0.9656 - val_accuracy: 0.7520\n",
      "Epoch 917/1000\n",
      "7000/7000 [==============================] - 1s 81us/step - loss: 0.8144 - accuracy: 0.8101 - val_loss: 0.9498 - val_accuracy: 0.7500\n",
      "Epoch 918/1000\n",
      "7000/7000 [==============================] - 1s 84us/step - loss: 0.8175 - accuracy: 0.8034 - val_loss: 0.9535 - val_accuracy: 0.7500\n",
      "Epoch 919/1000\n",
      "7000/7000 [==============================] - 1s 87us/step - loss: 0.8196 - accuracy: 0.8013 - val_loss: 0.9675 - val_accuracy: 0.7510\n",
      "Epoch 920/1000\n",
      "7000/7000 [==============================] - 1s 84us/step - loss: 0.8159 - accuracy: 0.8067 - val_loss: 0.9657 - val_accuracy: 0.7660\n",
      "Epoch 921/1000\n",
      "7000/7000 [==============================] - 1s 76us/step - loss: 0.8189 - accuracy: 0.8049 - val_loss: 0.9491 - val_accuracy: 0.7580\n",
      "Epoch 922/1000\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 0.8224 - accuracy: 0.8003 - val_loss: 0.9550 - val_accuracy: 0.7580\n",
      "Epoch 923/1000\n",
      "7000/7000 [==============================] - 1s 78us/step - loss: 0.8193 - accuracy: 0.8027 - val_loss: 0.9448 - val_accuracy: 0.7550\n",
      "Epoch 924/1000\n",
      "7000/7000 [==============================] - 1s 76us/step - loss: 0.8161 - accuracy: 0.8039 - val_loss: 0.9343 - val_accuracy: 0.7600\n",
      "Epoch 925/1000\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 0.8364 - accuracy: 0.7977 - val_loss: 0.9749 - val_accuracy: 0.7620\n",
      "Epoch 926/1000\n",
      "7000/7000 [==============================] - 0s 67us/step - loss: 0.8168 - accuracy: 0.8053 - val_loss: 0.9447 - val_accuracy: 0.7620\n",
      "Epoch 927/1000\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 0.8178 - accuracy: 0.8086 - val_loss: 0.9706 - val_accuracy: 0.7590\n",
      "Epoch 928/1000\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 0.8206 - accuracy: 0.8049 - val_loss: 0.9709 - val_accuracy: 0.7480\n",
      "Epoch 929/1000\n",
      "7000/7000 [==============================] - 0s 68us/step - loss: 0.8222 - accuracy: 0.8003 - val_loss: 0.9793 - val_accuracy: 0.7570\n",
      "Epoch 930/1000\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 0.8163 - accuracy: 0.8069 - val_loss: 0.9456 - val_accuracy: 0.7640\n",
      "Epoch 931/1000\n",
      "7000/7000 [==============================] - 0s 67us/step - loss: 0.8397 - accuracy: 0.7926 - val_loss: 1.0708 - val_accuracy: 0.7150\n",
      "Epoch 932/1000\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 0.8184 - accuracy: 0.8031 - val_loss: 0.9924 - val_accuracy: 0.7490\n",
      "Epoch 933/1000\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 0.8165 - accuracy: 0.8091 - val_loss: 1.0105 - val_accuracy: 0.7480\n",
      "Epoch 934/1000\n",
      "7000/7000 [==============================] - 0s 68us/step - loss: 0.8438 - accuracy: 0.7940 - val_loss: 0.9443 - val_accuracy: 0.7510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 935/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.8172 - accuracy: 0.8053 - val_loss: 0.9524 - val_accuracy: 0.7690\n",
      "Epoch 936/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.8191 - accuracy: 0.8049 - val_loss: 0.9474 - val_accuracy: 0.7630\n",
      "Epoch 937/1000\n",
      "7000/7000 [==============================] - 0s 64us/step - loss: 0.8154 - accuracy: 0.8067 - val_loss: 0.9965 - val_accuracy: 0.7460\n",
      "Epoch 938/1000\n",
      "7000/7000 [==============================] - 0s 71us/step - loss: 0.8317 - accuracy: 0.7954 - val_loss: 0.9636 - val_accuracy: 0.7500\n",
      "Epoch 939/1000\n",
      "7000/7000 [==============================] - 0s 67us/step - loss: 0.8347 - accuracy: 0.7946 - val_loss: 0.9630 - val_accuracy: 0.7510\n",
      "Epoch 940/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 0.8169 - accuracy: 0.8040 - val_loss: 0.9472 - val_accuracy: 0.7510\n",
      "Epoch 941/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 0.8144 - accuracy: 0.8040 - val_loss: 1.0352 - val_accuracy: 0.7280\n",
      "Epoch 942/1000\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 0.8278 - accuracy: 0.7991 - val_loss: 0.9438 - val_accuracy: 0.7570\n",
      "Epoch 943/1000\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 0.8138 - accuracy: 0.8071 - val_loss: 1.0253 - val_accuracy: 0.7280\n",
      "Epoch 944/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.8141 - accuracy: 0.8073 - val_loss: 0.9367 - val_accuracy: 0.7540\n",
      "Epoch 945/1000\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 0.8290 - accuracy: 0.7963 - val_loss: 0.9603 - val_accuracy: 0.7450\n",
      "Epoch 946/1000\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 0.8208 - accuracy: 0.8040 - val_loss: 0.9590 - val_accuracy: 0.7550\n",
      "Epoch 947/1000\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 0.8121 - accuracy: 0.8090 - val_loss: 0.9409 - val_accuracy: 0.7590\n",
      "Epoch 948/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 0.8111 - accuracy: 0.8081 - val_loss: 0.9496 - val_accuracy: 0.7590\n",
      "Epoch 949/1000\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 0.8192 - accuracy: 0.8084 - val_loss: 0.9556 - val_accuracy: 0.7580\n",
      "Epoch 950/1000\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 0.8118 - accuracy: 0.8059 - val_loss: 0.9337 - val_accuracy: 0.7660\n",
      "Epoch 951/1000\n",
      "7000/7000 [==============================] - 0s 64us/step - loss: 0.8206 - accuracy: 0.8034 - val_loss: 0.9785 - val_accuracy: 0.7490\n",
      "Epoch 952/1000\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 0.8250 - accuracy: 0.8006 - val_loss: 0.9757 - val_accuracy: 0.7500\n",
      "Epoch 953/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.8121 - accuracy: 0.8087 - val_loss: 1.0118 - val_accuracy: 0.7270\n",
      "Epoch 954/1000\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 0.8164 - accuracy: 0.8071 - val_loss: 0.9418 - val_accuracy: 0.7550\n",
      "Epoch 955/1000\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 0.8127 - accuracy: 0.8086 - val_loss: 0.9689 - val_accuracy: 0.7640\n",
      "Epoch 956/1000\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 0.8310 - accuracy: 0.7954 - val_loss: 0.9389 - val_accuracy: 0.7690\n",
      "Epoch 957/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 0.8140 - accuracy: 0.8031 - val_loss: 0.9513 - val_accuracy: 0.7600\n",
      "Epoch 958/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 0.8080 - accuracy: 0.8079 - val_loss: 0.9465 - val_accuracy: 0.7670\n",
      "Epoch 959/1000\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 0.8152 - accuracy: 0.8060 - val_loss: 0.9558 - val_accuracy: 0.7470\n",
      "Epoch 960/1000\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 0.8304 - accuracy: 0.8011 - val_loss: 0.9788 - val_accuracy: 0.7400\n",
      "Epoch 961/1000\n",
      "7000/7000 [==============================] - 0s 64us/step - loss: 0.8119 - accuracy: 0.8094 - val_loss: 0.9783 - val_accuracy: 0.7480\n",
      "Epoch 962/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.8258 - accuracy: 0.7989 - val_loss: 0.9735 - val_accuracy: 0.7450\n",
      "Epoch 963/1000\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 0.8272 - accuracy: 0.8020 - val_loss: 0.9612 - val_accuracy: 0.7590\n",
      "Epoch 964/1000\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 0.8178 - accuracy: 0.8060 - val_loss: 0.9592 - val_accuracy: 0.7530\n",
      "Epoch 965/1000\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 0.8177 - accuracy: 0.8053 - val_loss: 0.9454 - val_accuracy: 0.7620\n",
      "Epoch 966/1000\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 0.8153 - accuracy: 0.8059 - val_loss: 0.9597 - val_accuracy: 0.7600\n",
      "Epoch 967/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 0.8065 - accuracy: 0.8100 - val_loss: 0.9461 - val_accuracy: 0.7590\n",
      "Epoch 968/1000\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 0.8114 - accuracy: 0.8086 - val_loss: 0.9655 - val_accuracy: 0.7430\n",
      "Epoch 969/1000\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 0.8098 - accuracy: 0.8063 - val_loss: 1.0706 - val_accuracy: 0.7260\n",
      "Epoch 970/1000\n",
      "7000/7000 [==============================] - 0s 64us/step - loss: 0.8636 - accuracy: 0.7817 - val_loss: 0.9350 - val_accuracy: 0.7620\n",
      "Epoch 971/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.8116 - accuracy: 0.8100 - val_loss: 0.9450 - val_accuracy: 0.7720\n",
      "Epoch 972/1000\n",
      "7000/7000 [==============================] - 0s 65us/step - loss: 0.8180 - accuracy: 0.8014 - val_loss: 0.9701 - val_accuracy: 0.7500\n",
      "Epoch 973/1000\n",
      "7000/7000 [==============================] - 0s 64us/step - loss: 0.8130 - accuracy: 0.8071 - val_loss: 0.9424 - val_accuracy: 0.7650\n",
      "Epoch 974/1000\n",
      "7000/7000 [==============================] - 0s 67us/step - loss: 0.8218 - accuracy: 0.8024 - val_loss: 0.9790 - val_accuracy: 0.7330\n",
      "Epoch 975/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.8116 - accuracy: 0.8050 - val_loss: 0.9718 - val_accuracy: 0.7670\n",
      "Epoch 976/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.8148 - accuracy: 0.8000 - val_loss: 0.9425 - val_accuracy: 0.7570\n",
      "Epoch 977/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.8187 - accuracy: 0.8050 - val_loss: 0.9443 - val_accuracy: 0.7760\n",
      "Epoch 978/1000\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 0.8119 - accuracy: 0.8076 - val_loss: 0.9972 - val_accuracy: 0.7420\n",
      "Epoch 979/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.8102 - accuracy: 0.8089 - val_loss: 0.9400 - val_accuracy: 0.7610\n",
      "Epoch 980/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.8063 - accuracy: 0.8097 - val_loss: 0.9437 - val_accuracy: 0.7610\n",
      "Epoch 981/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.8125 - accuracy: 0.8064 - val_loss: 0.9670 - val_accuracy: 0.7610\n",
      "Epoch 982/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.8252 - accuracy: 0.7983 - val_loss: 0.9362 - val_accuracy: 0.7610\n",
      "Epoch 983/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.8118 - accuracy: 0.8089 - val_loss: 0.9696 - val_accuracy: 0.7430\n",
      "Epoch 984/1000\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 0.8134 - accuracy: 0.8070 - val_loss: 0.9471 - val_accuracy: 0.7550\n",
      "Epoch 985/1000\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.8274 - accuracy: 0.7994 - val_loss: 1.0735 - val_accuracy: 0.7070\n",
      "Epoch 986/1000\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 0.8338 - accuracy: 0.7951 - val_loss: 0.9992 - val_accuracy: 0.7290\n",
      "Epoch 987/1000\n",
      "7000/7000 [==============================] - 0s 65us/step - loss: 0.8240 - accuracy: 0.8020 - val_loss: 0.9607 - val_accuracy: 0.7550\n",
      "Epoch 988/1000\n",
      "7000/7000 [==============================] - 0s 68us/step - loss: 0.8089 - accuracy: 0.8066 - val_loss: 1.0156 - val_accuracy: 0.7430\n",
      "Epoch 989/1000\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 0.8173 - accuracy: 0.8021 - val_loss: 0.9612 - val_accuracy: 0.7540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 990/1000\n",
      "7000/7000 [==============================] - 0s 53us/step - loss: 0.8165 - accuracy: 0.8041 - val_loss: 0.9728 - val_accuracy: 0.7540\n",
      "Epoch 991/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8137 - accuracy: 0.8053 - val_loss: 1.0259 - val_accuracy: 0.7310\n",
      "Epoch 992/1000\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.8326 - accuracy: 0.7941 - val_loss: 0.9542 - val_accuracy: 0.7580\n",
      "Epoch 993/1000\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.8233 - accuracy: 0.8013 - val_loss: 0.9546 - val_accuracy: 0.7530\n",
      "Epoch 994/1000\n",
      "7000/7000 [==============================] - 1s 85us/step - loss: 0.8080 - accuracy: 0.8070 - val_loss: 0.9452 - val_accuracy: 0.7560\n",
      "Epoch 995/1000\n",
      "7000/7000 [==============================] - 1s 72us/step - loss: 0.8141 - accuracy: 0.8056 - val_loss: 0.9439 - val_accuracy: 0.7670\n",
      "Epoch 996/1000\n",
      "7000/7000 [==============================] - 1s 81us/step - loss: 0.8094 - accuracy: 0.8079 - val_loss: 0.9441 - val_accuracy: 0.7530\n",
      "Epoch 997/1000\n",
      "7000/7000 [==============================] - 1s 80us/step - loss: 0.8153 - accuracy: 0.8031 - val_loss: 1.1490 - val_accuracy: 0.6890\n",
      "Epoch 998/1000\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 0.8562 - accuracy: 0.7859 - val_loss: 1.0324 - val_accuracy: 0.7210\n",
      "Epoch 999/1000\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 0.8149 - accuracy: 0.8034 - val_loss: 0.9512 - val_accuracy: 0.7580\n",
      "Epoch 1000/1000\n",
      "7000/7000 [==============================] - 1s 73us/step - loss: 0.8160 - accuracy: 0.8047 - val_loss: 0.9523 - val_accuracy: 0.7630\n"
     ]
    }
   ],
   "source": [
    "#  This cell may take several minutes to run\n",
    "random.seed(123)\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(50, activation='relu',kernel_regularizer=regularizers.l1(0.005), input_shape=(2000,))) #2 hidden layers\n",
    "model.add(keras.layers.Dense(25, kernel_regularizer=regularizers.l1(0.005), activation='relu'))\n",
    "model.add(keras.layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "L1_model = model.fit(X_train_tokenized,\n",
    "                    y_train_bin,\n",
    "                    epochs=1000,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "L1_model_dict = L1_model.history\n",
    "\n",
    "acc_values = L1_model_dict['accuracy'] \n",
    "val_acc_values = L1_model_dict['val_accuracy']\n",
    "\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "ax.plot(epochs, acc_values, label='Training acc L1')\n",
    "ax.plot(epochs, val_acc_values, label='Validation acc L1')\n",
    "ax.set_title('Training & validation accuracy L2 vs regular')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 1s 96us/step\n",
      "Training Loss: 0.816 Training Accuracy: 0.806\n",
      "2000/2000 [==============================] - 0s 70us/step\n",
      "Testing Loss: 0.984 Testing Accuracy: 0.758\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(X_train_tokenized, y_train_bin)\n",
    "print(f'Training Loss: {results_train[0]:.3} Training Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "results_test = model.evaluate(X_test_tok, y_test_cat)\n",
    "print(f'Testing Loss: {results_test[0]:.3} Testing Accuracy: {results_test[1]:.3}')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is about the best result you've achieved so far, but you were training for quite a while! Next, experiment with dropout regularization to see if it offers any advantages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 1000 samples\n",
      "Epoch 1/200\n",
      "7000/7000 [==============================] - 1s 135us/step - loss: 1.9953 - accuracy: 0.1353 - val_loss: 1.9422 - val_accuracy: 0.1570\n",
      "Epoch 2/200\n",
      "7000/7000 [==============================] - 1s 104us/step - loss: 1.9652 - accuracy: 0.1443 - val_loss: 1.9280 - val_accuracy: 0.1800\n",
      "Epoch 3/200\n",
      "7000/7000 [==============================] - 1s 110us/step - loss: 1.9425 - accuracy: 0.1730 - val_loss: 1.9174 - val_accuracy: 0.2110\n",
      "Epoch 4/200\n",
      "7000/7000 [==============================] - 1s 127us/step - loss: 1.9321 - accuracy: 0.1827 - val_loss: 1.9083 - val_accuracy: 0.2260\n",
      "Epoch 5/200\n",
      "7000/7000 [==============================] - 1s 108us/step - loss: 1.9207 - accuracy: 0.1943 - val_loss: 1.8989 - val_accuracy: 0.2290\n",
      "Epoch 6/200\n",
      "7000/7000 [==============================] - 1s 129us/step - loss: 1.9157 - accuracy: 0.2021 - val_loss: 1.8901 - val_accuracy: 0.2370\n",
      "Epoch 7/200\n",
      "7000/7000 [==============================] - 1s 108us/step - loss: 1.9080 - accuracy: 0.2013 - val_loss: 1.8813 - val_accuracy: 0.2400\n",
      "Epoch 8/200\n",
      "7000/7000 [==============================] - 1s 108us/step - loss: 1.9020 - accuracy: 0.2073 - val_loss: 1.8719 - val_accuracy: 0.2520\n",
      "Epoch 9/200\n",
      "7000/7000 [==============================] - 1s 107us/step - loss: 1.8965 - accuracy: 0.2081 - val_loss: 1.8631 - val_accuracy: 0.2590\n",
      "Epoch 10/200\n",
      "7000/7000 [==============================] - 1s 106us/step - loss: 1.8860 - accuracy: 0.2160 - val_loss: 1.8518 - val_accuracy: 0.2650\n",
      "Epoch 11/200\n",
      "7000/7000 [==============================] - 1s 105us/step - loss: 1.8738 - accuracy: 0.2280 - val_loss: 1.8399 - val_accuracy: 0.2820\n",
      "Epoch 12/200\n",
      "7000/7000 [==============================] - 1s 104us/step - loss: 1.8642 - accuracy: 0.2399 - val_loss: 1.8264 - val_accuracy: 0.2880\n",
      "Epoch 13/200\n",
      "7000/7000 [==============================] - 1s 107us/step - loss: 1.8542 - accuracy: 0.2399 - val_loss: 1.8114 - val_accuracy: 0.3110\n",
      "Epoch 14/200\n",
      "7000/7000 [==============================] - 1s 108us/step - loss: 1.8388 - accuracy: 0.2513 - val_loss: 1.7958 - val_accuracy: 0.3310\n",
      "Epoch 15/200\n",
      "7000/7000 [==============================] - 1s 103us/step - loss: 1.8401 - accuracy: 0.2587 - val_loss: 1.7815 - val_accuracy: 0.3430\n",
      "Epoch 16/200\n",
      "7000/7000 [==============================] - 1s 116us/step - loss: 1.8117 - accuracy: 0.2746 - val_loss: 1.7644 - val_accuracy: 0.3690\n",
      "Epoch 17/200\n",
      "7000/7000 [==============================] - 1s 110us/step - loss: 1.8129 - accuracy: 0.2617 - val_loss: 1.7477 - val_accuracy: 0.3720\n",
      "Epoch 18/200\n",
      "7000/7000 [==============================] - 1s 112us/step - loss: 1.7897 - accuracy: 0.2826 - val_loss: 1.7295 - val_accuracy: 0.3820\n",
      "Epoch 19/200\n",
      "7000/7000 [==============================] - 1s 111us/step - loss: 1.7827 - accuracy: 0.2936 - val_loss: 1.7097 - val_accuracy: 0.3960\n",
      "Epoch 20/200\n",
      "7000/7000 [==============================] - 1s 107us/step - loss: 1.7662 - accuracy: 0.3006 - val_loss: 1.6936 - val_accuracy: 0.4130\n",
      "Epoch 21/200\n",
      "7000/7000 [==============================] - 1s 114us/step - loss: 1.7545 - accuracy: 0.3020 - val_loss: 1.6725 - val_accuracy: 0.4190\n",
      "Epoch 22/200\n",
      "7000/7000 [==============================] - 1s 111us/step - loss: 1.7361 - accuracy: 0.3219 - val_loss: 1.6548 - val_accuracy: 0.4320\n",
      "Epoch 23/200\n",
      "7000/7000 [==============================] - 1s 105us/step - loss: 1.7217 - accuracy: 0.3273 - val_loss: 1.6381 - val_accuracy: 0.4470\n",
      "Epoch 24/200\n",
      "7000/7000 [==============================] - 1s 110us/step - loss: 1.7108 - accuracy: 0.3296 - val_loss: 1.6189 - val_accuracy: 0.4560\n",
      "Epoch 25/200\n",
      "7000/7000 [==============================] - 1s 104us/step - loss: 1.7004 - accuracy: 0.3236 - val_loss: 1.5986 - val_accuracy: 0.4600\n",
      "Epoch 26/200\n",
      "7000/7000 [==============================] - 1s 109us/step - loss: 1.6779 - accuracy: 0.3447 - val_loss: 1.5790 - val_accuracy: 0.4680\n",
      "Epoch 27/200\n",
      "7000/7000 [==============================] - 1s 116us/step - loss: 1.6694 - accuracy: 0.3501 - val_loss: 1.5613 - val_accuracy: 0.4830\n",
      "Epoch 28/200\n",
      "7000/7000 [==============================] - 1s 107us/step - loss: 1.6572 - accuracy: 0.3504 - val_loss: 1.5400 - val_accuracy: 0.4880\n",
      "Epoch 29/200\n",
      "7000/7000 [==============================] - 1s 107us/step - loss: 1.6372 - accuracy: 0.3637 - val_loss: 1.5237 - val_accuracy: 0.4980\n",
      "Epoch 30/200\n",
      "7000/7000 [==============================] - 1s 105us/step - loss: 1.6299 - accuracy: 0.3686 - val_loss: 1.5032 - val_accuracy: 0.4990\n",
      "Epoch 31/200\n",
      "7000/7000 [==============================] - 1s 105us/step - loss: 1.6136 - accuracy: 0.3737 - val_loss: 1.4857 - val_accuracy: 0.5070\n",
      "Epoch 32/200\n",
      "7000/7000 [==============================] - 1s 108us/step - loss: 1.5910 - accuracy: 0.3774 - val_loss: 1.4699 - val_accuracy: 0.5130\n",
      "Epoch 33/200\n",
      "7000/7000 [==============================] - 1s 105us/step - loss: 1.5867 - accuracy: 0.3809 - val_loss: 1.4517 - val_accuracy: 0.5180\n",
      "Epoch 34/200\n",
      "7000/7000 [==============================] - 1s 109us/step - loss: 1.5670 - accuracy: 0.3931 - val_loss: 1.4317 - val_accuracy: 0.5280\n",
      "Epoch 35/200\n",
      "7000/7000 [==============================] - 1s 127us/step - loss: 1.5644 - accuracy: 0.3840 - val_loss: 1.4154 - val_accuracy: 0.5310\n",
      "Epoch 36/200\n",
      "7000/7000 [==============================] - 1s 130us/step - loss: 1.5485 - accuracy: 0.3969 - val_loss: 1.3998 - val_accuracy: 0.5390\n",
      "Epoch 37/200\n",
      "7000/7000 [==============================] - 1s 128us/step - loss: 1.5388 - accuracy: 0.4050 - val_loss: 1.3869 - val_accuracy: 0.5470\n",
      "Epoch 38/200\n",
      "7000/7000 [==============================] - 1s 128us/step - loss: 1.5268 - accuracy: 0.4073 - val_loss: 1.3694 - val_accuracy: 0.5600\n",
      "Epoch 39/200\n",
      "7000/7000 [==============================] - 1s 132us/step - loss: 1.5071 - accuracy: 0.4201 - val_loss: 1.3493 - val_accuracy: 0.5700\n",
      "Epoch 40/200\n",
      "7000/7000 [==============================] - 1s 124us/step - loss: 1.5009 - accuracy: 0.4184 - val_loss: 1.3372 - val_accuracy: 0.5800\n",
      "Epoch 41/200\n",
      "7000/7000 [==============================] - 1s 133us/step - loss: 1.4846 - accuracy: 0.4300 - val_loss: 1.3179 - val_accuracy: 0.5850\n",
      "Epoch 42/200\n",
      "7000/7000 [==============================] - 1s 126us/step - loss: 1.4780 - accuracy: 0.4277 - val_loss: 1.3039 - val_accuracy: 0.5820\n",
      "Epoch 43/200\n",
      "7000/7000 [==============================] - 1s 127us/step - loss: 1.4677 - accuracy: 0.4347 - val_loss: 1.2888 - val_accuracy: 0.5900\n",
      "Epoch 44/200\n",
      "7000/7000 [==============================] - 1s 121us/step - loss: 1.4532 - accuracy: 0.4391 - val_loss: 1.2741 - val_accuracy: 0.5910\n",
      "Epoch 45/200\n",
      "7000/7000 [==============================] - 1s 119us/step - loss: 1.4445 - accuracy: 0.4449 - val_loss: 1.2608 - val_accuracy: 0.5950\n",
      "Epoch 46/200\n",
      "7000/7000 [==============================] - 1s 126us/step - loss: 1.4356 - accuracy: 0.4483 - val_loss: 1.2478 - val_accuracy: 0.6060\n",
      "Epoch 47/200\n",
      "7000/7000 [==============================] - 1s 118us/step - loss: 1.4177 - accuracy: 0.4514 - val_loss: 1.2318 - val_accuracy: 0.6120\n",
      "Epoch 48/200\n",
      "7000/7000 [==============================] - 1s 123us/step - loss: 1.4105 - accuracy: 0.4586 - val_loss: 1.2186 - val_accuracy: 0.6220\n",
      "Epoch 49/200\n",
      "7000/7000 [==============================] - 1s 120us/step - loss: 1.3961 - accuracy: 0.4589 - val_loss: 1.2040 - val_accuracy: 0.6230\n",
      "Epoch 50/200\n",
      "7000/7000 [==============================] - 1s 123us/step - loss: 1.3952 - accuracy: 0.4656 - val_loss: 1.1969 - val_accuracy: 0.6270\n",
      "Epoch 51/200\n",
      "7000/7000 [==============================] - 1s 122us/step - loss: 1.3857 - accuracy: 0.4651 - val_loss: 1.1845 - val_accuracy: 0.6330\n",
      "Epoch 52/200\n",
      "7000/7000 [==============================] - 1s 123us/step - loss: 1.3750 - accuracy: 0.4730 - val_loss: 1.1721 - val_accuracy: 0.6380\n",
      "Epoch 53/200\n",
      "7000/7000 [==============================] - 1s 122us/step - loss: 1.3675 - accuracy: 0.4760 - val_loss: 1.1597 - val_accuracy: 0.6420\n",
      "Epoch 54/200\n",
      "7000/7000 [==============================] - 1s 123us/step - loss: 1.3585 - accuracy: 0.4871 - val_loss: 1.1472 - val_accuracy: 0.6480\n",
      "Epoch 55/200\n",
      "7000/7000 [==============================] - 1s 124us/step - loss: 1.3516 - accuracy: 0.4859 - val_loss: 1.1375 - val_accuracy: 0.6490\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 1s 112us/step - loss: 1.3298 - accuracy: 0.4907 - val_loss: 1.1271 - val_accuracy: 0.6530\n",
      "Epoch 57/200\n",
      "7000/7000 [==============================] - 1s 111us/step - loss: 1.3153 - accuracy: 0.4956 - val_loss: 1.1123 - val_accuracy: 0.6570\n",
      "Epoch 58/200\n",
      "7000/7000 [==============================] - 1s 112us/step - loss: 1.3204 - accuracy: 0.4947 - val_loss: 1.1042 - val_accuracy: 0.6610\n",
      "Epoch 59/200\n",
      "7000/7000 [==============================] - 1s 106us/step - loss: 1.2951 - accuracy: 0.5063 - val_loss: 1.0925 - val_accuracy: 0.6640\n",
      "Epoch 60/200\n",
      "7000/7000 [==============================] - 1s 111us/step - loss: 1.3102 - accuracy: 0.5027 - val_loss: 1.0846 - val_accuracy: 0.6660\n",
      "Epoch 61/200\n",
      "7000/7000 [==============================] - 1s 108us/step - loss: 1.2822 - accuracy: 0.5084 - val_loss: 1.0726 - val_accuracy: 0.6680\n",
      "Epoch 62/200\n",
      "7000/7000 [==============================] - 1s 110us/step - loss: 1.2915 - accuracy: 0.5069 - val_loss: 1.0627 - val_accuracy: 0.6650\n",
      "Epoch 63/200\n",
      "7000/7000 [==============================] - 1s 112us/step - loss: 1.2734 - accuracy: 0.5180 - val_loss: 1.0553 - val_accuracy: 0.6720\n",
      "Epoch 64/200\n",
      "7000/7000 [==============================] - 1s 109us/step - loss: 1.2526 - accuracy: 0.5261 - val_loss: 1.0454 - val_accuracy: 0.6770\n",
      "Epoch 65/200\n",
      "7000/7000 [==============================] - 1s 111us/step - loss: 1.2471 - accuracy: 0.5316 - val_loss: 1.0351 - val_accuracy: 0.6790\n",
      "Epoch 66/200\n",
      "7000/7000 [==============================] - 1s 111us/step - loss: 1.2478 - accuracy: 0.5246 - val_loss: 1.0263 - val_accuracy: 0.6810\n",
      "Epoch 67/200\n",
      "7000/7000 [==============================] - 1s 108us/step - loss: 1.2469 - accuracy: 0.5290 - val_loss: 1.0194 - val_accuracy: 0.6840\n",
      "Epoch 68/200\n",
      "7000/7000 [==============================] - 1s 112us/step - loss: 1.2288 - accuracy: 0.5267 - val_loss: 1.0113 - val_accuracy: 0.6880\n",
      "Epoch 69/200\n",
      "7000/7000 [==============================] - 1s 109us/step - loss: 1.2273 - accuracy: 0.5343 - val_loss: 1.0027 - val_accuracy: 0.6890\n",
      "Epoch 70/200\n",
      "7000/7000 [==============================] - 1s 113us/step - loss: 1.2064 - accuracy: 0.5370 - val_loss: 0.9924 - val_accuracy: 0.6890\n",
      "Epoch 71/200\n",
      "7000/7000 [==============================] - 1s 112us/step - loss: 1.1895 - accuracy: 0.5566 - val_loss: 0.9810 - val_accuracy: 0.6930\n",
      "Epoch 72/200\n",
      "7000/7000 [==============================] - 1s 110us/step - loss: 1.1917 - accuracy: 0.5423 - val_loss: 0.9713 - val_accuracy: 0.6950\n",
      "Epoch 73/200\n",
      "7000/7000 [==============================] - 1s 112us/step - loss: 1.2093 - accuracy: 0.5376 - val_loss: 0.9652 - val_accuracy: 0.6970\n",
      "Epoch 74/200\n",
      "7000/7000 [==============================] - 1s 111us/step - loss: 1.1840 - accuracy: 0.5523 - val_loss: 0.9589 - val_accuracy: 0.7020\n",
      "Epoch 75/200\n",
      "7000/7000 [==============================] - 1s 111us/step - loss: 1.1771 - accuracy: 0.5547 - val_loss: 0.9520 - val_accuracy: 0.7020\n",
      "Epoch 76/200\n",
      "7000/7000 [==============================] - 1s 112us/step - loss: 1.1696 - accuracy: 0.5579 - val_loss: 0.9442 - val_accuracy: 0.7050\n",
      "Epoch 77/200\n",
      "7000/7000 [==============================] - 1s 107us/step - loss: 1.1602 - accuracy: 0.5600 - val_loss: 0.9376 - val_accuracy: 0.7070\n",
      "Epoch 78/200\n",
      "7000/7000 [==============================] - 1s 111us/step - loss: 1.1720 - accuracy: 0.5623 - val_loss: 0.9316 - val_accuracy: 0.7110\n",
      "Epoch 79/200\n",
      "7000/7000 [==============================] - 1s 111us/step - loss: 1.1569 - accuracy: 0.5614 - val_loss: 0.9258 - val_accuracy: 0.7130\n",
      "Epoch 80/200\n",
      "7000/7000 [==============================] - 1s 112us/step - loss: 1.1502 - accuracy: 0.5726 - val_loss: 0.9219 - val_accuracy: 0.7070\n",
      "Epoch 81/200\n",
      "7000/7000 [==============================] - 1s 114us/step - loss: 1.1371 - accuracy: 0.5710 - val_loss: 0.9131 - val_accuracy: 0.7080\n",
      "Epoch 82/200\n",
      "7000/7000 [==============================] - 1s 108us/step - loss: 1.1346 - accuracy: 0.5736 - val_loss: 0.9057 - val_accuracy: 0.7110\n",
      "Epoch 83/200\n",
      "7000/7000 [==============================] - 1s 113us/step - loss: 1.1320 - accuracy: 0.5670 - val_loss: 0.9010 - val_accuracy: 0.7140\n",
      "Epoch 84/200\n",
      "7000/7000 [==============================] - 1s 111us/step - loss: 1.1188 - accuracy: 0.5799 - val_loss: 0.8970 - val_accuracy: 0.7130\n",
      "Epoch 85/200\n",
      "7000/7000 [==============================] - 1s 111us/step - loss: 1.1053 - accuracy: 0.5907 - val_loss: 0.8889 - val_accuracy: 0.7160\n",
      "Epoch 86/200\n",
      "7000/7000 [==============================] - 1s 111us/step - loss: 1.1250 - accuracy: 0.5801 - val_loss: 0.8834 - val_accuracy: 0.7190\n",
      "Epoch 87/200\n",
      "7000/7000 [==============================] - 1s 109us/step - loss: 1.0955 - accuracy: 0.5969 - val_loss: 0.8763 - val_accuracy: 0.7170\n",
      "Epoch 88/200\n",
      "7000/7000 [==============================] - 1s 113us/step - loss: 1.0892 - accuracy: 0.5933 - val_loss: 0.8699 - val_accuracy: 0.7210\n",
      "Epoch 89/200\n",
      "7000/7000 [==============================] - 1s 113us/step - loss: 1.0814 - accuracy: 0.5996 - val_loss: 0.8633 - val_accuracy: 0.7210\n",
      "Epoch 90/200\n",
      "7000/7000 [==============================] - 1s 109us/step - loss: 1.0984 - accuracy: 0.5860 - val_loss: 0.8613 - val_accuracy: 0.7160\n",
      "Epoch 91/200\n",
      "7000/7000 [==============================] - 1s 139us/step - loss: 1.0745 - accuracy: 0.5957 - val_loss: 0.8543 - val_accuracy: 0.7240\n",
      "Epoch 92/200\n",
      "7000/7000 [==============================] - 1s 154us/step - loss: 1.0668 - accuracy: 0.5977 - val_loss: 0.8485 - val_accuracy: 0.7240\n",
      "Epoch 93/200\n",
      "7000/7000 [==============================] - 1s 158us/step - loss: 1.0831 - accuracy: 0.5936 - val_loss: 0.8448 - val_accuracy: 0.7260\n",
      "Epoch 94/200\n",
      "7000/7000 [==============================] - 1s 144us/step - loss: 1.0690 - accuracy: 0.6009 - val_loss: 0.8402 - val_accuracy: 0.7290\n",
      "Epoch 95/200\n",
      "7000/7000 [==============================] - 1s 138us/step - loss: 1.0544 - accuracy: 0.6129 - val_loss: 0.8356 - val_accuracy: 0.7280\n",
      "Epoch 96/200\n",
      "7000/7000 [==============================] - 1s 137us/step - loss: 1.0576 - accuracy: 0.5983 - val_loss: 0.8311 - val_accuracy: 0.7320\n",
      "Epoch 97/200\n",
      "7000/7000 [==============================] - 1s 134us/step - loss: 1.0638 - accuracy: 0.6061 - val_loss: 0.8283 - val_accuracy: 0.7330\n",
      "Epoch 98/200\n",
      "7000/7000 [==============================] - 1s 132us/step - loss: 1.0393 - accuracy: 0.6093 - val_loss: 0.8244 - val_accuracy: 0.7340\n",
      "Epoch 99/200\n",
      "7000/7000 [==============================] - 1s 135us/step - loss: 1.0453 - accuracy: 0.6091 - val_loss: 0.8230 - val_accuracy: 0.7330\n",
      "Epoch 100/200\n",
      "7000/7000 [==============================] - 1s 141us/step - loss: 1.0333 - accuracy: 0.6121 - val_loss: 0.8160 - val_accuracy: 0.7340\n",
      "Epoch 101/200\n",
      "7000/7000 [==============================] - 1s 154us/step - loss: 1.0357 - accuracy: 0.6107 - val_loss: 0.8107 - val_accuracy: 0.7360\n",
      "Epoch 102/200\n",
      "7000/7000 [==============================] - 1s 157us/step - loss: 1.0312 - accuracy: 0.6111 - val_loss: 0.8067 - val_accuracy: 0.7320\n",
      "Epoch 103/200\n",
      "7000/7000 [==============================] - 1s 125us/step - loss: 1.0354 - accuracy: 0.6093 - val_loss: 0.8035 - val_accuracy: 0.7350\n",
      "Epoch 104/200\n",
      "7000/7000 [==============================] - 1s 118us/step - loss: 1.0228 - accuracy: 0.6170 - val_loss: 0.7995 - val_accuracy: 0.7360\n",
      "Epoch 105/200\n",
      "7000/7000 [==============================] - 1s 153us/step - loss: 1.0144 - accuracy: 0.6224 - val_loss: 0.7950 - val_accuracy: 0.7340\n",
      "Epoch 106/200\n",
      "7000/7000 [==============================] - 1s 119us/step - loss: 1.0146 - accuracy: 0.6131 - val_loss: 0.7905 - val_accuracy: 0.7350\n",
      "Epoch 107/200\n",
      "7000/7000 [==============================] - 1s 129us/step - loss: 1.0210 - accuracy: 0.6146 - val_loss: 0.7880 - val_accuracy: 0.7370\n",
      "Epoch 108/200\n",
      "7000/7000 [==============================] - 1s 155us/step - loss: 1.0073 - accuracy: 0.6281 - val_loss: 0.7850 - val_accuracy: 0.7360\n",
      "Epoch 109/200\n",
      "7000/7000 [==============================] - 1s 131us/step - loss: 1.0082 - accuracy: 0.6256 - val_loss: 0.7808 - val_accuracy: 0.7380\n",
      "Epoch 110/200\n",
      "7000/7000 [==============================] - 2s 239us/step - loss: 1.0105 - accuracy: 0.6223 - val_loss: 0.7785 - val_accuracy: 0.7380\n",
      "Epoch 111/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 1s 129us/step - loss: 1.0014 - accuracy: 0.6214 - val_loss: 0.7762 - val_accuracy: 0.7360\n",
      "Epoch 112/200\n",
      "7000/7000 [==============================] - 1s 119us/step - loss: 0.9973 - accuracy: 0.6296 - val_loss: 0.7729 - val_accuracy: 0.7400\n",
      "Epoch 113/200\n",
      "7000/7000 [==============================] - 1s 123us/step - loss: 0.9882 - accuracy: 0.6316 - val_loss: 0.7705 - val_accuracy: 0.7380\n",
      "Epoch 114/200\n",
      "7000/7000 [==============================] - 1s 116us/step - loss: 0.9744 - accuracy: 0.6393 - val_loss: 0.7657 - val_accuracy: 0.7400\n",
      "Epoch 115/200\n",
      "7000/7000 [==============================] - 1s 123us/step - loss: 0.9910 - accuracy: 0.6347 - val_loss: 0.7628 - val_accuracy: 0.7410\n",
      "Epoch 116/200\n",
      "7000/7000 [==============================] - 1s 118us/step - loss: 0.9686 - accuracy: 0.6383 - val_loss: 0.7604 - val_accuracy: 0.7420\n",
      "Epoch 117/200\n",
      "7000/7000 [==============================] - 1s 121us/step - loss: 0.9602 - accuracy: 0.6406 - val_loss: 0.7574 - val_accuracy: 0.7440\n",
      "Epoch 118/200\n",
      "7000/7000 [==============================] - 1s 178us/step - loss: 0.9663 - accuracy: 0.6370 - val_loss: 0.7552 - val_accuracy: 0.7420\n",
      "Epoch 119/200\n",
      "7000/7000 [==============================] - 1s 169us/step - loss: 0.9730 - accuracy: 0.6440 - val_loss: 0.7520 - val_accuracy: 0.7450\n",
      "Epoch 120/200\n",
      "7000/7000 [==============================] - 1s 179us/step - loss: 0.9807 - accuracy: 0.6321 - val_loss: 0.7506 - val_accuracy: 0.7460\n",
      "Epoch 121/200\n",
      "7000/7000 [==============================] - 1s 164us/step - loss: 0.9765 - accuracy: 0.6286 - val_loss: 0.7504 - val_accuracy: 0.7450\n",
      "Epoch 122/200\n",
      "7000/7000 [==============================] - 1s 161us/step - loss: 0.9533 - accuracy: 0.6516 - val_loss: 0.7470 - val_accuracy: 0.7450\n",
      "Epoch 123/200\n",
      "7000/7000 [==============================] - 1s 154us/step - loss: 0.9413 - accuracy: 0.6487 - val_loss: 0.7421 - val_accuracy: 0.7450\n",
      "Epoch 124/200\n",
      "7000/7000 [==============================] - 1s 156us/step - loss: 0.9572 - accuracy: 0.6423 - val_loss: 0.7400 - val_accuracy: 0.7460\n",
      "Epoch 125/200\n",
      "7000/7000 [==============================] - 1s 147us/step - loss: 0.9592 - accuracy: 0.6483 - val_loss: 0.7379 - val_accuracy: 0.7420\n",
      "Epoch 126/200\n",
      "7000/7000 [==============================] - 1s 145us/step - loss: 0.9476 - accuracy: 0.6451 - val_loss: 0.7375 - val_accuracy: 0.7460\n",
      "Epoch 127/200\n",
      "7000/7000 [==============================] - 1s 131us/step - loss: 0.9474 - accuracy: 0.6519 - val_loss: 0.7341 - val_accuracy: 0.7460\n",
      "Epoch 128/200\n",
      "7000/7000 [==============================] - 1s 113us/step - loss: 0.9510 - accuracy: 0.6457 - val_loss: 0.7323 - val_accuracy: 0.7420\n",
      "Epoch 129/200\n",
      "7000/7000 [==============================] - 1s 137us/step - loss: 0.9510 - accuracy: 0.6500 - val_loss: 0.7305 - val_accuracy: 0.7450\n",
      "Epoch 130/200\n",
      "7000/7000 [==============================] - 1s 139us/step - loss: 0.9337 - accuracy: 0.6499 - val_loss: 0.7276 - val_accuracy: 0.7450\n",
      "Epoch 131/200\n",
      "7000/7000 [==============================] - 1s 116us/step - loss: 0.9243 - accuracy: 0.6504 - val_loss: 0.7246 - val_accuracy: 0.7460\n",
      "Epoch 132/200\n",
      "7000/7000 [==============================] - 1s 112us/step - loss: 0.9236 - accuracy: 0.6546 - val_loss: 0.7240 - val_accuracy: 0.7440\n",
      "Epoch 133/200\n",
      "7000/7000 [==============================] - 1s 127us/step - loss: 0.9145 - accuracy: 0.6597 - val_loss: 0.7189 - val_accuracy: 0.7450\n",
      "Epoch 134/200\n",
      "7000/7000 [==============================] - 1s 123us/step - loss: 0.9115 - accuracy: 0.6630 - val_loss: 0.7174 - val_accuracy: 0.7500\n",
      "Epoch 135/200\n",
      "7000/7000 [==============================] - 1s 129us/step - loss: 0.9314 - accuracy: 0.6536 - val_loss: 0.7150 - val_accuracy: 0.7470\n",
      "Epoch 136/200\n",
      "7000/7000 [==============================] - 1s 157us/step - loss: 0.9094 - accuracy: 0.6649 - val_loss: 0.7124 - val_accuracy: 0.7460\n",
      "Epoch 137/200\n",
      "7000/7000 [==============================] - 1s 140us/step - loss: 0.9079 - accuracy: 0.6566 - val_loss: 0.7106 - val_accuracy: 0.7460\n",
      "Epoch 138/200\n",
      "7000/7000 [==============================] - 1s 140us/step - loss: 0.9143 - accuracy: 0.6574 - val_loss: 0.7132 - val_accuracy: 0.7510\n",
      "Epoch 139/200\n",
      "7000/7000 [==============================] - 1s 129us/step - loss: 0.9047 - accuracy: 0.6637 - val_loss: 0.7083 - val_accuracy: 0.7480\n",
      "Epoch 140/200\n",
      "7000/7000 [==============================] - 1s 125us/step - loss: 0.8976 - accuracy: 0.6637 - val_loss: 0.7054 - val_accuracy: 0.7500\n",
      "Epoch 141/200\n",
      "7000/7000 [==============================] - 1s 130us/step - loss: 0.9021 - accuracy: 0.6643 - val_loss: 0.7051 - val_accuracy: 0.7520\n",
      "Epoch 142/200\n",
      "7000/7000 [==============================] - 1s 129us/step - loss: 0.9017 - accuracy: 0.6631 - val_loss: 0.7019 - val_accuracy: 0.7510\n",
      "Epoch 143/200\n",
      "7000/7000 [==============================] - 1s 132us/step - loss: 0.9025 - accuracy: 0.6644 - val_loss: 0.7004 - val_accuracy: 0.7520\n",
      "Epoch 144/200\n",
      "7000/7000 [==============================] - 1s 130us/step - loss: 0.9054 - accuracy: 0.6601 - val_loss: 0.7008 - val_accuracy: 0.7530\n",
      "Epoch 145/200\n",
      "7000/7000 [==============================] - 1s 115us/step - loss: 0.8973 - accuracy: 0.6636 - val_loss: 0.6989 - val_accuracy: 0.7520\n",
      "Epoch 146/200\n",
      "7000/7000 [==============================] - 1s 141us/step - loss: 0.8799 - accuracy: 0.6720 - val_loss: 0.6961 - val_accuracy: 0.7530\n",
      "Epoch 147/200\n",
      "7000/7000 [==============================] - 1s 126us/step - loss: 0.8981 - accuracy: 0.6631 - val_loss: 0.6970 - val_accuracy: 0.7490\n",
      "Epoch 148/200\n",
      "7000/7000 [==============================] - 1s 126us/step - loss: 0.8924 - accuracy: 0.6654 - val_loss: 0.6959 - val_accuracy: 0.7540\n",
      "Epoch 149/200\n",
      "7000/7000 [==============================] - 1s 115us/step - loss: 0.8809 - accuracy: 0.6714 - val_loss: 0.6932 - val_accuracy: 0.7530\n",
      "Epoch 150/200\n",
      "7000/7000 [==============================] - 1s 111us/step - loss: 0.8878 - accuracy: 0.6666 - val_loss: 0.6919 - val_accuracy: 0.7540\n",
      "Epoch 151/200\n",
      "7000/7000 [==============================] - 1s 115us/step - loss: 0.8726 - accuracy: 0.6774 - val_loss: 0.6875 - val_accuracy: 0.7530\n",
      "Epoch 152/200\n",
      "7000/7000 [==============================] - 1s 131us/step - loss: 0.8723 - accuracy: 0.6747 - val_loss: 0.6875 - val_accuracy: 0.7540\n",
      "Epoch 153/200\n",
      "7000/7000 [==============================] - 1s 125us/step - loss: 0.8709 - accuracy: 0.6789 - val_loss: 0.6891 - val_accuracy: 0.7540\n",
      "Epoch 154/200\n",
      "7000/7000 [==============================] - 1s 116us/step - loss: 0.8732 - accuracy: 0.6740 - val_loss: 0.6845 - val_accuracy: 0.7510\n",
      "Epoch 155/200\n",
      "7000/7000 [==============================] - 1s 117us/step - loss: 0.8820 - accuracy: 0.6723 - val_loss: 0.6846 - val_accuracy: 0.7520\n",
      "Epoch 156/200\n",
      "7000/7000 [==============================] - 1s 114us/step - loss: 0.8814 - accuracy: 0.6733 - val_loss: 0.6832 - val_accuracy: 0.7560\n",
      "Epoch 157/200\n",
      "7000/7000 [==============================] - 1s 111us/step - loss: 0.8532 - accuracy: 0.6800 - val_loss: 0.6809 - val_accuracy: 0.7550\n",
      "Epoch 158/200\n",
      "7000/7000 [==============================] - 1s 126us/step - loss: 0.8716 - accuracy: 0.6731 - val_loss: 0.6809 - val_accuracy: 0.7540\n",
      "Epoch 159/200\n",
      "7000/7000 [==============================] - 1s 115us/step - loss: 0.8582 - accuracy: 0.6787 - val_loss: 0.6809 - val_accuracy: 0.7520\n",
      "Epoch 160/200\n",
      "7000/7000 [==============================] - 2s 215us/step - loss: 0.8611 - accuracy: 0.6787 - val_loss: 0.6808 - val_accuracy: 0.7560\n",
      "Epoch 161/200\n",
      "7000/7000 [==============================] - 1s 163us/step - loss: 0.8589 - accuracy: 0.6786 - val_loss: 0.6782 - val_accuracy: 0.7550\n",
      "Epoch 162/200\n",
      "7000/7000 [==============================] - 1s 138us/step - loss: 0.8555 - accuracy: 0.6834 - val_loss: 0.6740 - val_accuracy: 0.7560\n",
      "Epoch 163/200\n",
      "7000/7000 [==============================] - 1s 133us/step - loss: 0.8504 - accuracy: 0.6834 - val_loss: 0.6728 - val_accuracy: 0.7590\n",
      "Epoch 164/200\n",
      "7000/7000 [==============================] - 1s 135us/step - loss: 0.8502 - accuracy: 0.6817 - val_loss: 0.6733 - val_accuracy: 0.7560\n",
      "Epoch 165/200\n",
      "7000/7000 [==============================] - 1s 134us/step - loss: 0.8420 - accuracy: 0.6887 - val_loss: 0.6705 - val_accuracy: 0.7570\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 1s 120us/step - loss: 0.8457 - accuracy: 0.6860 - val_loss: 0.6712 - val_accuracy: 0.7570\n",
      "Epoch 167/200\n",
      "2048/7000 [=======>......................] - ETA: 1s - loss: 0.8793 - accuracy: 0.6777"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\keras\\callbacks\\callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.236166). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\keras\\callbacks\\callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.118592). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 1s 150us/step - loss: 0.8480 - accuracy: 0.6853 - val_loss: 0.6687 - val_accuracy: 0.7570\n",
      "Epoch 168/200\n",
      "7000/7000 [==============================] - 1s 118us/step - loss: 0.8276 - accuracy: 0.6914 - val_loss: 0.6681 - val_accuracy: 0.7530\n",
      "Epoch 169/200\n",
      "7000/7000 [==============================] - 1s 116us/step - loss: 0.8348 - accuracy: 0.6894 - val_loss: 0.6673 - val_accuracy: 0.7530\n",
      "Epoch 170/200\n",
      "7000/7000 [==============================] - 1s 116us/step - loss: 0.8410 - accuracy: 0.6821 - val_loss: 0.6669 - val_accuracy: 0.7570\n",
      "Epoch 171/200\n",
      "7000/7000 [==============================] - 1s 117us/step - loss: 0.8330 - accuracy: 0.6959 - val_loss: 0.6658 - val_accuracy: 0.7590\n",
      "Epoch 172/200\n",
      "7000/7000 [==============================] - 1s 115us/step - loss: 0.8391 - accuracy: 0.6841 - val_loss: 0.6658 - val_accuracy: 0.7560\n",
      "Epoch 173/200\n",
      "7000/7000 [==============================] - 1s 116us/step - loss: 0.8177 - accuracy: 0.6930 - val_loss: 0.6656 - val_accuracy: 0.7530\n",
      "Epoch 174/200\n",
      "7000/7000 [==============================] - 1s 114us/step - loss: 0.8267 - accuracy: 0.6897 - val_loss: 0.6643 - val_accuracy: 0.7530\n",
      "Epoch 175/200\n",
      "7000/7000 [==============================] - 1s 126us/step - loss: 0.8362 - accuracy: 0.6883 - val_loss: 0.6627 - val_accuracy: 0.7540\n",
      "Epoch 176/200\n",
      "7000/7000 [==============================] - 1s 122us/step - loss: 0.8240 - accuracy: 0.6943 - val_loss: 0.6607 - val_accuracy: 0.7560\n",
      "Epoch 177/200\n",
      "7000/7000 [==============================] - 1s 123us/step - loss: 0.8185 - accuracy: 0.6933 - val_loss: 0.6600 - val_accuracy: 0.7550\n",
      "Epoch 178/200\n",
      "7000/7000 [==============================] - 1s 128us/step - loss: 0.8327 - accuracy: 0.6930 - val_loss: 0.6599 - val_accuracy: 0.7530\n",
      "Epoch 179/200\n",
      "7000/7000 [==============================] - 1s 111us/step - loss: 0.8172 - accuracy: 0.6971 - val_loss: 0.6596 - val_accuracy: 0.7550\n",
      "Epoch 180/200\n",
      "7000/7000 [==============================] - 1s 115us/step - loss: 0.8102 - accuracy: 0.6994 - val_loss: 0.6588 - val_accuracy: 0.7560\n",
      "Epoch 181/200\n",
      "7000/7000 [==============================] - 1s 111us/step - loss: 0.8282 - accuracy: 0.6914 - val_loss: 0.6567 - val_accuracy: 0.7590\n",
      "Epoch 182/200\n",
      "7000/7000 [==============================] - 1s 113us/step - loss: 0.8202 - accuracy: 0.6934 - val_loss: 0.6552 - val_accuracy: 0.7550\n",
      "Epoch 183/200\n",
      "7000/7000 [==============================] - 1s 112us/step - loss: 0.8271 - accuracy: 0.6933 - val_loss: 0.6547 - val_accuracy: 0.7540\n",
      "Epoch 184/200\n",
      "7000/7000 [==============================] - 1s 110us/step - loss: 0.8141 - accuracy: 0.6940 - val_loss: 0.6508 - val_accuracy: 0.7610\n",
      "Epoch 185/200\n",
      "7000/7000 [==============================] - 1s 115us/step - loss: 0.8046 - accuracy: 0.6953 - val_loss: 0.6497 - val_accuracy: 0.7600\n",
      "Epoch 186/200\n",
      "7000/7000 [==============================] - 1s 111us/step - loss: 0.7985 - accuracy: 0.6979 - val_loss: 0.6485 - val_accuracy: 0.7570\n",
      "Epoch 187/200\n",
      "7000/7000 [==============================] - 1s 111us/step - loss: 0.7976 - accuracy: 0.7037 - val_loss: 0.6505 - val_accuracy: 0.7580\n",
      "Epoch 188/200\n",
      "7000/7000 [==============================] - 1s 113us/step - loss: 0.8048 - accuracy: 0.7006 - val_loss: 0.6475 - val_accuracy: 0.7590\n",
      "Epoch 189/200\n",
      "7000/7000 [==============================] - 1s 111us/step - loss: 0.8122 - accuracy: 0.6944 - val_loss: 0.6468 - val_accuracy: 0.7570\n",
      "Epoch 190/200\n",
      "7000/7000 [==============================] - 1s 115us/step - loss: 0.7860 - accuracy: 0.7070 - val_loss: 0.6457 - val_accuracy: 0.7580\n",
      "Epoch 191/200\n",
      "7000/7000 [==============================] - 1s 111us/step - loss: 0.7903 - accuracy: 0.7027 - val_loss: 0.6446 - val_accuracy: 0.7570\n",
      "Epoch 192/200\n",
      "7000/7000 [==============================] - 1s 112us/step - loss: 0.7931 - accuracy: 0.7007 - val_loss: 0.6452 - val_accuracy: 0.7580\n",
      "Epoch 193/200\n",
      "7000/7000 [==============================] - 1s 114us/step - loss: 0.7819 - accuracy: 0.7117 - val_loss: 0.6447 - val_accuracy: 0.7570\n",
      "Epoch 194/200\n",
      "7000/7000 [==============================] - 1s 111us/step - loss: 0.7964 - accuracy: 0.6976 - val_loss: 0.6421 - val_accuracy: 0.7570\n",
      "Epoch 195/200\n",
      "7000/7000 [==============================] - 1s 113us/step - loss: 0.7882 - accuracy: 0.7040 - val_loss: 0.6427 - val_accuracy: 0.7590\n",
      "Epoch 196/200\n",
      "7000/7000 [==============================] - 1s 113us/step - loss: 0.8040 - accuracy: 0.6900 - val_loss: 0.6426 - val_accuracy: 0.7600\n",
      "Epoch 197/200\n",
      "7000/7000 [==============================] - 1s 111us/step - loss: 0.7955 - accuracy: 0.7024 - val_loss: 0.6413 - val_accuracy: 0.7590\n",
      "Epoch 198/200\n",
      "7000/7000 [==============================] - 1s 113us/step - loss: 0.7865 - accuracy: 0.7064 - val_loss: 0.6406 - val_accuracy: 0.7570\n",
      "Epoch 199/200\n",
      "7000/7000 [==============================] - 1s 109us/step - loss: 0.7884 - accuracy: 0.7026 - val_loss: 0.6382 - val_accuracy: 0.7600\n",
      "Epoch 200/200\n",
      "7000/7000 [==============================] - 1s 113us/step - loss: 0.7755 - accuracy: 0.7114 - val_loss: 0.6396 - val_accuracy: 0.7570\n"
     ]
    }
   ],
   "source": [
    "#  This cell may take about a minute to run\n",
    "random.seed(123)\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dropout(0.3, input_shape=(2000,)))\n",
    "model.add(keras.layers.Dense(50, activation='relu')) #2 hidden layers\n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "model.add(keras.layers.Dense(25, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "model.add(keras.layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "dropout_model = model.fit(X_train_tokenized,\n",
    "                    y_train_bin,\n",
    "                    epochs=200,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 1s 104us/step\n",
      "Training Loss: 0.49 Training Accuracy: 0.822\n",
      "2000/2000 [==============================] - 0s 66us/step\n",
      "Testing Loss: 0.639 Testing Accuracy: 0.769\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(X_train_tokenized, y_train_bin)\n",
    "print(f'Training Loss: {results_train[0]:.3} Training Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "results_test = model.evaluate(X_test_tok, y_test_cat)\n",
    "print(f'Testing Loss: {results_test[0]:.3} Testing Accuracy: {results_test[1]:.3}')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see here that the validation performance has improved again! The variance did become higher again compared to L1-regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigger Data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lecture, one of the solutions to high variance was just getting more data. You actually *have* more data, but took a subset of 10,000 units before. Let's now quadruple your data set, and see what happens. Note that you are really just lucky here, and getting more data isn't always possible, but this is a useful exercise in order to understand the power of big data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Bank_complaints.csv')\n",
    "df = df.sample(40000, random_state=123)\n",
    "\n",
    "X = df[\"Consumer complaint narrative\"]\n",
    "y = df[\"Product\"]\n",
    "\n",
    "# train test split\n",
    "X_train_lrg, X_test_lrg, y_train_lrg, y_test_lrg = train_test_split(X, y, random_state=42)\n",
    "\n",
    "#Validation set\n",
    "X_train_final_lrg, X_val_lrg, y_train_final_lrg, y_val_lrg = train_test_split(X_train_lrg, y_train_lrg, random_state=123)\n",
    "\n",
    "\n",
    "#one-hot encoding of the complaints\n",
    "tokenizer = Tokenizer(num_words=2000)\n",
    "tokenizer.fit_on_texts(X_train_final_lrg)\n",
    "\n",
    "X_train_tok_lrg = tokenizer.texts_to_matrix(X_train_final_lrg, mode='binary')\n",
    "X_val_lrg = tokenizer.texts_to_matrix(X_val_lrg, mode='binary')\n",
    "X_test_lrg = tokenizer.texts_to_matrix(X_test_lrg, mode='binary')\n",
    "\n",
    "#one-hot encoding of products\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_train_final_lrg)\n",
    "\n",
    "y_train_lb_lrg = to_categorical(lb.transform(y_train_final_lrg))[:, :, 1]\n",
    "y_val_lrg = to_categorical(lb.transform(y_val_lrg))[:, :, 1]\n",
    "y_test_lrg = to_categorical(lb.transform(y_test_lrg))[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22500 samples, validate on 7500 samples\n",
      "Epoch 1/120\n",
      "22500/22500 [==============================] - 2s 73us/step - loss: 1.9122 - accuracy: 0.1988 - val_loss: 1.8662 - val_accuracy: 0.2525\n",
      "Epoch 2/120\n",
      "22500/22500 [==============================] - 1s 58us/step - loss: 1.8219 - accuracy: 0.2980 - val_loss: 1.7642 - val_accuracy: 0.3580\n",
      "Epoch 3/120\n",
      "22500/22500 [==============================] - 1s 64us/step - loss: 1.6946 - accuracy: 0.4109 - val_loss: 1.6159 - val_accuracy: 0.4611\n",
      "Epoch 4/120\n",
      "22500/22500 [==============================] - 1s 57us/step - loss: 1.5323 - accuracy: 0.5022 - val_loss: 1.4481 - val_accuracy: 0.5321\n",
      "Epoch 5/120\n",
      "22500/22500 [==============================] - 1s 56us/step - loss: 1.3674 - accuracy: 0.5676 - val_loss: 1.2917 - val_accuracy: 0.5975\n",
      "Epoch 6/120\n",
      "22500/22500 [==============================] - 1s 55us/step - loss: 1.2212 - accuracy: 0.6220 - val_loss: 1.1596 - val_accuracy: 0.6348\n",
      "Epoch 7/120\n",
      "22500/22500 [==============================] - 1s 55us/step - loss: 1.1012 - accuracy: 0.6561 - val_loss: 1.0546 - val_accuracy: 0.6639\n",
      "Epoch 8/120\n",
      "22500/22500 [==============================] - 1s 55us/step - loss: 1.0054 - accuracy: 0.6772 - val_loss: 0.9722 - val_accuracy: 0.6837\n",
      "Epoch 9/120\n",
      "22500/22500 [==============================] - 1s 54us/step - loss: 0.9299 - accuracy: 0.6960 - val_loss: 0.9103 - val_accuracy: 0.6939\n",
      "Epoch 10/120\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.8703 - accuracy: 0.7083 - val_loss: 0.8576 - val_accuracy: 0.7063\n",
      "Epoch 11/120\n",
      "22500/22500 [==============================] - 1s 57us/step - loss: 0.8230 - accuracy: 0.7188 - val_loss: 0.8180 - val_accuracy: 0.7155\n",
      "Epoch 12/120\n",
      "22500/22500 [==============================] - 1s 54us/step - loss: 0.7838 - accuracy: 0.7300 - val_loss: 0.7859 - val_accuracy: 0.7256\n",
      "Epoch 13/120\n",
      "22500/22500 [==============================] - 1s 54us/step - loss: 0.7521 - accuracy: 0.7370 - val_loss: 0.7627 - val_accuracy: 0.7305\n",
      "Epoch 14/120\n",
      "22500/22500 [==============================] - 1s 55us/step - loss: 0.7254 - accuracy: 0.7453 - val_loss: 0.7402 - val_accuracy: 0.7347\n",
      "Epoch 15/120\n",
      "22500/22500 [==============================] - 1s 55us/step - loss: 0.7024 - accuracy: 0.7502 - val_loss: 0.7211 - val_accuracy: 0.7392\n",
      "Epoch 16/120\n",
      "22500/22500 [==============================] - 1s 64us/step - loss: 0.6829 - accuracy: 0.7564 - val_loss: 0.7058 - val_accuracy: 0.7440\n",
      "Epoch 17/120\n",
      "22500/22500 [==============================] - 2s 68us/step - loss: 0.6652 - accuracy: 0.7620 - val_loss: 0.6946 - val_accuracy: 0.7487\n",
      "Epoch 18/120\n",
      "22500/22500 [==============================] - 2s 69us/step - loss: 0.6496 - accuracy: 0.7677 - val_loss: 0.6822 - val_accuracy: 0.7523\n",
      "Epoch 19/120\n",
      "22500/22500 [==============================] - 2s 69us/step - loss: 0.6361 - accuracy: 0.7733 - val_loss: 0.6744 - val_accuracy: 0.7555\n",
      "Epoch 20/120\n",
      "22500/22500 [==============================] - 2s 68us/step - loss: 0.6234 - accuracy: 0.7772 - val_loss: 0.6629 - val_accuracy: 0.7565\n",
      "Epoch 21/120\n",
      "22500/22500 [==============================] - 2s 68us/step - loss: 0.6115 - accuracy: 0.7809 - val_loss: 0.6548 - val_accuracy: 0.7597\n",
      "Epoch 22/120\n",
      "22500/22500 [==============================] - 2s 67us/step - loss: 0.6009 - accuracy: 0.7837 - val_loss: 0.6498 - val_accuracy: 0.7584\n",
      "Epoch 23/120\n",
      "22500/22500 [==============================] - 2s 71us/step - loss: 0.5912 - accuracy: 0.7871 - val_loss: 0.6425 - val_accuracy: 0.7640\n",
      "Epoch 24/120\n",
      "22500/22500 [==============================] - 4s 157us/step - loss: 0.5815 - accuracy: 0.7918 - val_loss: 0.6362 - val_accuracy: 0.7679\n",
      "Epoch 25/120\n",
      "22500/22500 [==============================] - 3s 133us/step - loss: 0.5724 - accuracy: 0.7952 - val_loss: 0.6313 - val_accuracy: 0.7668\n",
      "Epoch 26/120\n",
      "22500/22500 [==============================] - 1s 59us/step - loss: 0.5643 - accuracy: 0.7976 - val_loss: 0.6262 - val_accuracy: 0.7684\n",
      "Epoch 27/120\n",
      "22500/22500 [==============================] - 3s 136us/step - loss: 0.5567 - accuracy: 0.8001 - val_loss: 0.6217 - val_accuracy: 0.7703\n",
      "Epoch 28/120\n",
      "22500/22500 [==============================] - 3s 132us/step - loss: 0.5490 - accuracy: 0.8018 - val_loss: 0.6180 - val_accuracy: 0.7749\n",
      "Epoch 29/120\n",
      "22500/22500 [==============================] - 3s 137us/step - loss: 0.5421 - accuracy: 0.8060 - val_loss: 0.6158 - val_accuracy: 0.7708\n",
      "Epoch 30/120\n",
      "22500/22500 [==============================] - 3s 134us/step - loss: 0.5358 - accuracy: 0.8077 - val_loss: 0.6112 - val_accuracy: 0.7771\n",
      "Epoch 31/120\n",
      "22500/22500 [==============================] - 3s 148us/step - loss: 0.5292 - accuracy: 0.8109 - val_loss: 0.6105 - val_accuracy: 0.7735\n",
      "Epoch 32/120\n",
      "22500/22500 [==============================] - 3s 113us/step - loss: 0.5233 - accuracy: 0.8139 - val_loss: 0.6062 - val_accuracy: 0.7769\n",
      "Epoch 33/120\n",
      "22500/22500 [==============================] - 1s 65us/step - loss: 0.5170 - accuracy: 0.8143 - val_loss: 0.6036 - val_accuracy: 0.7759\n",
      "Epoch 34/120\n",
      "22500/22500 [==============================] - 1s 56us/step - loss: 0.5116 - accuracy: 0.8181 - val_loss: 0.6006 - val_accuracy: 0.7803\n",
      "Epoch 35/120\n",
      "22500/22500 [==============================] - 1s 57us/step - loss: 0.5058 - accuracy: 0.8194 - val_loss: 0.6001 - val_accuracy: 0.7789\n",
      "Epoch 36/120\n",
      "22500/22500 [==============================] - 1s 58us/step - loss: 0.5008 - accuracy: 0.8216 - val_loss: 0.5966 - val_accuracy: 0.7819\n",
      "Epoch 37/120\n",
      "22500/22500 [==============================] - 1s 56us/step - loss: 0.4956 - accuracy: 0.8248 - val_loss: 0.5960 - val_accuracy: 0.7829\n",
      "Epoch 38/120\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.4906 - accuracy: 0.8257 - val_loss: 0.5929 - val_accuracy: 0.7833\n",
      "Epoch 39/120\n",
      "22500/22500 [==============================] - 1s 57us/step - loss: 0.4858 - accuracy: 0.8278 - val_loss: 0.5928 - val_accuracy: 0.7823\n",
      "Epoch 40/120\n",
      "22500/22500 [==============================] - 1s 57us/step - loss: 0.4814 - accuracy: 0.8300 - val_loss: 0.5909 - val_accuracy: 0.7844\n",
      "Epoch 41/120\n",
      "22500/22500 [==============================] - 1s 56us/step - loss: 0.4764 - accuracy: 0.8319 - val_loss: 0.5910 - val_accuracy: 0.7817\n",
      "Epoch 42/120\n",
      "22500/22500 [==============================] - 1s 57us/step - loss: 0.4722 - accuracy: 0.8331 - val_loss: 0.5892 - val_accuracy: 0.7852\n",
      "Epoch 43/120\n",
      "22500/22500 [==============================] - 1s 56us/step - loss: 0.4683 - accuracy: 0.8347 - val_loss: 0.5867 - val_accuracy: 0.7865\n",
      "Epoch 44/120\n",
      "22500/22500 [==============================] - 1s 66us/step - loss: 0.4637 - accuracy: 0.8363 - val_loss: 0.5862 - val_accuracy: 0.7848\n",
      "Epoch 45/120\n",
      "22500/22500 [==============================] - 1s 65us/step - loss: 0.4598 - accuracy: 0.8377 - val_loss: 0.5843 - val_accuracy: 0.7857\n",
      "Epoch 46/120\n",
      "22500/22500 [==============================] - 1s 64us/step - loss: 0.4557 - accuracy: 0.8399 - val_loss: 0.5842 - val_accuracy: 0.7875\n",
      "Epoch 47/120\n",
      "22500/22500 [==============================] - 1s 64us/step - loss: 0.4517 - accuracy: 0.8397 - val_loss: 0.5838 - val_accuracy: 0.7879\n",
      "Epoch 48/120\n",
      "22500/22500 [==============================] - 1s 65us/step - loss: 0.4482 - accuracy: 0.8423 - val_loss: 0.5869 - val_accuracy: 0.7844\n",
      "Epoch 49/120\n",
      "22500/22500 [==============================] - 1s 64us/step - loss: 0.4443 - accuracy: 0.8440 - val_loss: 0.5826 - val_accuracy: 0.7893\n",
      "Epoch 50/120\n",
      "22500/22500 [==============================] - 1s 66us/step - loss: 0.4407 - accuracy: 0.8453 - val_loss: 0.5819 - val_accuracy: 0.7889\n",
      "Epoch 51/120\n",
      "22500/22500 [==============================] - 3s 131us/step - loss: 0.4368 - accuracy: 0.8475 - val_loss: 0.5805 - val_accuracy: 0.7905\n",
      "Epoch 52/120\n",
      "22500/22500 [==============================] - 3s 137us/step - loss: 0.4337 - accuracy: 0.8483 - val_loss: 0.5804 - val_accuracy: 0.7904\n",
      "Epoch 53/120\n",
      "22500/22500 [==============================] - 3s 116us/step - loss: 0.4303 - accuracy: 0.8495 - val_loss: 0.5806 - val_accuracy: 0.7901\n",
      "Epoch 54/120\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.4274 - accuracy: 0.8505 - val_loss: 0.5791 - val_accuracy: 0.7907\n",
      "Epoch 55/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 1s 53us/step - loss: 0.4236 - accuracy: 0.8527 - val_loss: 0.5785 - val_accuracy: 0.7915\n",
      "Epoch 56/120\n",
      "22500/22500 [==============================] - 1s 58us/step - loss: 0.4205 - accuracy: 0.8537 - val_loss: 0.5782 - val_accuracy: 0.7920\n",
      "Epoch 57/120\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.4173 - accuracy: 0.8551 - val_loss: 0.5792 - val_accuracy: 0.7920\n",
      "Epoch 58/120\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.4143 - accuracy: 0.8556 - val_loss: 0.5783 - val_accuracy: 0.7913\n",
      "Epoch 59/120\n",
      "22500/22500 [==============================] - 1s 61us/step - loss: 0.4111 - accuracy: 0.8587 - val_loss: 0.5787 - val_accuracy: 0.7945\n",
      "Epoch 60/120\n",
      "22500/22500 [==============================] - 2s 70us/step - loss: 0.4080 - accuracy: 0.8583 - val_loss: 0.5782 - val_accuracy: 0.7903\n",
      "Epoch 61/120\n",
      "22500/22500 [==============================] - 2s 68us/step - loss: 0.4052 - accuracy: 0.8606 - val_loss: 0.5787 - val_accuracy: 0.7935\n",
      "Epoch 62/120\n",
      "22500/22500 [==============================] - 1s 65us/step - loss: 0.4023 - accuracy: 0.8612 - val_loss: 0.5802 - val_accuracy: 0.7917\n",
      "Epoch 63/120\n",
      "22500/22500 [==============================] - 1s 66us/step - loss: 0.3995 - accuracy: 0.8618 - val_loss: 0.5778 - val_accuracy: 0.7933\n",
      "Epoch 64/120\n",
      "22500/22500 [==============================] - 1s 65us/step - loss: 0.3965 - accuracy: 0.8627 - val_loss: 0.5786 - val_accuracy: 0.7921\n",
      "Epoch 65/120\n",
      "22500/22500 [==============================] - 1s 65us/step - loss: 0.3939 - accuracy: 0.8641 - val_loss: 0.5819 - val_accuracy: 0.7923\n",
      "Epoch 66/120\n",
      "22500/22500 [==============================] - 2s 67us/step - loss: 0.3914 - accuracy: 0.8662 - val_loss: 0.5783 - val_accuracy: 0.7928\n",
      "Epoch 67/120\n",
      "22500/22500 [==============================] - 2s 82us/step - loss: 0.3887 - accuracy: 0.8665 - val_loss: 0.5796 - val_accuracy: 0.7924\n",
      "Epoch 68/120\n",
      "22500/22500 [==============================] - 2s 82us/step - loss: 0.3863 - accuracy: 0.8668 - val_loss: 0.5791 - val_accuracy: 0.7939\n",
      "Epoch 69/120\n",
      "22500/22500 [==============================] - 2s 84us/step - loss: 0.3837 - accuracy: 0.8684 - val_loss: 0.5796 - val_accuracy: 0.7920\n",
      "Epoch 70/120\n",
      "22500/22500 [==============================] - 2s 90us/step - loss: 0.3813 - accuracy: 0.8688 - val_loss: 0.5800 - val_accuracy: 0.7933\n",
      "Epoch 71/120\n",
      "22500/22500 [==============================] - 2s 80us/step - loss: 0.3785 - accuracy: 0.8710 - val_loss: 0.5800 - val_accuracy: 0.7953\n",
      "Epoch 72/120\n",
      "22500/22500 [==============================] - 2s 78us/step - loss: 0.3759 - accuracy: 0.8717 - val_loss: 0.5804 - val_accuracy: 0.7943\n",
      "Epoch 73/120\n",
      "22500/22500 [==============================] - 2s 83us/step - loss: 0.3735 - accuracy: 0.8729 - val_loss: 0.5820 - val_accuracy: 0.7929\n",
      "Epoch 74/120\n",
      "22500/22500 [==============================] - 2s 73us/step - loss: 0.3712 - accuracy: 0.8737 - val_loss: 0.5818 - val_accuracy: 0.7935\n",
      "Epoch 75/120\n",
      "22500/22500 [==============================] - 2s 69us/step - loss: 0.3691 - accuracy: 0.8747 - val_loss: 0.5815 - val_accuracy: 0.7935\n",
      "Epoch 76/120\n",
      "22500/22500 [==============================] - 3s 129us/step - loss: 0.3666 - accuracy: 0.8753 - val_loss: 0.5836 - val_accuracy: 0.7932\n",
      "Epoch 77/120\n",
      "22500/22500 [==============================] - 3s 127us/step - loss: 0.3645 - accuracy: 0.8763 - val_loss: 0.5833 - val_accuracy: 0.7933\n",
      "Epoch 78/120\n",
      "22500/22500 [==============================] - 3s 130us/step - loss: 0.3620 - accuracy: 0.8775 - val_loss: 0.5845 - val_accuracy: 0.7936\n",
      "Epoch 79/120\n",
      "22500/22500 [==============================] - 3s 127us/step - loss: 0.3599 - accuracy: 0.8780 - val_loss: 0.5852 - val_accuracy: 0.7929\n",
      "Epoch 80/120\n",
      "22500/22500 [==============================] - 3s 128us/step - loss: 0.3579 - accuracy: 0.8784 - val_loss: 0.5860 - val_accuracy: 0.7928\n",
      "Epoch 81/120\n",
      "22500/22500 [==============================] - 3s 128us/step - loss: 0.3553 - accuracy: 0.8791 - val_loss: 0.5871 - val_accuracy: 0.7915\n",
      "Epoch 82/120\n",
      "22500/22500 [==============================] - 3s 112us/step - loss: 0.3529 - accuracy: 0.8800 - val_loss: 0.5881 - val_accuracy: 0.7916\n",
      "Epoch 83/120\n",
      "22500/22500 [==============================] - 1s 59us/step - loss: 0.3510 - accuracy: 0.8799 - val_loss: 0.5869 - val_accuracy: 0.7941\n",
      "Epoch 84/120\n",
      "22500/22500 [==============================] - 1s 55us/step - loss: 0.3488 - accuracy: 0.8820 - val_loss: 0.5895 - val_accuracy: 0.7915\n",
      "Epoch 85/120\n",
      "22500/22500 [==============================] - 1s 56us/step - loss: 0.3468 - accuracy: 0.8832 - val_loss: 0.5881 - val_accuracy: 0.7948\n",
      "Epoch 86/120\n",
      "22500/22500 [==============================] - 1s 56us/step - loss: 0.3447 - accuracy: 0.8845 - val_loss: 0.5893 - val_accuracy: 0.7944\n",
      "Epoch 87/120\n",
      "22500/22500 [==============================] - 1s 56us/step - loss: 0.3425 - accuracy: 0.8841 - val_loss: 0.5900 - val_accuracy: 0.7945\n",
      "Epoch 88/120\n",
      "22500/22500 [==============================] - 1s 57us/step - loss: 0.3407 - accuracy: 0.8862 - val_loss: 0.5920 - val_accuracy: 0.7935\n",
      "Epoch 89/120\n",
      "22500/22500 [==============================] - 1s 56us/step - loss: 0.3386 - accuracy: 0.8861 - val_loss: 0.5920 - val_accuracy: 0.7921\n",
      "Epoch 90/120\n",
      "22500/22500 [==============================] - 1s 56us/step - loss: 0.3365 - accuracy: 0.8880 - val_loss: 0.5924 - val_accuracy: 0.7935\n",
      "Epoch 91/120\n",
      "22500/22500 [==============================] - 1s 58us/step - loss: 0.3346 - accuracy: 0.8882 - val_loss: 0.5945 - val_accuracy: 0.7919\n",
      "Epoch 92/120\n",
      "22500/22500 [==============================] - 1s 57us/step - loss: 0.3326 - accuracy: 0.8883 - val_loss: 0.5935 - val_accuracy: 0.7931\n",
      "Epoch 93/120\n",
      "22500/22500 [==============================] - 1s 57us/step - loss: 0.3308 - accuracy: 0.8892 - val_loss: 0.5982 - val_accuracy: 0.7917\n",
      "Epoch 94/120\n",
      "22500/22500 [==============================] - 1s 64us/step - loss: 0.3290 - accuracy: 0.8902 - val_loss: 0.5951 - val_accuracy: 0.7952\n",
      "Epoch 95/120\n",
      "22500/22500 [==============================] - 2s 69us/step - loss: 0.3270 - accuracy: 0.8906 - val_loss: 0.5957 - val_accuracy: 0.7955\n",
      "Epoch 96/120\n",
      "22500/22500 [==============================] - 1s 63us/step - loss: 0.3251 - accuracy: 0.8911 - val_loss: 0.6003 - val_accuracy: 0.7924\n",
      "Epoch 97/120\n",
      "22500/22500 [==============================] - 3s 130us/step - loss: 0.3232 - accuracy: 0.8920 - val_loss: 0.5977 - val_accuracy: 0.7932\n",
      "Epoch 98/120\n",
      "22500/22500 [==============================] - 2s 97us/step - loss: 0.3215 - accuracy: 0.8923 - val_loss: 0.6001 - val_accuracy: 0.7925\n",
      "Epoch 99/120\n",
      "22500/22500 [==============================] - 1s 58us/step - loss: 0.3195 - accuracy: 0.8936 - val_loss: 0.6014 - val_accuracy: 0.7931\n",
      "Epoch 100/120\n",
      "22500/22500 [==============================] - 1s 56us/step - loss: 0.3179 - accuracy: 0.8937 - val_loss: 0.6017 - val_accuracy: 0.7937\n",
      "Epoch 101/120\n",
      "22500/22500 [==============================] - 1s 59us/step - loss: 0.3161 - accuracy: 0.8951 - val_loss: 0.6021 - val_accuracy: 0.7935\n",
      "Epoch 102/120\n",
      "22500/22500 [==============================] - 2s 67us/step - loss: 0.3142 - accuracy: 0.8955 - val_loss: 0.6032 - val_accuracy: 0.7940\n",
      "Epoch 103/120\n",
      "22500/22500 [==============================] - 2s 69us/step - loss: 0.3128 - accuracy: 0.8953 - val_loss: 0.6062 - val_accuracy: 0.7933\n",
      "Epoch 104/120\n",
      "22500/22500 [==============================] - 2s 73us/step - loss: 0.3105 - accuracy: 0.8966 - val_loss: 0.6056 - val_accuracy: 0.7931\n",
      "Epoch 105/120\n",
      "22500/22500 [==============================] - 2s 69us/step - loss: 0.3093 - accuracy: 0.8978 - val_loss: 0.6082 - val_accuracy: 0.7932\n",
      "Epoch 106/120\n",
      "22500/22500 [==============================] - 2s 71us/step - loss: 0.3074 - accuracy: 0.8981 - val_loss: 0.6087 - val_accuracy: 0.7923\n",
      "Epoch 107/120\n",
      "22500/22500 [==============================] - 2s 74us/step - loss: 0.3055 - accuracy: 0.8996 - val_loss: 0.6118 - val_accuracy: 0.7915\n",
      "Epoch 108/120\n",
      "22500/22500 [==============================] - 2s 72us/step - loss: 0.3038 - accuracy: 0.8996 - val_loss: 0.6096 - val_accuracy: 0.7928\n",
      "Epoch 109/120\n",
      "22500/22500 [==============================] - 2s 70us/step - loss: 0.3024 - accuracy: 0.8994 - val_loss: 0.6111 - val_accuracy: 0.7927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/120\n",
      "22500/22500 [==============================] - 1s 63us/step - loss: 0.3002 - accuracy: 0.9016 - val_loss: 0.6125 - val_accuracy: 0.7931\n",
      "Epoch 111/120\n",
      "22500/22500 [==============================] - 1s 62us/step - loss: 0.2992 - accuracy: 0.9006 - val_loss: 0.6132 - val_accuracy: 0.7947\n",
      "Epoch 112/120\n",
      "22500/22500 [==============================] - 1s 62us/step - loss: 0.2972 - accuracy: 0.9012 - val_loss: 0.6156 - val_accuracy: 0.7936\n",
      "Epoch 113/120\n",
      "22500/22500 [==============================] - 1s 63us/step - loss: 0.2955 - accuracy: 0.9026 - val_loss: 0.6168 - val_accuracy: 0.7929\n",
      "Epoch 114/120\n",
      "22500/22500 [==============================] - 1s 63us/step - loss: 0.2939 - accuracy: 0.9041 - val_loss: 0.6195 - val_accuracy: 0.7932\n",
      "Epoch 115/120\n",
      "22500/22500 [==============================] - 3s 120us/step - loss: 0.2924 - accuracy: 0.9034 - val_loss: 0.6202 - val_accuracy: 0.7924\n",
      "Epoch 116/120\n",
      "22500/22500 [==============================] - 3s 122us/step - loss: 0.2908 - accuracy: 0.9041 - val_loss: 0.6212 - val_accuracy: 0.7925\n",
      "Epoch 117/120\n",
      "22500/22500 [==============================] - 3s 123us/step - loss: 0.2891 - accuracy: 0.9050 - val_loss: 0.6208 - val_accuracy: 0.7937\n",
      "Epoch 118/120\n",
      "22500/22500 [==============================] - 3s 122us/step - loss: 0.2874 - accuracy: 0.9066 - val_loss: 0.6223 - val_accuracy: 0.7940\n",
      "Epoch 119/120\n",
      "22500/22500 [==============================] - 3s 130us/step - loss: 0.2860 - accuracy: 0.9070 - val_loss: 0.6229 - val_accuracy: 0.7925\n",
      "Epoch 120/120\n",
      "22500/22500 [==============================] - 2s 90us/step - loss: 0.2847 - accuracy: 0.9071 - val_loss: 0.6255 - val_accuracy: 0.7937\n"
     ]
    }
   ],
   "source": [
    "#  This cell may take several minutes to run\n",
    "random.seed(123)\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(50, activation='relu', input_shape=(2000,))) #2 hidden layers\n",
    "model.add(keras.layers.Dense(25, activation='relu'))\n",
    "model.add(keras.layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "moredata_model = model.fit(X_train_tok_lrg,\n",
    "                    y_train_lb_lrg,\n",
    "                    epochs=120,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val_lrg, y_val_lrg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 2s 109us/step\n",
      "Training Loss: 0.28 Training Accuracy: 0.909\n",
      "10000/10000 [==============================] - 1s 51us/step\n",
      "Testing Loss: 0.627 Testing Accuracy: 0.79\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(X_train_tok_lrg, y_train_lb_lrg)\n",
    "print(f'Training Loss: {results_train[0]:.3} Training Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "results_test = model.evaluate(X_test_lrg, y_test_lrg)\n",
    "print(f'Testing Loss: {results_test[0]:.3} Testing Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the same amount of epochs, you were able to get a fairly similar validation accuracy of 89.67 (compared to 88.45 in obtained in the first model in this lab). Your test set accuracy went up from 75.8 to 79.2% though, without any other regularization technique. You can still consider early stopping, L1, L2 and dropout here. It's clear that having more data has a strong impact on model performance!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    "* https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Consumer_complaints.ipynb\n",
    "* https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/\n",
    "* https://catalog.data.gov/dataset/consumer-complaint-database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary  \n",
    "\n",
    "In this lesson, you not only built an initial deep-learning model, you then used a validation set to tune your model using various types of regularization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
